{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sciml.model.deeponet import DeepONet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = 40\n",
    "d_V = 80\n",
    "epochs = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(80,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "])\n",
    "\n",
    "\n",
    "external_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/test_data/example_data/heat2d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:34:42,446 - sciml.model.deeponet.deeponet - INFO - Model initialized with 300 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(regular_params={\"internal_model\": internal_model, \"external_model\": external_model}, hyper_params={\"d_p\": d_p, \"d_V\": d_V,\"device\": \"GPU\",\"n_epochs\":epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 9626.03it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 4659.56it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 6049.55it/s]\n"
     ]
    }
   ],
   "source": [
    "mus, xs, sol = model.get_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 80)\n",
      "(40, 8000, 3)\n",
      "(40, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(mus.shape)\n",
    "print(xs.shape)\n",
    "print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 6685.22it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 4965.00it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 6809.21it/s]\n",
      "2025-03-16 20:34:42.968778: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [40,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "Training progress:   0%|          | 0/300 [00:00<?, ?it/s]2025-03-16 20:34:42.986607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-16 20:34:43.319126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [8,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-16 20:34:43,364 - sciml.model.deeponet.deeponet - INFO - Epoch 1/300\n",
      "2025-03-16 20:34:43,365 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.295027\n",
      "2025-03-16 20:34:43,366 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.248939\n",
      "Training progress:   0%|          | 1/300 [00:00<01:54,  2.61it/s]2025-03-16 20:34:43,735 - sciml.model.deeponet.deeponet - INFO - Epoch 2/300\n",
      "2025-03-16 20:34:43,736 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.284759\n",
      "2025-03-16 20:34:43,737 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.237069\n",
      "Training progress:   1%|          | 2/300 [00:00<01:52,  2.66it/s]2025-03-16 20:34:44,102 - sciml.model.deeponet.deeponet - INFO - Epoch 3/300\n",
      "2025-03-16 20:34:44,103 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.272740\n",
      "2025-03-16 20:34:44,103 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.238732\n",
      "Training progress:   1%|          | 3/300 [00:01<01:50,  2.69it/s]2025-03-16 20:34:44,470 - sciml.model.deeponet.deeponet - INFO - Epoch 4/300\n",
      "2025-03-16 20:34:44,471 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.270108\n",
      "2025-03-16 20:34:44,471 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.232918\n",
      "Training progress:   1%|▏         | 4/300 [00:01<01:49,  2.70it/s]2025-03-16 20:34:44,848 - sciml.model.deeponet.deeponet - INFO - Epoch 5/300\n",
      "2025-03-16 20:34:44,849 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.260651\n",
      "2025-03-16 20:34:44,849 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.226034\n",
      "Training progress:   2%|▏         | 5/300 [00:01<01:50,  2.68it/s]2025-03-16 20:34:45,203 - sciml.model.deeponet.deeponet - INFO - Epoch 6/300\n",
      "2025-03-16 20:34:45,204 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.254156\n",
      "2025-03-16 20:34:45,204 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.221621\n",
      "Training progress:   2%|▏         | 6/300 [00:02<01:47,  2.73it/s]2025-03-16 20:34:45,568 - sciml.model.deeponet.deeponet - INFO - Epoch 7/300\n",
      "2025-03-16 20:34:45,568 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.248727\n",
      "2025-03-16 20:34:45,569 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.218065\n",
      "Training progress:   2%|▏         | 7/300 [00:02<01:47,  2.73it/s]2025-03-16 20:34:45,928 - sciml.model.deeponet.deeponet - INFO - Epoch 8/300\n",
      "2025-03-16 20:34:45,929 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.242185\n",
      "2025-03-16 20:34:45,929 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.215700\n",
      "Training progress:   3%|▎         | 8/300 [00:02<01:46,  2.75it/s]2025-03-16 20:34:46,298 - sciml.model.deeponet.deeponet - INFO - Epoch 9/300\n",
      "2025-03-16 20:34:46,299 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.236549\n",
      "2025-03-16 20:34:46,300 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.212444\n",
      "Training progress:   3%|▎         | 9/300 [00:03<01:46,  2.73it/s]2025-03-16 20:34:46,672 - sciml.model.deeponet.deeponet - INFO - Epoch 10/300\n",
      "2025-03-16 20:34:46,673 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.231383\n",
      "2025-03-16 20:34:46,673 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.207244\n",
      "Training progress:   3%|▎         | 10/300 [00:03<01:46,  2.71it/s]2025-03-16 20:34:47,056 - sciml.model.deeponet.deeponet - INFO - Epoch 11/300\n",
      "2025-03-16 20:34:47,057 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.225098\n",
      "2025-03-16 20:34:47,057 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.202234\n",
      "Training progress:   4%|▎         | 11/300 [00:04<01:47,  2.68it/s]2025-03-16 20:34:47,433 - sciml.model.deeponet.deeponet - INFO - Epoch 12/300\n",
      "2025-03-16 20:34:47,434 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.218472\n",
      "2025-03-16 20:34:47,435 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.197791\n",
      "Training progress:   4%|▍         | 12/300 [00:04<01:47,  2.67it/s]2025-03-16 20:34:47,808 - sciml.model.deeponet.deeponet - INFO - Epoch 13/300\n",
      "2025-03-16 20:34:47,808 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.211678\n",
      "2025-03-16 20:34:47,818 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.193015\n",
      "Training progress:   4%|▍         | 13/300 [00:04<01:48,  2.65it/s]2025-03-16 20:34:48,190 - sciml.model.deeponet.deeponet - INFO - Epoch 14/300\n",
      "2025-03-16 20:34:48,191 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.203795\n",
      "2025-03-16 20:34:48,192 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.188445\n",
      "Training progress:   5%|▍         | 14/300 [00:05<01:47,  2.66it/s]2025-03-16 20:34:48,560 - sciml.model.deeponet.deeponet - INFO - Epoch 15/300\n",
      "2025-03-16 20:34:48,561 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.195844\n",
      "2025-03-16 20:34:48,562 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.183748\n",
      "Training progress:   5%|▌         | 15/300 [00:05<01:46,  2.67it/s]2025-03-16 20:34:48,912 - sciml.model.deeponet.deeponet - INFO - Epoch 16/300\n",
      "2025-03-16 20:34:48,913 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.187716\n",
      "2025-03-16 20:34:48,913 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.178782\n",
      "Training progress:   5%|▌         | 16/300 [00:05<01:44,  2.72it/s]2025-03-16 20:34:49,278 - sciml.model.deeponet.deeponet - INFO - Epoch 17/300\n",
      "2025-03-16 20:34:49,279 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.179106\n",
      "2025-03-16 20:34:49,280 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.174784\n",
      "Training progress:   6%|▌         | 17/300 [00:06<01:43,  2.72it/s]2025-03-16 20:34:49,657 - sciml.model.deeponet.deeponet - INFO - Epoch 18/300\n",
      "2025-03-16 20:34:49,658 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.172086\n",
      "2025-03-16 20:34:49,658 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.169831\n",
      "Training progress:   6%|▌         | 18/300 [00:06<01:44,  2.70it/s]2025-03-16 20:34:50,016 - sciml.model.deeponet.deeponet - INFO - Epoch 19/300\n",
      "2025-03-16 20:34:50,017 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.165167\n",
      "2025-03-16 20:34:50,018 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.164906\n",
      "Training progress:   6%|▋         | 19/300 [00:07<01:43,  2.72it/s]2025-03-16 20:34:50,375 - sciml.model.deeponet.deeponet - INFO - Epoch 20/300\n",
      "2025-03-16 20:34:50,376 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.159238\n",
      "2025-03-16 20:34:50,377 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.162266\n",
      "Training progress:   7%|▋         | 20/300 [00:07<01:42,  2.74it/s]2025-03-16 20:34:50,754 - sciml.model.deeponet.deeponet - INFO - Epoch 21/300\n",
      "2025-03-16 20:34:50,755 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.153546\n",
      "2025-03-16 20:34:50,755 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.160222\n",
      "Training progress:   7%|▋         | 21/300 [00:07<01:42,  2.71it/s]2025-03-16 20:34:51,122 - sciml.model.deeponet.deeponet - INFO - Epoch 22/300\n",
      "2025-03-16 20:34:51,123 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.150175\n",
      "2025-03-16 20:34:51,124 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.156927\n",
      "Training progress:   7%|▋         | 22/300 [00:08<01:42,  2.71it/s]2025-03-16 20:34:51,500 - sciml.model.deeponet.deeponet - INFO - Epoch 23/300\n",
      "2025-03-16 20:34:51,500 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.148043\n",
      "2025-03-16 20:34:51,501 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.156715\n",
      "Training progress:   8%|▊         | 23/300 [00:08<01:42,  2.69it/s]2025-03-16 20:34:51,853 - sciml.model.deeponet.deeponet - INFO - Epoch 24/300\n",
      "2025-03-16 20:34:51,854 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.145930\n",
      "2025-03-16 20:34:51,855 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.155608\n",
      "Training progress:   8%|▊         | 24/300 [00:08<01:40,  2.73it/s]2025-03-16 20:34:52,217 - sciml.model.deeponet.deeponet - INFO - Epoch 25/300\n",
      "2025-03-16 20:34:52,218 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.144641\n",
      "2025-03-16 20:34:52,218 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.154313\n",
      "Training progress:   8%|▊         | 25/300 [00:09<01:40,  2.74it/s]2025-03-16 20:34:52,564 - sciml.model.deeponet.deeponet - INFO - Epoch 26/300\n",
      "2025-03-16 20:34:52,565 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.143666\n",
      "2025-03-16 20:34:52,565 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.154831\n",
      "Training progress:   9%|▊         | 26/300 [00:09<01:38,  2.78it/s]2025-03-16 20:34:52,918 - sciml.model.deeponet.deeponet - INFO - Epoch 27/300\n",
      "2025-03-16 20:34:52,919 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.142396\n",
      "2025-03-16 20:34:52,920 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.151760\n",
      "Training progress:   9%|▉         | 27/300 [00:09<01:37,  2.79it/s]2025-03-16 20:34:53,276 - sciml.model.deeponet.deeponet - INFO - Epoch 28/300\n",
      "2025-03-16 20:34:53,276 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.140612\n",
      "2025-03-16 20:34:53,277 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.150785\n",
      "Training progress:   9%|▉         | 28/300 [00:10<01:37,  2.79it/s]2025-03-16 20:34:53,649 - sciml.model.deeponet.deeponet - INFO - Epoch 29/300\n",
      "2025-03-16 20:34:53,649 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.138385\n",
      "2025-03-16 20:34:53,650 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.149130\n",
      "Training progress:  10%|▉         | 29/300 [00:10<01:38,  2.76it/s]2025-03-16 20:34:54,013 - sciml.model.deeponet.deeponet - INFO - Epoch 30/300\n",
      "2025-03-16 20:34:54,014 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.136292\n",
      "2025-03-16 20:34:54,014 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.146640\n",
      "Training progress:  10%|█         | 30/300 [00:11<01:37,  2.76it/s]2025-03-16 20:34:54,384 - sciml.model.deeponet.deeponet - INFO - Epoch 31/300\n",
      "2025-03-16 20:34:54,385 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.134482\n",
      "2025-03-16 20:34:54,386 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.145838\n",
      "Training progress:  10%|█         | 31/300 [00:11<01:38,  2.74it/s]2025-03-16 20:34:54,763 - sciml.model.deeponet.deeponet - INFO - Epoch 32/300\n",
      "2025-03-16 20:34:54,763 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.132784\n",
      "2025-03-16 20:34:54,764 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.143640\n",
      "Training progress:  11%|█         | 32/300 [00:11<01:39,  2.71it/s]2025-03-16 20:34:55,139 - sciml.model.deeponet.deeponet - INFO - Epoch 33/300\n",
      "2025-03-16 20:34:55,140 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.131027\n",
      "2025-03-16 20:34:55,141 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.142054\n",
      "Training progress:  11%|█         | 33/300 [00:12<01:39,  2.69it/s]2025-03-16 20:34:55,509 - sciml.model.deeponet.deeponet - INFO - Epoch 34/300\n",
      "2025-03-16 20:34:55,510 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.129279\n",
      "2025-03-16 20:34:55,511 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.140486\n",
      "Training progress:  11%|█▏        | 34/300 [00:12<01:38,  2.69it/s]2025-03-16 20:34:55,887 - sciml.model.deeponet.deeponet - INFO - Epoch 35/300\n",
      "2025-03-16 20:34:55,887 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.127980\n",
      "2025-03-16 20:34:55,888 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.138867\n",
      "Training progress:  12%|█▏        | 35/300 [00:12<01:38,  2.68it/s]2025-03-16 20:34:56,262 - sciml.model.deeponet.deeponet - INFO - Epoch 36/300\n",
      "2025-03-16 20:34:56,263 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.126443\n",
      "2025-03-16 20:34:56,264 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.137664\n",
      "Training progress:  12%|█▏        | 36/300 [00:13<01:38,  2.68it/s]2025-03-16 20:34:56,647 - sciml.model.deeponet.deeponet - INFO - Epoch 37/300\n",
      "2025-03-16 20:34:56,648 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.124769\n",
      "2025-03-16 20:34:56,649 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.136583\n",
      "Training progress:  12%|█▏        | 37/300 [00:13<01:39,  2.65it/s]2025-03-16 20:34:57,018 - sciml.model.deeponet.deeponet - INFO - Epoch 38/300\n",
      "2025-03-16 20:34:57,019 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.123101\n",
      "2025-03-16 20:34:57,020 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.134998\n",
      "Training progress:  13%|█▎        | 38/300 [00:14<01:38,  2.67it/s]2025-03-16 20:34:57,390 - sciml.model.deeponet.deeponet - INFO - Epoch 39/300\n",
      "2025-03-16 20:34:57,391 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.121487\n",
      "2025-03-16 20:34:57,392 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.133277\n",
      "Training progress:  13%|█▎        | 39/300 [00:14<01:37,  2.67it/s]2025-03-16 20:34:57,765 - sciml.model.deeponet.deeponet - INFO - Epoch 40/300\n",
      "2025-03-16 20:34:57,766 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.119888\n",
      "2025-03-16 20:34:57,767 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131145\n",
      "Training progress:  13%|█▎        | 40/300 [00:14<01:37,  2.67it/s]2025-03-16 20:34:58,143 - sciml.model.deeponet.deeponet - INFO - Epoch 41/300\n",
      "2025-03-16 20:34:58,144 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.118292\n",
      "2025-03-16 20:34:58,145 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.129096\n",
      "Training progress:  14%|█▎        | 41/300 [00:15<01:37,  2.66it/s]2025-03-16 20:34:58,522 - sciml.model.deeponet.deeponet - INFO - Epoch 42/300\n",
      "2025-03-16 20:34:58,523 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.116918\n",
      "2025-03-16 20:34:58,524 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.127179\n",
      "Training progress:  14%|█▍        | 42/300 [00:15<01:37,  2.65it/s]2025-03-16 20:34:58,900 - sciml.model.deeponet.deeponet - INFO - Epoch 43/300\n",
      "2025-03-16 20:34:58,901 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.115561\n",
      "2025-03-16 20:34:58,901 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125962\n",
      "Training progress:  14%|█▍        | 43/300 [00:15<01:36,  2.65it/s]2025-03-16 20:34:59,256 - sciml.model.deeponet.deeponet - INFO - Epoch 44/300\n",
      "2025-03-16 20:34:59,257 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114589\n",
      "2025-03-16 20:34:59,257 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125508\n",
      "Training progress:  15%|█▍        | 44/300 [00:16<01:34,  2.70it/s]2025-03-16 20:34:59,609 - sciml.model.deeponet.deeponet - INFO - Epoch 45/300\n",
      "2025-03-16 20:34:59,610 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114688\n",
      "2025-03-16 20:34:59,610 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125453\n",
      "Training progress:  15%|█▌        | 45/300 [00:16<01:33,  2.74it/s]2025-03-16 20:34:59,974 - sciml.model.deeponet.deeponet - INFO - Epoch 46/300\n",
      "2025-03-16 20:34:59,975 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114383\n",
      "2025-03-16 20:34:59,975 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.124005\n",
      "Training progress:  15%|█▌        | 46/300 [00:16<01:32,  2.74it/s]2025-03-16 20:35:00,330 - sciml.model.deeponet.deeponet - INFO - Epoch 47/300\n",
      "2025-03-16 20:35:00,331 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.112683\n",
      "2025-03-16 20:35:00,332 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121064\n",
      "Training progress:  16%|█▌        | 47/300 [00:17<01:31,  2.76it/s]2025-03-16 20:35:00,684 - sciml.model.deeponet.deeponet - INFO - Epoch 48/300\n",
      "2025-03-16 20:35:00,685 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108730\n",
      "2025-03-16 20:35:00,685 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.122844\n",
      "Training progress:  16%|█▌        | 48/300 [00:17<01:30,  2.78it/s]2025-03-16 20:35:01,045 - sciml.model.deeponet.deeponet - INFO - Epoch 49/300\n",
      "2025-03-16 20:35:01,046 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.111322\n",
      "2025-03-16 20:35:01,046 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.123596\n",
      "Training progress:  16%|█▋        | 49/300 [00:18<01:30,  2.78it/s]2025-03-16 20:35:01,399 - sciml.model.deeponet.deeponet - INFO - Epoch 50/300\n",
      "2025-03-16 20:35:01,399 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.111306\n",
      "2025-03-16 20:35:01,400 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.119149\n",
      "Training progress:  17%|█▋        | 50/300 [00:18<01:29,  2.79it/s]2025-03-16 20:35:01,753 - sciml.model.deeponet.deeponet - INFO - Epoch 51/300\n",
      "2025-03-16 20:35:01,754 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106263\n",
      "2025-03-16 20:35:01,755 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121476\n",
      "Training progress:  17%|█▋        | 51/300 [00:18<01:28,  2.80it/s]2025-03-16 20:34:59,173 - sciml.model.deeponet.deeponet - INFO - Epoch 52/300\n",
      "2025-03-16 20:34:59,174 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.110946\n",
      "2025-03-16 20:34:59,174 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.118327\n",
      "2025-03-16 20:34:59,523 - sciml.model.deeponet.deeponet - INFO - Epoch 53/300\n",
      "2025-03-16 20:34:59,524 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104866\n",
      "2025-03-16 20:34:59,525 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.120131\n",
      "2025-03-16 20:34:59,879 - sciml.model.deeponet.deeponet - INFO - Epoch 54/300\n",
      "2025-03-16 20:34:59,880 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106180\n",
      "2025-03-16 20:34:59,880 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.117299\n",
      "2025-03-16 20:35:00,240 - sciml.model.deeponet.deeponet - INFO - Epoch 55/300\n",
      "2025-03-16 20:35:00,241 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104214\n",
      "2025-03-16 20:35:00,242 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115539\n",
      "2025-03-16 20:35:00,603 - sciml.model.deeponet.deeponet - INFO - Epoch 56/300\n",
      "2025-03-16 20:35:00,603 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102060\n",
      "2025-03-16 20:35:00,604 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116061\n",
      "2025-03-16 20:35:01,063 - sciml.model.deeponet.deeponet - INFO - Epoch 57/300\n",
      "2025-03-16 20:35:01,063 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102194\n",
      "2025-03-16 20:35:01,064 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113916\n",
      "2025-03-16 20:35:01,459 - sciml.model.deeponet.deeponet - INFO - Epoch 58/300\n",
      "2025-03-16 20:35:01,460 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101218\n",
      "2025-03-16 20:35:01,460 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112148\n",
      "2025-03-16 20:35:01,809 - sciml.model.deeponet.deeponet - INFO - Epoch 59/300\n",
      "2025-03-16 20:35:01,810 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100747\n",
      "2025-03-16 20:35:01,810 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111358\n",
      "2025-03-16 20:35:02,163 - sciml.model.deeponet.deeponet - INFO - Epoch 60/300\n",
      "2025-03-16 20:35:02,164 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098172\n",
      "2025-03-16 20:35:02,165 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112403\n",
      "Training progress:  20%|██        | 60/300 [00:19<00:26,  9.12it/s]2025-03-16 20:35:02,525 - sciml.model.deeponet.deeponet - INFO - Epoch 61/300\n",
      "2025-03-16 20:35:02,526 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098961\n",
      "2025-03-16 20:35:02,527 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109996\n",
      "Training progress:  20%|██        | 61/300 [00:19<00:32,  7.25it/s]2025-03-16 20:35:02,892 - sciml.model.deeponet.deeponet - INFO - Epoch 62/300\n",
      "2025-03-16 20:35:02,893 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097998\n",
      "2025-03-16 20:35:02,894 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106817\n",
      "Training progress:  21%|██        | 62/300 [00:19<00:40,  5.90it/s]2025-03-16 20:35:03,249 - sciml.model.deeponet.deeponet - INFO - Epoch 63/300\n",
      "2025-03-16 20:35:03,250 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096718\n",
      "2025-03-16 20:35:03,251 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105794\n",
      "Training progress:  21%|██        | 63/300 [00:20<00:47,  4.99it/s]2025-03-16 20:35:03,613 - sciml.model.deeponet.deeponet - INFO - Epoch 64/300\n",
      "2025-03-16 20:35:03,614 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096278\n",
      "2025-03-16 20:35:03,614 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106170\n",
      "Training progress:  21%|██▏       | 64/300 [00:20<00:54,  4.32it/s]2025-03-16 20:35:03,985 - sciml.model.deeponet.deeponet - INFO - Epoch 65/300\n",
      "2025-03-16 20:35:03,986 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095871\n",
      "2025-03-16 20:35:03,987 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106173\n",
      "Training progress:  22%|██▏       | 65/300 [00:21<01:01,  3.82it/s]2025-03-16 20:35:04,351 - sciml.model.deeponet.deeponet - INFO - Epoch 66/300\n",
      "2025-03-16 20:35:04,352 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094833\n",
      "2025-03-16 20:35:04,353 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106024\n",
      "Training progress:  22%|██▏       | 66/300 [00:21<01:06,  3.49it/s]2025-03-16 20:35:04,732 - sciml.model.deeponet.deeponet - INFO - Epoch 67/300\n",
      "2025-03-16 20:35:04,733 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094401\n",
      "2025-03-16 20:35:04,734 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105715\n",
      "Training progress:  22%|██▏       | 67/300 [00:21<01:12,  3.23it/s]2025-03-16 20:35:05,088 - sciml.model.deeponet.deeponet - INFO - Epoch 68/300\n",
      "2025-03-16 20:35:05,088 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093865\n",
      "2025-03-16 20:35:05,089 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104236\n",
      "Training progress:  23%|██▎       | 68/300 [00:22<01:14,  3.11it/s]2025-03-16 20:35:05,442 - sciml.model.deeponet.deeponet - INFO - Epoch 69/300\n",
      "2025-03-16 20:35:05,443 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093043\n",
      "2025-03-16 20:35:05,443 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102274\n",
      "Training progress:  23%|██▎       | 69/300 [00:22<01:16,  3.02it/s]2025-03-16 20:35:05,801 - sciml.model.deeponet.deeponet - INFO - Epoch 70/300\n",
      "2025-03-16 20:35:05,802 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092923\n",
      "2025-03-16 20:35:05,803 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101470\n",
      "Training progress:  23%|██▎       | 70/300 [00:22<01:17,  2.95it/s]2025-03-16 20:35:06,155 - sciml.model.deeponet.deeponet - INFO - Epoch 71/300\n",
      "2025-03-16 20:35:06,156 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092230\n",
      "2025-03-16 20:35:06,157 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102363\n",
      "Training progress:  24%|██▎       | 71/300 [00:23<01:18,  2.91it/s]2025-03-16 20:35:06,501 - sciml.model.deeponet.deeponet - INFO - Epoch 72/300\n",
      "2025-03-16 20:35:06,502 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091453\n",
      "2025-03-16 20:35:06,503 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103085\n",
      "Training progress:  24%|██▍       | 72/300 [00:23<01:18,  2.91it/s]2025-03-16 20:35:06,871 - sciml.model.deeponet.deeponet - INFO - Epoch 73/300\n",
      "2025-03-16 20:35:06,872 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091526\n",
      "2025-03-16 20:35:06,872 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101743\n",
      "Training progress:  24%|██▍       | 73/300 [00:23<01:19,  2.85it/s]2025-03-16 20:35:07,239 - sciml.model.deeponet.deeponet - INFO - Epoch 74/300\n",
      "2025-03-16 20:35:07,240 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090891\n",
      "2025-03-16 20:35:07,241 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100191\n",
      "Training progress:  25%|██▍       | 74/300 [00:24<01:20,  2.80it/s]2025-03-16 20:35:07,603 - sciml.model.deeponet.deeponet - INFO - Epoch 75/300\n",
      "2025-03-16 20:35:07,604 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090370\n",
      "2025-03-16 20:35:07,604 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099437\n",
      "Training progress:  25%|██▌       | 75/300 [00:24<01:20,  2.79it/s]2025-03-16 20:35:07,950 - sciml.model.deeponet.deeponet - INFO - Epoch 76/300\n",
      "2025-03-16 20:35:07,951 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090095\n",
      "2025-03-16 20:35:07,952 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099142\n",
      "Training progress:  25%|██▌       | 76/300 [00:24<01:19,  2.82it/s]2025-03-16 20:35:08,333 - sciml.model.deeponet.deeponet - INFO - Epoch 77/300\n",
      "2025-03-16 20:35:08,334 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089703\n",
      "2025-03-16 20:35:08,335 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099446\n",
      "Training progress:  26%|██▌       | 77/300 [00:25<01:21,  2.75it/s]2025-03-16 20:35:08,715 - sciml.model.deeponet.deeponet - INFO - Epoch 78/300\n",
      "2025-03-16 20:35:08,716 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089418\n",
      "2025-03-16 20:35:08,716 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099355\n",
      "Training progress:  26%|██▌       | 78/300 [00:25<01:21,  2.71it/s]2025-03-16 20:35:09,093 - sciml.model.deeponet.deeponet - INFO - Epoch 79/300\n",
      "2025-03-16 20:35:09,094 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088945\n",
      "2025-03-16 20:35:09,095 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098608\n",
      "Training progress:  26%|██▋       | 79/300 [00:26<01:22,  2.69it/s]2025-03-16 20:35:09,452 - sciml.model.deeponet.deeponet - INFO - Epoch 80/300\n",
      "2025-03-16 20:35:09,453 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088730\n",
      "2025-03-16 20:35:09,453 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097358\n",
      "Training progress:  27%|██▋       | 80/300 [00:26<01:20,  2.72it/s]2025-03-16 20:35:09,813 - sciml.model.deeponet.deeponet - INFO - Epoch 81/300\n",
      "2025-03-16 20:35:09,814 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088286\n",
      "2025-03-16 20:35:09,815 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096852\n",
      "Training progress:  27%|██▋       | 81/300 [00:26<01:20,  2.73it/s]2025-03-16 20:35:10,228 - sciml.model.deeponet.deeponet - INFO - Epoch 82/300\n",
      "2025-03-16 20:35:10,230 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088000\n",
      "2025-03-16 20:35:10,230 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096361\n",
      "Training progress:  27%|██▋       | 82/300 [00:27<01:22,  2.63it/s]2025-03-16 20:35:10,609 - sciml.model.deeponet.deeponet - INFO - Epoch 83/300\n",
      "2025-03-16 20:35:10,610 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087650\n",
      "2025-03-16 20:35:10,611 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096201\n",
      "Training progress:  28%|██▊       | 83/300 [00:27<01:22,  2.63it/s]2025-03-16 20:35:10,962 - sciml.model.deeponet.deeponet - INFO - Epoch 84/300\n",
      "2025-03-16 20:35:10,963 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087362\n",
      "2025-03-16 20:35:10,964 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096274\n",
      "Training progress:  28%|██▊       | 84/300 [00:27<01:20,  2.69it/s]2025-03-16 20:35:11,380 - sciml.model.deeponet.deeponet - INFO - Epoch 85/300\n",
      "2025-03-16 20:35:11,381 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087063\n",
      "2025-03-16 20:35:11,381 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095679\n",
      "Training progress:  28%|██▊       | 85/300 [00:28<01:23,  2.59it/s]2025-03-16 20:35:11,758 - sciml.model.deeponet.deeponet - INFO - Epoch 86/300\n",
      "2025-03-16 20:35:11,759 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086750\n",
      "2025-03-16 20:35:11,760 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095678\n",
      "Training progress:  29%|██▊       | 86/300 [00:28<01:22,  2.61it/s]2025-03-16 20:35:12,132 - sciml.model.deeponet.deeponet - INFO - Epoch 87/300\n",
      "2025-03-16 20:35:12,133 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086555\n",
      "2025-03-16 20:35:12,135 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094591\n",
      "Training progress:  29%|██▉       | 87/300 [00:29<01:21,  2.63it/s]2025-03-16 20:35:12,491 - sciml.model.deeponet.deeponet - INFO - Epoch 88/300\n",
      "2025-03-16 20:35:12,492 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086342\n",
      "2025-03-16 20:35:12,492 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095189\n",
      "Training progress:  29%|██▉       | 88/300 [00:29<01:19,  2.67it/s]2025-03-16 20:35:12,861 - sciml.model.deeponet.deeponet - INFO - Epoch 89/300\n",
      "2025-03-16 20:35:12,862 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086462\n",
      "2025-03-16 20:35:12,863 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096497\n",
      "Training progress:  30%|██▉       | 89/300 [00:29<01:18,  2.68it/s]2025-03-16 20:35:13,315 - sciml.model.deeponet.deeponet - INFO - Epoch 90/300\n",
      "2025-03-16 20:35:13,317 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088487\n",
      "2025-03-16 20:35:13,318 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101194\n",
      "Training progress:  30%|███       | 90/300 [00:30<01:23,  2.52it/s]2025-03-16 20:35:13,791 - sciml.model.deeponet.deeponet - INFO - Epoch 91/300\n",
      "2025-03-16 20:35:13,792 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093433\n",
      "2025-03-16 20:35:13,793 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107891\n",
      "Training progress:  30%|███       | 91/300 [00:30<01:27,  2.38it/s]2025-03-16 20:35:14,174 - sciml.model.deeponet.deeponet - INFO - Epoch 92/300\n",
      "2025-03-16 20:35:14,175 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100696\n",
      "2025-03-16 20:35:14,176 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093663\n",
      "Training progress:  31%|███       | 92/300 [00:31<01:25,  2.44it/s]2025-03-16 20:35:14,542 - sciml.model.deeponet.deeponet - INFO - Epoch 93/300\n",
      "2025-03-16 20:35:14,543 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086071\n",
      "2025-03-16 20:35:14,543 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107078\n",
      "Training progress:  31%|███       | 93/300 [00:31<01:22,  2.52it/s]2025-03-16 20:35:14,900 - sciml.model.deeponet.deeponet - INFO - Epoch 94/300\n",
      "2025-03-16 20:35:14,900 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102752\n",
      "2025-03-16 20:35:14,901 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106024\n",
      "Training progress:  31%|███▏      | 94/300 [00:31<01:19,  2.60it/s]2025-03-16 20:35:15,283 - sciml.model.deeponet.deeponet - INFO - Epoch 95/300\n",
      "2025-03-16 20:35:15,283 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098922\n",
      "2025-03-16 20:35:15,284 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104209\n",
      "Training progress:  32%|███▏      | 95/300 [00:32<01:18,  2.60it/s]2025-03-16 20:35:15,662 - sciml.model.deeponet.deeponet - INFO - Epoch 96/300\n",
      "2025-03-16 20:35:15,663 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098013\n",
      "2025-03-16 20:35:15,663 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103909\n",
      "Training progress:  32%|███▏      | 96/300 [00:32<01:18,  2.61it/s]2025-03-16 20:35:16,040 - sciml.model.deeponet.deeponet - INFO - Epoch 97/300\n",
      "2025-03-16 20:35:16,040 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097361\n",
      "2025-03-16 20:35:16,041 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098527\n",
      "Training progress:  32%|███▏      | 97/300 [00:33<01:17,  2.62it/s]2025-03-16 20:35:16,408 - sciml.model.deeponet.deeponet - INFO - Epoch 98/300\n",
      "2025-03-16 20:35:16,409 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089092\n",
      "2025-03-16 20:35:16,409 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097688\n",
      "Training progress:  33%|███▎      | 98/300 [00:33<01:16,  2.65it/s]2025-03-16 20:35:16,797 - sciml.model.deeponet.deeponet - INFO - Epoch 99/300\n",
      "2025-03-16 20:35:16,797 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091054\n",
      "2025-03-16 20:35:16,798 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099799\n",
      "Training progress:  33%|███▎      | 99/300 [00:33<01:16,  2.63it/s]2025-03-16 20:35:17,161 - sciml.model.deeponet.deeponet - INFO - Epoch 100/300\n",
      "2025-03-16 20:35:17,161 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090658\n",
      "2025-03-16 20:35:17,162 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100536\n",
      "Training progress:  33%|███▎      | 100/300 [00:34<01:15,  2.66it/s]2025-03-16 20:35:17,533 - sciml.model.deeponet.deeponet - INFO - Epoch 101/300\n",
      "2025-03-16 20:35:17,534 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092361\n",
      "2025-03-16 20:35:17,535 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093397\n",
      "Training progress:  34%|███▎      | 101/300 [00:34<01:14,  2.67it/s]2025-03-16 20:35:17,894 - sciml.model.deeponet.deeponet - INFO - Epoch 102/300\n",
      "2025-03-16 20:35:17,894 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087995\n",
      "2025-03-16 20:35:17,895 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093499\n",
      "Training progress:  34%|███▍      | 102/300 [00:34<01:13,  2.70it/s]2025-03-16 20:35:18,242 - sciml.model.deeponet.deeponet - INFO - Epoch 103/300\n",
      "2025-03-16 20:35:18,243 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089662\n",
      "2025-03-16 20:35:18,243 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097305\n",
      "Training progress:  34%|███▍      | 103/300 [00:35<01:11,  2.75it/s]2025-03-16 20:35:18,587 - sciml.model.deeponet.deeponet - INFO - Epoch 104/300\n",
      "2025-03-16 20:35:18,587 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088054\n",
      "2025-03-16 20:35:18,588 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100699\n",
      "Training progress:  35%|███▍      | 104/300 [00:35<01:10,  2.79it/s]2025-03-16 20:35:18,941 - sciml.model.deeponet.deeponet - INFO - Epoch 105/300\n",
      "2025-03-16 20:35:18,942 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088928\n",
      "2025-03-16 20:35:18,942 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098727\n",
      "Training progress:  35%|███▌      | 105/300 [00:35<01:09,  2.80it/s]2025-03-16 20:35:19,311 - sciml.model.deeponet.deeponet - INFO - Epoch 106/300\n",
      "2025-03-16 20:35:19,312 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086725\n",
      "2025-03-16 20:35:19,312 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097737\n",
      "Training progress:  35%|███▌      | 106/300 [00:36<01:09,  2.77it/s]2025-03-16 20:35:19,675 - sciml.model.deeponet.deeponet - INFO - Epoch 107/300\n",
      "2025-03-16 20:35:19,675 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088059\n",
      "2025-03-16 20:35:19,676 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096434\n",
      "Training progress:  36%|███▌      | 107/300 [00:36<01:09,  2.77it/s]2025-03-16 20:35:20,033 - sciml.model.deeponet.deeponet - INFO - Epoch 108/300\n",
      "2025-03-16 20:35:20,034 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086042\n",
      "2025-03-16 20:35:20,035 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094608\n",
      "Training progress:  36%|███▌      | 108/300 [00:37<01:09,  2.77it/s]2025-03-16 20:35:20,398 - sciml.model.deeponet.deeponet - INFO - Epoch 109/300\n",
      "2025-03-16 20:35:20,399 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086737\n",
      "2025-03-16 20:35:20,399 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090587\n",
      "Training progress:  36%|███▋      | 109/300 [00:37<01:09,  2.76it/s]2025-03-16 20:35:20,747 - sciml.model.deeponet.deeponet - INFO - Epoch 110/300\n",
      "2025-03-16 20:35:20,747 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085381\n",
      "2025-03-16 20:35:20,748 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090496\n",
      "Training progress:  37%|███▋      | 110/300 [00:37<01:08,  2.79it/s]2025-03-16 20:35:21,102 - sciml.model.deeponet.deeponet - INFO - Epoch 111/300\n",
      "2025-03-16 20:35:21,103 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086527\n",
      "2025-03-16 20:35:21,104 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093297\n",
      "Training progress:  37%|███▋      | 111/300 [00:38<01:07,  2.80it/s]2025-03-16 20:35:21,452 - sciml.model.deeponet.deeponet - INFO - Epoch 112/300\n",
      "2025-03-16 20:35:21,452 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084658\n",
      "2025-03-16 20:35:21,453 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096561\n",
      "Training progress:  37%|███▋      | 112/300 [00:38<01:06,  2.82it/s]2025-03-16 20:35:21,803 - sciml.model.deeponet.deeponet - INFO - Epoch 113/300\n",
      "2025-03-16 20:35:21,804 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085681\n",
      "2025-03-16 20:35:21,804 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094642\n",
      "Training progress:  38%|███▊      | 113/300 [00:38<01:06,  2.83it/s]2025-03-16 20:35:22,166 - sciml.model.deeponet.deeponet - INFO - Epoch 114/300\n",
      "2025-03-16 20:35:22,167 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084164\n",
      "2025-03-16 20:35:22,168 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092456\n",
      "Training progress:  38%|███▊      | 114/300 [00:39<01:06,  2.80it/s]2025-03-16 20:35:22,533 - sciml.model.deeponet.deeponet - INFO - Epoch 115/300\n",
      "2025-03-16 20:35:22,534 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084846\n",
      "2025-03-16 20:35:22,534 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091669\n",
      "Training progress:  38%|███▊      | 115/300 [00:39<01:06,  2.78it/s]2025-03-16 20:35:22,894 - sciml.model.deeponet.deeponet - INFO - Epoch 116/300\n",
      "2025-03-16 20:35:22,895 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083895\n",
      "2025-03-16 20:35:22,896 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092790\n",
      "Training progress:  39%|███▊      | 116/300 [00:39<01:06,  2.78it/s]2025-03-16 20:35:23,261 - sciml.model.deeponet.deeponet - INFO - Epoch 117/300\n",
      "2025-03-16 20:35:23,262 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084368\n",
      "2025-03-16 20:35:23,262 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091914\n",
      "Training progress:  39%|███▉      | 117/300 [00:40<01:06,  2.76it/s]2025-03-16 20:35:23,617 - sciml.model.deeponet.deeponet - INFO - Epoch 118/300\n",
      "2025-03-16 20:35:23,618 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083146\n",
      "2025-03-16 20:35:23,619 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091720\n",
      "Training progress:  39%|███▉      | 118/300 [00:40<01:05,  2.77it/s]2025-03-16 20:35:23,970 - sciml.model.deeponet.deeponet - INFO - Epoch 119/300\n",
      "2025-03-16 20:35:23,971 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083713\n",
      "2025-03-16 20:35:23,972 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092168\n",
      "Training progress:  40%|███▉      | 119/300 [00:40<01:04,  2.79it/s]2025-03-16 20:35:24,354 - sciml.model.deeponet.deeponet - INFO - Epoch 120/300\n",
      "2025-03-16 20:35:24,354 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083305\n",
      "2025-03-16 20:35:24,355 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091980\n",
      "Training progress:  40%|████      | 120/300 [00:41<01:05,  2.74it/s]2025-03-16 20:35:24,708 - sciml.model.deeponet.deeponet - INFO - Epoch 121/300\n",
      "2025-03-16 20:35:24,709 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082770\n",
      "2025-03-16 20:35:24,709 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090291\n",
      "Training progress:  40%|████      | 121/300 [00:41<01:04,  2.76it/s]2025-03-16 20:35:25,065 - sciml.model.deeponet.deeponet - INFO - Epoch 122/300\n",
      "2025-03-16 20:35:25,065 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082512\n",
      "2025-03-16 20:35:25,066 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088806\n",
      "Training progress:  41%|████      | 122/300 [00:42<01:04,  2.77it/s]2025-03-16 20:35:25,412 - sciml.model.deeponet.deeponet - INFO - Epoch 123/300\n",
      "2025-03-16 20:35:25,413 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082851\n",
      "2025-03-16 20:35:25,413 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089318\n",
      "Training progress:  41%|████      | 123/300 [00:42<01:03,  2.80it/s]2025-03-16 20:35:25,771 - sciml.model.deeponet.deeponet - INFO - Epoch 124/300\n",
      "2025-03-16 20:35:25,772 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082379\n",
      "2025-03-16 20:35:25,772 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091059\n",
      "Training progress:  41%|████▏     | 124/300 [00:42<01:02,  2.80it/s]2025-03-16 20:35:26,121 - sciml.model.deeponet.deeponet - INFO - Epoch 125/300\n",
      "2025-03-16 20:35:26,123 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082096\n",
      "2025-03-16 20:35:26,124 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091437\n",
      "Training progress:  42%|████▏     | 125/300 [00:43<01:02,  2.81it/s]2025-03-16 20:35:26,521 - sciml.model.deeponet.deeponet - INFO - Epoch 126/300\n",
      "2025-03-16 20:35:26,522 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081872\n",
      "2025-03-16 20:35:26,523 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090440\n",
      "Training progress:  42%|████▏     | 126/300 [00:43<01:04,  2.71it/s]2025-03-16 20:35:26,914 - sciml.model.deeponet.deeponet - INFO - Epoch 127/300\n",
      "2025-03-16 20:35:26,915 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081979\n",
      "2025-03-16 20:35:26,916 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089822\n",
      "Training progress:  42%|████▏     | 127/300 [00:43<01:05,  2.66it/s]2025-03-16 20:35:27,280 - sciml.model.deeponet.deeponet - INFO - Epoch 128/300\n",
      "2025-03-16 20:35:27,281 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081511\n",
      "2025-03-16 20:35:27,282 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089927\n",
      "Training progress:  43%|████▎     | 128/300 [00:44<01:04,  2.68it/s]2025-03-16 20:35:27,643 - sciml.model.deeponet.deeponet - INFO - Epoch 129/300\n",
      "2025-03-16 20:35:27,643 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081544\n",
      "2025-03-16 20:35:27,644 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089411\n",
      "Training progress:  43%|████▎     | 129/300 [00:44<01:03,  2.70it/s]2025-03-16 20:35:28,007 - sciml.model.deeponet.deeponet - INFO - Epoch 130/300\n",
      "2025-03-16 20:35:28,008 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081256\n",
      "2025-03-16 20:35:28,008 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089370\n",
      "Training progress:  43%|████▎     | 130/300 [00:45<01:02,  2.72it/s]2025-03-16 20:35:28,382 - sciml.model.deeponet.deeponet - INFO - Epoch 131/300\n",
      "2025-03-16 20:35:28,383 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081217\n",
      "2025-03-16 20:35:28,383 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090214\n",
      "Training progress:  44%|████▎     | 131/300 [00:45<01:02,  2.70it/s]2025-03-16 20:35:28,797 - sciml.model.deeponet.deeponet - INFO - Epoch 132/300\n",
      "2025-03-16 20:35:28,798 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080926\n",
      "2025-03-16 20:35:28,799 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089910\n",
      "Training progress:  44%|████▍     | 132/300 [00:45<01:04,  2.61it/s]2025-03-16 20:35:29,190 - sciml.model.deeponet.deeponet - INFO - Epoch 133/300\n",
      "2025-03-16 20:35:29,191 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080875\n",
      "2025-03-16 20:35:29,191 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088338\n",
      "Training progress:  44%|████▍     | 133/300 [00:46<01:04,  2.59it/s]2025-03-16 20:35:29,577 - sciml.model.deeponet.deeponet - INFO - Epoch 134/300\n",
      "2025-03-16 20:35:29,578 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080718\n",
      "2025-03-16 20:35:29,578 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087756\n",
      "Training progress:  45%|████▍     | 134/300 [00:46<01:04,  2.59it/s]2025-03-16 20:35:29,948 - sciml.model.deeponet.deeponet - INFO - Epoch 135/300\n",
      "2025-03-16 20:35:29,948 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080570\n",
      "2025-03-16 20:35:29,949 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088751\n",
      "Training progress:  45%|████▌     | 135/300 [00:46<01:02,  2.62it/s]2025-03-16 20:35:30,313 - sciml.model.deeponet.deeponet - INFO - Epoch 136/300\n",
      "2025-03-16 20:35:30,313 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080423\n",
      "2025-03-16 20:35:30,314 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089174\n",
      "Training progress:  45%|████▌     | 136/300 [00:47<01:01,  2.65it/s]2025-03-16 20:35:30,683 - sciml.model.deeponet.deeponet - INFO - Epoch 137/300\n",
      "2025-03-16 20:35:30,683 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080288\n",
      "2025-03-16 20:35:30,684 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088925\n",
      "Training progress:  46%|████▌     | 137/300 [00:47<01:01,  2.67it/s]2025-03-16 20:35:31,066 - sciml.model.deeponet.deeponet - INFO - Epoch 138/300\n",
      "2025-03-16 20:35:31,067 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080202\n",
      "2025-03-16 20:35:31,068 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088778\n",
      "Training progress:  46%|████▌     | 138/300 [00:48<01:01,  2.65it/s]2025-03-16 20:35:28,504 - sciml.model.deeponet.deeponet - INFO - Epoch 139/300\n",
      "2025-03-16 20:35:28,504 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079983\n",
      "2025-03-16 20:35:28,505 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088535\n",
      "2025-03-16 20:35:28,870 - sciml.model.deeponet.deeponet - INFO - Epoch 140/300\n",
      "2025-03-16 20:35:28,871 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079975\n",
      "2025-03-16 20:35:28,872 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087996\n",
      "2025-03-16 20:35:29,246 - sciml.model.deeponet.deeponet - INFO - Epoch 141/300\n",
      "2025-03-16 20:35:29,247 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079796\n",
      "2025-03-16 20:35:29,248 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088612\n",
      "2025-03-16 20:35:29,622 - sciml.model.deeponet.deeponet - INFO - Epoch 142/300\n",
      "2025-03-16 20:35:29,622 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079620\n",
      "2025-03-16 20:35:29,623 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089116\n",
      "2025-03-16 20:35:30,008 - sciml.model.deeponet.deeponet - INFO - Epoch 143/300\n",
      "2025-03-16 20:35:30,009 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079594\n",
      "2025-03-16 20:35:30,009 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088211\n",
      "2025-03-16 20:35:30,380 - sciml.model.deeponet.deeponet - INFO - Epoch 144/300\n",
      "2025-03-16 20:35:30,381 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079414\n",
      "2025-03-16 20:35:30,381 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087691\n",
      "2025-03-16 20:35:30,744 - sciml.model.deeponet.deeponet - INFO - Epoch 145/300\n",
      "2025-03-16 20:35:30,745 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079306\n",
      "2025-03-16 20:35:30,745 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088271\n",
      "2025-03-16 20:35:31,110 - sciml.model.deeponet.deeponet - INFO - Epoch 146/300\n",
      "2025-03-16 20:35:31,111 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079204\n",
      "2025-03-16 20:35:31,111 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088226\n",
      "2025-03-16 20:35:31,467 - sciml.model.deeponet.deeponet - INFO - Epoch 147/300\n",
      "2025-03-16 20:35:31,468 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079075\n",
      "2025-03-16 20:35:31,468 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087835\n",
      "Training progress:  49%|████▉     | 147/300 [00:48<00:17,  8.85it/s]2025-03-16 20:35:31,810 - sciml.model.deeponet.deeponet - INFO - Epoch 148/300\n",
      "2025-03-16 20:35:31,811 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078969\n",
      "2025-03-16 20:35:31,812 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087862\n",
      "Training progress:  49%|████▉     | 148/300 [00:48<00:21,  7.20it/s]2025-03-16 20:35:32,162 - sciml.model.deeponet.deeponet - INFO - Epoch 149/300\n",
      "2025-03-16 20:35:32,163 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078882\n",
      "2025-03-16 20:35:32,164 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087511\n",
      "Training progress:  50%|████▉     | 149/300 [00:49<00:25,  5.94it/s]2025-03-16 20:35:32,520 - sciml.model.deeponet.deeponet - INFO - Epoch 150/300\n",
      "2025-03-16 20:35:32,521 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078740\n",
      "2025-03-16 20:35:32,522 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087624\n",
      "Training progress:  50%|█████     | 150/300 [00:49<00:29,  5.01it/s]2025-03-16 20:35:32,890 - sciml.model.deeponet.deeponet - INFO - Epoch 151/300\n",
      "2025-03-16 20:35:32,891 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078648\n",
      "2025-03-16 20:35:32,891 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088105\n",
      "Training progress:  50%|█████     | 151/300 [00:49<00:34,  4.31it/s]2025-03-16 20:35:33,247 - sciml.model.deeponet.deeponet - INFO - Epoch 152/300\n",
      "2025-03-16 20:35:33,248 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078571\n",
      "2025-03-16 20:35:33,248 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087210\n",
      "Training progress:  51%|█████     | 152/300 [00:50<00:38,  3.87it/s]2025-03-16 20:35:33,595 - sciml.model.deeponet.deeponet - INFO - Epoch 153/300\n",
      "2025-03-16 20:35:33,596 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078434\n",
      "2025-03-16 20:35:33,596 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087160\n",
      "Training progress:  51%|█████     | 153/300 [00:50<00:41,  3.58it/s]2025-03-16 20:35:33,971 - sciml.model.deeponet.deeponet - INFO - Epoch 154/300\n",
      "2025-03-16 20:35:33,972 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078329\n",
      "2025-03-16 20:35:33,972 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087706\n",
      "Training progress:  51%|█████▏    | 154/300 [00:50<00:44,  3.29it/s]2025-03-16 20:35:34,342 - sciml.model.deeponet.deeponet - INFO - Epoch 155/300\n",
      "2025-03-16 20:35:34,343 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078245\n",
      "2025-03-16 20:35:34,344 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087197\n",
      "Training progress:  52%|█████▏    | 155/300 [00:51<00:46,  3.11it/s]2025-03-16 20:35:34,705 - sciml.model.deeponet.deeponet - INFO - Epoch 156/300\n",
      "2025-03-16 20:35:34,706 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078150\n",
      "2025-03-16 20:35:34,708 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087336\n",
      "Training progress:  52%|█████▏    | 156/300 [00:51<00:47,  3.00it/s]2025-03-16 20:35:35,072 - sciml.model.deeponet.deeponet - INFO - Epoch 157/300\n",
      "2025-03-16 20:35:35,072 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078026\n",
      "2025-03-16 20:35:35,073 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086994\n",
      "Training progress:  52%|█████▏    | 157/300 [00:52<00:48,  2.92it/s]2025-03-16 20:35:35,428 - sciml.model.deeponet.deeponet - INFO - Epoch 158/300\n",
      "2025-03-16 20:35:35,429 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077921\n",
      "2025-03-16 20:35:35,430 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086993\n",
      "Training progress:  53%|█████▎    | 158/300 [00:52<00:49,  2.89it/s]2025-03-16 20:35:35,798 - sciml.model.deeponet.deeponet - INFO - Epoch 159/300\n",
      "2025-03-16 20:35:35,799 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077830\n",
      "2025-03-16 20:35:35,800 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087501\n",
      "Training progress:  53%|█████▎    | 159/300 [00:52<00:49,  2.83it/s]2025-03-16 20:35:36,155 - sciml.model.deeponet.deeponet - INFO - Epoch 160/300\n",
      "2025-03-16 20:35:36,156 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077756\n",
      "2025-03-16 20:35:36,157 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086542\n",
      "Training progress:  53%|█████▎    | 160/300 [00:53<00:49,  2.82it/s]2025-03-16 20:35:36,521 - sciml.model.deeponet.deeponet - INFO - Epoch 161/300\n",
      "2025-03-16 20:35:36,522 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077669\n",
      "2025-03-16 20:35:36,522 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087066\n",
      "Training progress:  54%|█████▎    | 161/300 [00:53<00:49,  2.80it/s]2025-03-16 20:35:36,910 - sciml.model.deeponet.deeponet - INFO - Epoch 162/300\n",
      "2025-03-16 20:35:36,911 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077584\n",
      "2025-03-16 20:35:36,912 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086558\n",
      "Training progress:  54%|█████▍    | 162/300 [00:53<00:50,  2.72it/s]2025-03-16 20:35:37,271 - sciml.model.deeponet.deeponet - INFO - Epoch 163/300\n",
      "2025-03-16 20:35:37,272 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077477\n",
      "2025-03-16 20:35:37,273 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086953\n",
      "Training progress:  54%|█████▍    | 163/300 [00:54<00:50,  2.74it/s]2025-03-16 20:35:37,632 - sciml.model.deeponet.deeponet - INFO - Epoch 164/300\n",
      "2025-03-16 20:35:37,633 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077377\n",
      "2025-03-16 20:35:37,634 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086801\n",
      "Training progress:  55%|█████▍    | 164/300 [00:54<00:49,  2.75it/s]2025-03-16 20:35:37,988 - sciml.model.deeponet.deeponet - INFO - Epoch 165/300\n",
      "2025-03-16 20:35:37,988 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077296\n",
      "2025-03-16 20:35:37,989 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086411\n",
      "Training progress:  55%|█████▌    | 165/300 [00:55<00:48,  2.77it/s]2025-03-16 20:35:38,341 - sciml.model.deeponet.deeponet - INFO - Epoch 166/300\n",
      "2025-03-16 20:35:38,342 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077257\n",
      "2025-03-16 20:35:38,342 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087256\n",
      "Training progress:  55%|█████▌    | 166/300 [00:55<00:48,  2.79it/s]2025-03-16 20:35:38,781 - sciml.model.deeponet.deeponet - INFO - Epoch 167/300\n",
      "2025-03-16 20:35:38,782 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077328\n",
      "2025-03-16 20:35:38,782 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085958\n",
      "Training progress:  56%|█████▌    | 167/300 [00:55<00:50,  2.61it/s]2025-03-16 20:35:39,133 - sciml.model.deeponet.deeponet - INFO - Epoch 168/300\n",
      "2025-03-16 20:35:39,134 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077546\n",
      "2025-03-16 20:35:39,135 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088147\n",
      "Training progress:  56%|█████▌    | 168/300 [00:56<00:49,  2.67it/s]2025-03-16 20:35:39,486 - sciml.model.deeponet.deeponet - INFO - Epoch 169/300\n",
      "2025-03-16 20:35:39,487 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078128\n",
      "2025-03-16 20:35:39,488 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086431\n",
      "Training progress:  56%|█████▋    | 169/300 [00:56<00:48,  2.72it/s]2025-03-16 20:35:39,848 - sciml.model.deeponet.deeponet - INFO - Epoch 170/300\n",
      "2025-03-16 20:35:39,849 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078116\n",
      "2025-03-16 20:35:39,850 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087831\n",
      "Training progress:  57%|█████▋    | 170/300 [00:56<00:47,  2.73it/s]2025-03-16 20:35:40,211 - sciml.model.deeponet.deeponet - INFO - Epoch 171/300\n",
      "2025-03-16 20:35:40,212 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078421\n",
      "2025-03-16 20:35:40,212 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089560\n",
      "Training progress:  57%|█████▋    | 171/300 [00:57<00:47,  2.74it/s]2025-03-16 20:35:40,570 - sciml.model.deeponet.deeponet - INFO - Epoch 172/300\n",
      "2025-03-16 20:35:40,571 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079524\n",
      "2025-03-16 20:35:40,572 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087003\n",
      "Training progress:  57%|█████▋    | 172/300 [00:57<00:46,  2.75it/s]2025-03-16 20:35:40,941 - sciml.model.deeponet.deeponet - INFO - Epoch 173/300\n",
      "2025-03-16 20:35:40,942 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079025\n",
      "2025-03-16 20:35:40,943 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090395\n",
      "Training progress:  58%|█████▊    | 173/300 [00:57<00:46,  2.74it/s]2025-03-16 20:35:41,300 - sciml.model.deeponet.deeponet - INFO - Epoch 174/300\n",
      "2025-03-16 20:35:41,301 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079271\n",
      "2025-03-16 20:35:41,301 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085565\n",
      "Training progress:  58%|█████▊    | 174/300 [00:58<00:45,  2.75it/s]2025-03-16 20:35:41,646 - sciml.model.deeponet.deeponet - INFO - Epoch 175/300\n",
      "2025-03-16 20:35:41,647 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077428\n",
      "2025-03-16 20:35:41,647 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087235\n",
      "Training progress:  58%|█████▊    | 175/300 [00:58<00:44,  2.79it/s]2025-03-16 20:35:41,998 - sciml.model.deeponet.deeponet - INFO - Epoch 176/300\n",
      "2025-03-16 20:35:41,999 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077075\n",
      "2025-03-16 20:35:42,000 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086741\n",
      "Training progress:  59%|█████▊    | 176/300 [00:59<00:44,  2.81it/s]2025-03-16 20:35:42,360 - sciml.model.deeponet.deeponet - INFO - Epoch 177/300\n",
      "2025-03-16 20:35:42,361 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077920\n",
      "2025-03-16 20:35:42,362 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088160\n",
      "Training progress:  59%|█████▉    | 177/300 [00:59<00:44,  2.79it/s]2025-03-16 20:35:42,741 - sciml.model.deeponet.deeponet - INFO - Epoch 178/300\n",
      "2025-03-16 20:35:42,742 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078854\n",
      "2025-03-16 20:35:42,743 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089672\n",
      "Training progress:  59%|█████▉    | 178/300 [00:59<00:44,  2.74it/s]2025-03-16 20:35:43,148 - sciml.model.deeponet.deeponet - INFO - Epoch 179/300\n",
      "2025-03-16 20:35:43,149 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080018\n",
      "2025-03-16 20:35:43,150 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086986\n",
      "Training progress:  60%|█████▉    | 179/300 [01:00<00:45,  2.65it/s]2025-03-16 20:35:43,552 - sciml.model.deeponet.deeponet - INFO - Epoch 180/300\n",
      "2025-03-16 20:35:43,553 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077382\n",
      "2025-03-16 20:35:43,554 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086268\n",
      "Training progress:  60%|██████    | 180/300 [01:00<00:46,  2.59it/s]2025-03-16 20:35:43,945 - sciml.model.deeponet.deeponet - INFO - Epoch 181/300\n",
      "2025-03-16 20:35:43,945 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076409\n",
      "2025-03-16 20:35:43,946 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088051\n",
      "Training progress:  60%|██████    | 181/300 [01:00<00:46,  2.58it/s]2025-03-16 20:35:44,331 - sciml.model.deeponet.deeponet - INFO - Epoch 182/300\n",
      "2025-03-16 20:35:44,332 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077623\n",
      "2025-03-16 20:35:44,333 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087121\n",
      "Training progress:  61%|██████    | 182/300 [01:01<00:45,  2.58it/s]2025-03-16 20:35:44,720 - sciml.model.deeponet.deeponet - INFO - Epoch 183/300\n",
      "2025-03-16 20:35:44,720 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078018\n",
      "2025-03-16 20:35:44,721 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087381\n",
      "Training progress:  61%|██████    | 183/300 [01:01<00:45,  2.58it/s]2025-03-16 20:35:45,108 - sciml.model.deeponet.deeponet - INFO - Epoch 184/300\n",
      "2025-03-16 20:35:45,109 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077968\n",
      "2025-03-16 20:35:45,110 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087166\n",
      "Training progress:  61%|██████▏   | 184/300 [01:02<00:44,  2.58it/s]2025-03-16 20:35:45,505 - sciml.model.deeponet.deeponet - INFO - Epoch 185/300\n",
      "2025-03-16 20:35:45,506 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076902\n",
      "2025-03-16 20:35:45,506 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085259\n",
      "Training progress:  62%|██████▏   | 185/300 [01:02<00:44,  2.56it/s]2025-03-16 20:35:45,904 - sciml.model.deeponet.deeponet - INFO - Epoch 186/300\n",
      "2025-03-16 20:35:45,905 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076807\n",
      "2025-03-16 20:35:45,906 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088444\n",
      "Training progress:  62%|██████▏   | 186/300 [01:02<00:44,  2.54it/s]2025-03-16 20:35:46,298 - sciml.model.deeponet.deeponet - INFO - Epoch 187/300\n",
      "2025-03-16 20:35:46,299 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077670\n",
      "2025-03-16 20:35:46,299 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085433\n",
      "Training progress:  62%|██████▏   | 187/300 [01:03<00:44,  2.54it/s]2025-03-16 20:35:46,678 - sciml.model.deeponet.deeponet - INFO - Epoch 188/300\n",
      "2025-03-16 20:35:46,679 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076944\n",
      "2025-03-16 20:35:46,679 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085955\n",
      "Training progress:  63%|██████▎   | 188/300 [01:03<00:43,  2.57it/s]2025-03-16 20:35:47,054 - sciml.model.deeponet.deeponet - INFO - Epoch 189/300\n",
      "2025-03-16 20:35:47,055 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076027\n",
      "2025-03-16 20:35:47,056 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086766\n",
      "Training progress:  63%|██████▎   | 189/300 [01:04<00:42,  2.59it/s]2025-03-16 20:35:47,410 - sciml.model.deeponet.deeponet - INFO - Epoch 190/300\n",
      "2025-03-16 20:35:47,410 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076179\n",
      "2025-03-16 20:35:47,411 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084694\n",
      "Training progress:  63%|██████▎   | 190/300 [01:04<00:41,  2.66it/s]2025-03-16 20:35:47,771 - sciml.model.deeponet.deeponet - INFO - Epoch 191/300\n",
      "2025-03-16 20:35:47,772 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076724\n",
      "2025-03-16 20:35:47,772 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088110\n",
      "Training progress:  64%|██████▎   | 191/300 [01:04<00:40,  2.69it/s]2025-03-16 20:35:48,141 - sciml.model.deeponet.deeponet - INFO - Epoch 192/300\n",
      "2025-03-16 20:35:48,141 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076980\n",
      "2025-03-16 20:35:48,142 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085120\n",
      "Training progress:  64%|██████▍   | 192/300 [01:05<00:40,  2.69it/s]2025-03-16 20:35:48,515 - sciml.model.deeponet.deeponet - INFO - Epoch 193/300\n",
      "2025-03-16 20:35:48,516 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076175\n",
      "2025-03-16 20:35:48,516 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085896\n",
      "Training progress:  64%|██████▍   | 193/300 [01:05<00:39,  2.69it/s]2025-03-16 20:35:48,889 - sciml.model.deeponet.deeponet - INFO - Epoch 194/300\n",
      "2025-03-16 20:35:48,890 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075836\n",
      "2025-03-16 20:35:48,891 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086048\n",
      "Training progress:  65%|██████▍   | 194/300 [01:05<00:39,  2.68it/s]2025-03-16 20:35:49,246 - sciml.model.deeponet.deeponet - INFO - Epoch 195/300\n",
      "2025-03-16 20:35:49,246 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076013\n",
      "2025-03-16 20:35:49,247 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085682\n",
      "Training progress:  65%|██████▌   | 195/300 [01:06<00:38,  2.72it/s]2025-03-16 20:35:49,620 - sciml.model.deeponet.deeponet - INFO - Epoch 196/300\n",
      "2025-03-16 20:35:49,621 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076097\n",
      "2025-03-16 20:35:49,622 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086116\n",
      "Training progress:  65%|██████▌   | 196/300 [01:06<00:38,  2.70it/s]2025-03-16 20:35:49,991 - sciml.model.deeponet.deeponet - INFO - Epoch 197/300\n",
      "2025-03-16 20:35:49,992 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075791\n",
      "2025-03-16 20:35:49,992 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085362\n",
      "Training progress:  66%|██████▌   | 197/300 [01:07<00:38,  2.70it/s]2025-03-16 20:35:50,362 - sciml.model.deeponet.deeponet - INFO - Epoch 198/300\n",
      "2025-03-16 20:35:50,362 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075515\n",
      "2025-03-16 20:35:50,363 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085333\n",
      "Training progress:  66%|██████▌   | 198/300 [01:07<00:37,  2.70it/s]2025-03-16 20:35:50,727 - sciml.model.deeponet.deeponet - INFO - Epoch 199/300\n",
      "2025-03-16 20:35:50,728 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075483\n",
      "2025-03-16 20:35:50,729 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086261\n",
      "Training progress:  66%|██████▋   | 199/300 [01:07<00:37,  2.71it/s]2025-03-16 20:35:51,094 - sciml.model.deeponet.deeponet - INFO - Epoch 200/300\n",
      "2025-03-16 20:35:51,095 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075635\n",
      "2025-03-16 20:35:51,096 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084591\n",
      "Training progress:  67%|██████▋   | 200/300 [01:08<00:36,  2.72it/s]2025-03-16 20:35:51,476 - sciml.model.deeponet.deeponet - INFO - Epoch 201/300\n",
      "2025-03-16 20:35:51,477 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075841\n",
      "2025-03-16 20:35:51,477 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087112\n",
      "Training progress:  67%|██████▋   | 201/300 [01:08<00:36,  2.69it/s]2025-03-16 20:35:51,857 - sciml.model.deeponet.deeponet - INFO - Epoch 202/300\n",
      "2025-03-16 20:35:51,858 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076037\n",
      "2025-03-16 20:35:51,859 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084238\n",
      "Training progress:  67%|██████▋   | 202/300 [01:08<00:36,  2.67it/s]2025-03-16 20:35:52,242 - sciml.model.deeponet.deeponet - INFO - Epoch 203/300\n",
      "2025-03-16 20:35:52,243 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075800\n",
      "2025-03-16 20:35:52,244 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086209\n",
      "Training progress:  68%|██████▊   | 203/300 [01:09<00:36,  2.65it/s]2025-03-16 20:35:52,628 - sciml.model.deeponet.deeponet - INFO - Epoch 204/300\n",
      "2025-03-16 20:35:52,629 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075960\n",
      "2025-03-16 20:35:52,629 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084710\n",
      "Training progress:  68%|██████▊   | 204/300 [01:09<00:36,  2.63it/s]2025-03-16 20:35:52,977 - sciml.model.deeponet.deeponet - INFO - Epoch 205/300\n",
      "2025-03-16 20:35:52,978 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075499\n",
      "2025-03-16 20:35:52,979 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084919\n",
      "Training progress:  68%|██████▊   | 205/300 [01:09<00:35,  2.69it/s]2025-03-16 20:35:53,331 - sciml.model.deeponet.deeponet - INFO - Epoch 206/300\n",
      "2025-03-16 20:35:53,332 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075636\n",
      "2025-03-16 20:35:53,332 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086285\n",
      "Training progress:  69%|██████▊   | 206/300 [01:10<00:34,  2.73it/s]2025-03-16 20:35:53,686 - sciml.model.deeponet.deeponet - INFO - Epoch 207/300\n",
      "2025-03-16 20:35:53,687 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075925\n",
      "2025-03-16 20:35:53,687 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085108\n",
      "Training progress:  69%|██████▉   | 207/300 [01:10<00:33,  2.76it/s]2025-03-16 20:35:54,041 - sciml.model.deeponet.deeponet - INFO - Epoch 208/300\n",
      "2025-03-16 20:35:54,041 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075761\n",
      "2025-03-16 20:35:54,042 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085955\n",
      "Training progress:  69%|██████▉   | 208/300 [01:11<00:33,  2.78it/s]2025-03-16 20:35:54,399 - sciml.model.deeponet.deeponet - INFO - Epoch 209/300\n",
      "2025-03-16 20:35:54,400 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075692\n",
      "2025-03-16 20:35:54,400 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085328\n",
      "Training progress:  70%|██████▉   | 209/300 [01:11<00:32,  2.78it/s]2025-03-16 20:35:54,820 - sciml.model.deeponet.deeponet - INFO - Epoch 210/300\n",
      "2025-03-16 20:35:54,821 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075526\n",
      "2025-03-16 20:35:54,822 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084356\n",
      "Training progress:  70%|███████   | 210/300 [01:11<00:34,  2.64it/s]2025-03-16 20:35:55,182 - sciml.model.deeponet.deeponet - INFO - Epoch 211/300\n",
      "2025-03-16 20:35:55,183 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075728\n",
      "2025-03-16 20:35:55,184 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087235\n",
      "Training progress:  70%|███████   | 211/300 [01:12<00:33,  2.68it/s]2025-03-16 20:35:55,546 - sciml.model.deeponet.deeponet - INFO - Epoch 212/300\n",
      "2025-03-16 20:35:55,546 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076730\n",
      "2025-03-16 20:35:55,547 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083884\n",
      "Training progress:  71%|███████   | 212/300 [01:12<00:32,  2.70it/s]2025-03-16 20:35:55,907 - sciml.model.deeponet.deeponet - INFO - Epoch 213/300\n",
      "2025-03-16 20:35:55,908 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075055\n",
      "2025-03-16 20:35:55,908 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084357\n",
      "Training progress:  71%|███████   | 213/300 [01:12<00:31,  2.72it/s]2025-03-16 20:35:56,275 - sciml.model.deeponet.deeponet - INFO - Epoch 214/300\n",
      "2025-03-16 20:35:56,276 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075679\n",
      "2025-03-16 20:35:56,276 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088005\n",
      "Training progress:  71%|███████▏  | 214/300 [01:13<00:31,  2.72it/s]2025-03-16 20:35:56,633 - sciml.model.deeponet.deeponet - INFO - Epoch 215/300\n",
      "2025-03-16 20:35:56,634 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078446\n",
      "2025-03-16 20:35:56,634 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085177\n",
      "Training progress:  72%|███████▏  | 215/300 [01:13<00:31,  2.74it/s]2025-03-16 20:35:56,991 - sciml.model.deeponet.deeponet - INFO - Epoch 216/300\n",
      "2025-03-16 20:35:56,992 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075267\n",
      "2025-03-16 20:35:56,993 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084950\n",
      "Training progress:  72%|███████▏  | 216/300 [01:14<00:30,  2.76it/s]2025-03-16 20:35:57,355 - sciml.model.deeponet.deeponet - INFO - Epoch 217/300\n",
      "2025-03-16 20:35:57,356 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081536\n",
      "2025-03-16 20:35:57,357 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092869\n",
      "Training progress:  72%|███████▏  | 217/300 [01:14<00:30,  2.75it/s]2025-03-16 20:35:57,725 - sciml.model.deeponet.deeponet - INFO - Epoch 218/300\n",
      "2025-03-16 20:35:57,726 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082893\n",
      "2025-03-16 20:35:57,727 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094353\n",
      "Training progress:  73%|███████▎  | 218/300 [01:14<00:29,  2.74it/s]2025-03-16 20:35:58,144 - sciml.model.deeponet.deeponet - INFO - Epoch 219/300\n",
      "2025-03-16 20:35:58,145 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084856\n",
      "2025-03-16 20:35:58,145 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094886\n",
      "Training progress:  73%|███████▎  | 219/300 [01:15<00:30,  2.62it/s]2025-03-16 20:35:58,538 - sciml.model.deeponet.deeponet - INFO - Epoch 220/300\n",
      "2025-03-16 20:35:58,539 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084495\n",
      "2025-03-16 20:35:58,540 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093789\n",
      "Training progress:  73%|███████▎  | 220/300 [01:15<00:30,  2.60it/s]2025-03-16 20:35:58,918 - sciml.model.deeponet.deeponet - INFO - Epoch 221/300\n",
      "2025-03-16 20:35:58,919 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083326\n",
      "2025-03-16 20:35:58,920 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091709\n",
      "Training progress:  74%|███████▎  | 221/300 [01:15<00:30,  2.61it/s]2025-03-16 20:35:59,294 - sciml.model.deeponet.deeponet - INFO - Epoch 222/300\n",
      "2025-03-16 20:35:59,295 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081787\n",
      "2025-03-16 20:35:59,295 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090431\n",
      "Training progress:  74%|███████▍  | 222/300 [01:16<00:29,  2.62it/s]2025-03-16 20:35:59,664 - sciml.model.deeponet.deeponet - INFO - Epoch 223/300\n",
      "2025-03-16 20:35:59,664 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081896\n",
      "2025-03-16 20:35:59,665 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087137\n",
      "Training progress:  74%|███████▍  | 223/300 [01:16<00:29,  2.65it/s]2025-03-16 20:36:00,042 - sciml.model.deeponet.deeponet - INFO - Epoch 224/300\n",
      "2025-03-16 20:36:00,043 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081374\n",
      "2025-03-16 20:36:00,044 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088464\n",
      "Training progress:  75%|███████▍  | 224/300 [01:17<00:28,  2.65it/s]2025-03-16 20:36:00,412 - sciml.model.deeponet.deeponet - INFO - Epoch 225/300\n",
      "2025-03-16 20:36:00,412 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079628\n",
      "2025-03-16 20:36:00,413 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088539\n",
      "Training progress:  75%|███████▌  | 225/300 [01:17<00:28,  2.66it/s]2025-03-16 20:35:57,860 - sciml.model.deeponet.deeponet - INFO - Epoch 226/300\n",
      "2025-03-16 20:35:57,861 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079937\n",
      "2025-03-16 20:35:57,862 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087624\n",
      "2025-03-16 20:35:58,229 - sciml.model.deeponet.deeponet - INFO - Epoch 227/300\n",
      "2025-03-16 20:35:58,229 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079948\n",
      "2025-03-16 20:35:58,230 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087400\n",
      "2025-03-16 20:35:58,598 - sciml.model.deeponet.deeponet - INFO - Epoch 228/300\n",
      "2025-03-16 20:35:58,598 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080123\n",
      "2025-03-16 20:35:58,599 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087597\n",
      "2025-03-16 20:35:59,015 - sciml.model.deeponet.deeponet - INFO - Epoch 229/300\n",
      "2025-03-16 20:35:59,016 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079653\n",
      "2025-03-16 20:35:59,017 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086536\n",
      "2025-03-16 20:35:59,397 - sciml.model.deeponet.deeponet - INFO - Epoch 230/300\n",
      "2025-03-16 20:35:59,397 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079175\n",
      "2025-03-16 20:35:59,398 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088995\n",
      "2025-03-16 20:35:59,769 - sciml.model.deeponet.deeponet - INFO - Epoch 231/300\n",
      "2025-03-16 20:35:59,770 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079236\n",
      "2025-03-16 20:35:59,771 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088180\n",
      "2025-03-16 20:36:00,130 - sciml.model.deeponet.deeponet - INFO - Epoch 232/300\n",
      "2025-03-16 20:36:00,131 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078717\n",
      "2025-03-16 20:36:00,132 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086183\n",
      "2025-03-16 20:36:00,496 - sciml.model.deeponet.deeponet - INFO - Epoch 233/300\n",
      "2025-03-16 20:36:00,497 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079344\n",
      "2025-03-16 20:36:00,498 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088341\n",
      "2025-03-16 20:36:00,856 - sciml.model.deeponet.deeponet - INFO - Epoch 234/300\n",
      "2025-03-16 20:36:00,857 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079633\n",
      "2025-03-16 20:36:00,858 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087387\n",
      "Training progress:  78%|███████▊  | 234/300 [01:17<00:07,  8.58it/s]2025-03-16 20:36:01,227 - sciml.model.deeponet.deeponet - INFO - Epoch 235/300\n",
      "2025-03-16 20:36:01,228 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079304\n",
      "2025-03-16 20:36:01,229 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087383\n",
      "Training progress:  78%|███████▊  | 235/300 [01:18<00:09,  6.90it/s]2025-03-16 20:36:01,614 - sciml.model.deeponet.deeponet - INFO - Epoch 236/300\n",
      "2025-03-16 20:36:01,615 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079243\n",
      "2025-03-16 20:36:01,616 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086781\n",
      "Training progress:  79%|███████▊  | 236/300 [01:18<00:11,  5.61it/s]2025-03-16 20:36:01,993 - sciml.model.deeponet.deeponet - INFO - Epoch 237/300\n",
      "2025-03-16 20:36:01,994 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078672\n",
      "2025-03-16 20:36:01,995 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089434\n",
      "Training progress:  79%|███████▉  | 237/300 [01:19<00:13,  4.73it/s]2025-03-16 20:36:02,354 - sciml.model.deeponet.deeponet - INFO - Epoch 238/300\n",
      "2025-03-16 20:36:02,355 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078751\n",
      "2025-03-16 20:36:02,356 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086788\n",
      "Training progress:  79%|███████▉  | 238/300 [01:19<00:14,  4.17it/s]2025-03-16 20:36:02,725 - sciml.model.deeponet.deeponet - INFO - Epoch 239/300\n",
      "2025-03-16 20:36:02,726 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078148\n",
      "2025-03-16 20:36:02,727 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087053\n",
      "Training progress:  80%|███████▉  | 239/300 [01:19<00:16,  3.73it/s]2025-03-16 20:36:03,093 - sciml.model.deeponet.deeponet - INFO - Epoch 240/300\n",
      "2025-03-16 20:36:03,093 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078332\n",
      "2025-03-16 20:36:03,094 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087043\n",
      "Training progress:  80%|████████  | 240/300 [01:20<00:17,  3.43it/s]2025-03-16 20:36:03,449 - sciml.model.deeponet.deeponet - INFO - Epoch 241/300\n",
      "2025-03-16 20:36:03,450 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077536\n",
      "2025-03-16 20:36:03,450 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087665\n",
      "Training progress:  80%|████████  | 241/300 [01:20<00:18,  3.25it/s]2025-03-16 20:36:03,816 - sciml.model.deeponet.deeponet - INFO - Epoch 242/300\n",
      "2025-03-16 20:36:03,817 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077634\n",
      "2025-03-16 20:36:03,818 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085338\n",
      "Training progress:  81%|████████  | 242/300 [01:20<00:18,  3.09it/s]2025-03-16 20:36:04,215 - sciml.model.deeponet.deeponet - INFO - Epoch 243/300\n",
      "2025-03-16 20:36:04,215 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077130\n",
      "2025-03-16 20:36:04,216 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084029\n",
      "Training progress:  81%|████████  | 243/300 [01:21<00:19,  2.91it/s]2025-03-16 20:36:04,592 - sciml.model.deeponet.deeponet - INFO - Epoch 244/300\n",
      "2025-03-16 20:36:04,592 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077425\n",
      "2025-03-16 20:36:04,593 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085675\n",
      "Training progress:  81%|████████▏ | 244/300 [01:21<00:19,  2.83it/s]2025-03-16 20:36:04,956 - sciml.model.deeponet.deeponet - INFO - Epoch 245/300\n",
      "2025-03-16 20:36:04,957 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077496\n",
      "2025-03-16 20:36:04,958 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085487\n",
      "Training progress:  82%|████████▏ | 245/300 [01:21<00:19,  2.81it/s]2025-03-16 20:36:05,337 - sciml.model.deeponet.deeponet - INFO - Epoch 246/300\n",
      "2025-03-16 20:36:05,338 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077526\n",
      "2025-03-16 20:36:05,339 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084960\n",
      "Training progress:  82%|████████▏ | 246/300 [01:22<00:19,  2.75it/s]2025-03-16 20:36:05,714 - sciml.model.deeponet.deeponet - INFO - Epoch 247/300\n",
      "2025-03-16 20:36:05,715 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077840\n",
      "2025-03-16 20:36:05,716 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084292\n",
      "Training progress:  82%|████████▏ | 247/300 [01:22<00:19,  2.72it/s]2025-03-16 20:36:06,089 - sciml.model.deeponet.deeponet - INFO - Epoch 248/300\n",
      "2025-03-16 20:36:06,090 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077322\n",
      "2025-03-16 20:36:06,091 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086354\n",
      "Training progress:  83%|████████▎ | 248/300 [01:23<00:19,  2.70it/s]2025-03-16 20:36:06,462 - sciml.model.deeponet.deeponet - INFO - Epoch 249/300\n",
      "2025-03-16 20:36:06,463 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077496\n",
      "2025-03-16 20:36:06,463 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084961\n",
      "Training progress:  83%|████████▎ | 249/300 [01:23<00:18,  2.70it/s]2025-03-16 20:36:06,838 - sciml.model.deeponet.deeponet - INFO - Epoch 250/300\n",
      "2025-03-16 20:36:06,839 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076811\n",
      "2025-03-16 20:36:06,840 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084896\n",
      "Training progress:  83%|████████▎ | 250/300 [01:23<00:18,  2.69it/s]2025-03-16 20:36:07,220 - sciml.model.deeponet.deeponet - INFO - Epoch 251/300\n",
      "2025-03-16 20:36:07,221 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076934\n",
      "2025-03-16 20:36:07,222 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085027\n",
      "Training progress:  84%|████████▎ | 251/300 [01:24<00:18,  2.66it/s]2025-03-16 20:36:07,601 - sciml.model.deeponet.deeponet - INFO - Epoch 252/300\n",
      "2025-03-16 20:36:07,602 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076461\n",
      "2025-03-16 20:36:07,603 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084915\n",
      "Training progress:  84%|████████▍ | 252/300 [01:24<00:18,  2.65it/s]2025-03-16 20:36:08,028 - sciml.model.deeponet.deeponet - INFO - Epoch 253/300\n",
      "2025-03-16 20:36:08,029 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076455\n",
      "2025-03-16 20:36:08,030 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084114\n",
      "Training progress:  84%|████████▍ | 253/300 [01:25<00:18,  2.55it/s]2025-03-16 20:36:08,423 - sciml.model.deeponet.deeponet - INFO - Epoch 254/300\n",
      "2025-03-16 20:36:08,424 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076362\n",
      "2025-03-16 20:36:08,425 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084248\n",
      "Training progress:  85%|████████▍ | 254/300 [01:25<00:18,  2.55it/s]2025-03-16 20:36:08,807 - sciml.model.deeponet.deeponet - INFO - Epoch 255/300\n",
      "2025-03-16 20:36:08,807 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076256\n",
      "2025-03-16 20:36:08,808 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085756\n",
      "Training progress:  85%|████████▌ | 255/300 [01:25<00:17,  2.56it/s]2025-03-16 20:36:09,184 - sciml.model.deeponet.deeponet - INFO - Epoch 256/300\n",
      "2025-03-16 20:36:09,184 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076500\n",
      "2025-03-16 20:36:09,185 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084320\n",
      "Training progress:  85%|████████▌ | 256/300 [01:26<00:16,  2.59it/s]2025-03-16 20:36:09,553 - sciml.model.deeponet.deeponet - INFO - Epoch 257/300\n",
      "2025-03-16 20:36:09,554 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076630\n",
      "2025-03-16 20:36:09,554 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086408\n",
      "Training progress:  86%|████████▌ | 257/300 [01:26<00:16,  2.63it/s]2025-03-16 20:36:09,909 - sciml.model.deeponet.deeponet - INFO - Epoch 258/300\n",
      "2025-03-16 20:36:09,909 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077599\n",
      "2025-03-16 20:36:09,910 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085064\n",
      "Training progress:  86%|████████▌ | 258/300 [01:26<00:15,  2.68it/s]2025-03-16 20:36:10,269 - sciml.model.deeponet.deeponet - INFO - Epoch 259/300\n",
      "2025-03-16 20:36:10,270 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077896\n",
      "2025-03-16 20:36:10,271 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089468\n",
      "Training progress:  86%|████████▋ | 259/300 [01:27<00:15,  2.70it/s]2025-03-16 20:36:10,630 - sciml.model.deeponet.deeponet - INFO - Epoch 260/300\n",
      "2025-03-16 20:36:10,631 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079580\n",
      "2025-03-16 20:36:10,632 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084812\n",
      "Training progress:  87%|████████▋ | 260/300 [01:27<00:14,  2.73it/s]2025-03-16 20:36:11,017 - sciml.model.deeponet.deeponet - INFO - Epoch 261/300\n",
      "2025-03-16 20:36:11,018 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078426\n",
      "2025-03-16 20:36:11,019 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086591\n",
      "Training progress:  87%|████████▋ | 261/300 [01:28<00:14,  2.68it/s]2025-03-16 20:36:11,388 - sciml.model.deeponet.deeponet - INFO - Epoch 262/300\n",
      "2025-03-16 20:36:11,389 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077763\n",
      "2025-03-16 20:36:11,390 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084053\n",
      "Training progress:  87%|████████▋ | 262/300 [01:28<00:14,  2.69it/s]2025-03-16 20:36:11,763 - sciml.model.deeponet.deeponet - INFO - Epoch 263/300\n",
      "2025-03-16 20:36:11,764 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076206\n",
      "2025-03-16 20:36:11,765 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083728\n",
      "Training progress:  88%|████████▊ | 263/300 [01:28<00:13,  2.68it/s]2025-03-16 20:36:12,139 - sciml.model.deeponet.deeponet - INFO - Epoch 264/300\n",
      "2025-03-16 20:36:12,140 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075815\n",
      "2025-03-16 20:36:12,140 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085083\n",
      "Training progress:  88%|████████▊ | 264/300 [01:29<00:13,  2.67it/s]2025-03-16 20:36:12,519 - sciml.model.deeponet.deeponet - INFO - Epoch 265/300\n",
      "2025-03-16 20:36:12,519 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076600\n",
      "2025-03-16 20:36:12,520 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084771\n",
      "Training progress:  88%|████████▊ | 265/300 [01:29<00:13,  2.66it/s]2025-03-16 20:36:12,877 - sciml.model.deeponet.deeponet - INFO - Epoch 266/300\n",
      "2025-03-16 20:36:12,878 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077107\n",
      "2025-03-16 20:36:12,878 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086806\n",
      "Training progress:  89%|████████▊ | 266/300 [01:29<00:12,  2.70it/s]2025-03-16 20:36:13,274 - sciml.model.deeponet.deeponet - INFO - Epoch 267/300\n",
      "2025-03-16 20:36:13,275 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077547\n",
      "2025-03-16 20:36:13,276 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083620\n",
      "Training progress:  89%|████████▉ | 267/300 [01:30<00:12,  2.64it/s]2025-03-16 20:36:13,634 - sciml.model.deeponet.deeponet - INFO - Epoch 268/300\n",
      "2025-03-16 20:36:13,635 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076336\n",
      "2025-03-16 20:36:13,635 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084043\n",
      "Training progress:  89%|████████▉ | 268/300 [01:30<00:11,  2.68it/s]2025-03-16 20:36:14,011 - sciml.model.deeponet.deeponet - INFO - Epoch 269/300\n",
      "2025-03-16 20:36:14,013 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075569\n",
      "2025-03-16 20:36:14,013 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084331\n",
      "Training progress:  90%|████████▉ | 269/300 [01:31<00:11,  2.67it/s]2025-03-16 20:36:14,375 - sciml.model.deeponet.deeponet - INFO - Epoch 270/300\n",
      "2025-03-16 20:36:14,376 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075749\n",
      "2025-03-16 20:36:14,377 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083506\n",
      "Training progress:  90%|█████████ | 270/300 [01:31<00:11,  2.69it/s]2025-03-16 20:36:14,740 - sciml.model.deeponet.deeponet - INFO - Epoch 271/300\n",
      "2025-03-16 20:36:14,740 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076349\n",
      "2025-03-16 20:36:14,741 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085651\n",
      "Training progress:  90%|█████████ | 271/300 [01:31<00:10,  2.71it/s]2025-03-16 20:36:15,105 - sciml.model.deeponet.deeponet - INFO - Epoch 272/300\n",
      "2025-03-16 20:36:15,106 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077074\n",
      "2025-03-16 20:36:15,106 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084045\n",
      "Training progress:  91%|█████████ | 272/300 [01:32<00:10,  2.72it/s]2025-03-16 20:36:15,476 - sciml.model.deeponet.deeponet - INFO - Epoch 273/300\n",
      "2025-03-16 20:36:15,476 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076428\n",
      "2025-03-16 20:36:15,477 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084427\n",
      "Training progress:  91%|█████████ | 273/300 [01:32<00:09,  2.71it/s]2025-03-16 20:36:16,171 - sciml.model.deeponet.deeponet - INFO - Epoch 274/300\n",
      "2025-03-16 20:36:16,172 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075783\n",
      "2025-03-16 20:36:16,173 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083239\n",
      "Training progress:  91%|█████████▏| 274/300 [01:33<00:12,  2.14it/s]2025-03-16 20:36:16,534 - sciml.model.deeponet.deeponet - INFO - Epoch 275/300\n",
      "2025-03-16 20:36:16,535 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075383\n",
      "2025-03-16 20:36:16,536 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083284\n",
      "Training progress:  92%|█████████▏| 275/300 [01:33<00:10,  2.30it/s]2025-03-16 20:36:16,912 - sciml.model.deeponet.deeponet - INFO - Epoch 276/300\n",
      "2025-03-16 20:36:16,913 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075503\n",
      "2025-03-16 20:36:16,914 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084805\n",
      "Training progress:  92%|█████████▏| 276/300 [01:33<00:10,  2.39it/s]2025-03-16 20:36:17,269 - sciml.model.deeponet.deeponet - INFO - Epoch 277/300\n",
      "2025-03-16 20:36:17,269 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076072\n",
      "2025-03-16 20:36:17,270 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083236\n",
      "Training progress:  92%|█████████▏| 277/300 [01:34<00:09,  2.50it/s]2025-03-16 20:36:17,637 - sciml.model.deeponet.deeponet - INFO - Epoch 278/300\n",
      "2025-03-16 20:36:17,638 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076035\n",
      "2025-03-16 20:36:17,639 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084366\n",
      "Training progress:  93%|█████████▎| 278/300 [01:34<00:08,  2.56it/s]2025-03-16 20:36:17,997 - sciml.model.deeponet.deeponet - INFO - Epoch 279/300\n",
      "2025-03-16 20:36:17,998 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075863\n",
      "2025-03-16 20:36:17,998 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083060\n",
      "Training progress:  93%|█████████▎| 279/300 [01:35<00:08,  2.62it/s]2025-03-16 20:36:18,351 - sciml.model.deeponet.deeponet - INFO - Epoch 280/300\n",
      "2025-03-16 20:36:18,355 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075354\n",
      "2025-03-16 20:36:18,356 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083261\n",
      "Training progress:  93%|█████████▎| 280/300 [01:35<00:07,  2.67it/s]2025-03-16 20:36:18,786 - sciml.model.deeponet.deeponet - INFO - Epoch 281/300\n",
      "2025-03-16 20:36:18,787 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075113\n",
      "2025-03-16 20:36:18,788 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083600\n",
      "Training progress:  94%|█████████▎| 281/300 [01:35<00:07,  2.55it/s]2025-03-16 20:36:19,163 - sciml.model.deeponet.deeponet - INFO - Epoch 282/300\n",
      "2025-03-16 20:36:19,164 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075232\n",
      "2025-03-16 20:36:19,165 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083140\n",
      "Training progress:  94%|█████████▍| 282/300 [01:36<00:06,  2.58it/s]2025-03-16 20:36:19,531 - sciml.model.deeponet.deeponet - INFO - Epoch 283/300\n",
      "2025-03-16 20:36:19,532 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075447\n",
      "2025-03-16 20:36:19,533 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084460\n",
      "Training progress:  94%|█████████▍| 283/300 [01:36<00:06,  2.62it/s]2025-03-16 20:36:19,906 - sciml.model.deeponet.deeponet - INFO - Epoch 284/300\n",
      "2025-03-16 20:36:19,907 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075762\n",
      "2025-03-16 20:36:19,908 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083181\n",
      "Training progress:  95%|█████████▍| 284/300 [01:36<00:06,  2.64it/s]2025-03-16 20:36:20,287 - sciml.model.deeponet.deeponet - INFO - Epoch 285/300\n",
      "2025-03-16 20:36:20,288 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075586\n",
      "2025-03-16 20:36:20,288 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084154\n",
      "Training progress:  95%|█████████▌| 285/300 [01:37<00:05,  2.63it/s]2025-03-16 20:36:20,661 - sciml.model.deeponet.deeponet - INFO - Epoch 286/300\n",
      "2025-03-16 20:36:20,662 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075404\n",
      "2025-03-16 20:36:20,663 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083038\n",
      "Training progress:  95%|█████████▌| 286/300 [01:37<00:05,  2.64it/s]2025-03-16 20:36:21,039 - sciml.model.deeponet.deeponet - INFO - Epoch 287/300\n",
      "2025-03-16 20:36:21,040 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075070\n",
      "2025-03-16 20:36:21,040 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083375\n",
      "Training progress:  96%|█████████▌| 287/300 [01:38<00:04,  2.65it/s]2025-03-16 20:36:21,471 - sciml.model.deeponet.deeponet - INFO - Epoch 288/300\n",
      "2025-03-16 20:36:21,472 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074898\n",
      "2025-03-16 20:36:21,474 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083183\n",
      "Training progress:  96%|█████████▌| 288/300 [01:38<00:04,  2.53it/s]2025-03-16 20:36:21,885 - sciml.model.deeponet.deeponet - INFO - Epoch 289/300\n",
      "2025-03-16 20:36:21,885 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074911\n",
      "2025-03-16 20:36:21,886 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082596\n",
      "Training progress:  96%|█████████▋| 289/300 [01:38<00:04,  2.50it/s]2025-03-16 20:36:22,301 - sciml.model.deeponet.deeponet - INFO - Epoch 290/300\n",
      "2025-03-16 20:36:22,303 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075113\n",
      "2025-03-16 20:36:22,304 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084342\n",
      "Training progress:  97%|█████████▋| 290/300 [01:39<00:04,  2.47it/s]2025-03-16 20:36:22,703 - sciml.model.deeponet.deeponet - INFO - Epoch 291/300\n",
      "2025-03-16 20:36:22,704 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075454\n",
      "2025-03-16 20:36:22,705 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082861\n",
      "Training progress:  97%|█████████▋| 291/300 [01:39<00:03,  2.48it/s]2025-03-16 20:36:23,102 - sciml.model.deeponet.deeponet - INFO - Epoch 292/300\n",
      "2025-03-16 20:36:23,103 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075355\n",
      "2025-03-16 20:36:23,104 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084222\n",
      "Training progress:  97%|█████████▋| 292/300 [01:40<00:03,  2.48it/s]2025-03-16 20:36:23,474 - sciml.model.deeponet.deeponet - INFO - Epoch 293/300\n",
      "2025-03-16 20:36:23,475 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075508\n",
      "2025-03-16 20:36:23,476 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083155\n",
      "Training progress:  98%|█████████▊| 293/300 [01:40<00:02,  2.54it/s]2025-03-16 20:36:23,852 - sciml.model.deeponet.deeponet - INFO - Epoch 294/300\n",
      "2025-03-16 20:36:23,853 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075176\n",
      "2025-03-16 20:36:23,853 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083625\n",
      "Training progress:  98%|█████████▊| 294/300 [01:40<00:02,  2.57it/s]2025-03-16 20:36:24,230 - sciml.model.deeponet.deeponet - INFO - Epoch 295/300\n",
      "2025-03-16 20:36:24,230 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074898\n",
      "2025-03-16 20:36:24,231 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082495\n",
      "Training progress:  98%|█████████▊| 295/300 [01:41<00:01,  2.59it/s]2025-03-16 20:36:24,603 - sciml.model.deeponet.deeponet - INFO - Epoch 296/300\n",
      "2025-03-16 20:36:24,604 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074711\n",
      "2025-03-16 20:36:24,605 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082664\n",
      "Training progress:  99%|█████████▊| 296/300 [01:41<00:01,  2.62it/s]2025-03-16 20:36:24,968 - sciml.model.deeponet.deeponet - INFO - Epoch 297/300\n",
      "2025-03-16 20:36:24,969 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074651\n",
      "2025-03-16 20:36:24,969 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083405\n",
      "Training progress:  99%|█████████▉| 297/300 [01:41<00:01,  2.66it/s]2025-03-16 20:36:25,335 - sciml.model.deeponet.deeponet - INFO - Epoch 298/300\n",
      "2025-03-16 20:36:25,336 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074837\n",
      "2025-03-16 20:36:25,337 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082623\n",
      "Training progress:  99%|█████████▉| 298/300 [01:42<00:00,  2.67it/s]2025-03-16 20:36:25,703 - sciml.model.deeponet.deeponet - INFO - Epoch 299/300\n",
      "2025-03-16 20:36:25,704 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074990\n",
      "2025-03-16 20:36:25,704 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084593\n",
      "Training progress: 100%|█████████▉| 299/300 [01:42<00:00,  2.69it/s]2025-03-16 20:36:26,041 - sciml.model.deeponet.deeponet - INFO - Epoch 300/300\n",
      "2025-03-16 20:36:26,042 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075421\n",
      "2025-03-16 20:36:26,043 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083197\n",
      "Training progress: 100%|██████████| 300/300 [01:43<00:00,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_history_train,loss_history_test = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2950269281864166, 0.2847592234611511, 0.2727395296096802, 0.27010759711265564, 0.2606508433818817, 0.2541564106941223, 0.24872665107250214, 0.2421846091747284, 0.2365485429763794, 0.2313825488090515, 0.22509804368019104, 0.21847200393676758, 0.21167835593223572, 0.2037951946258545, 0.19584423303604126, 0.18771600723266602, 0.17910587787628174, 0.1720864623785019, 0.16516675055027008, 0.15923771262168884, 0.15354576706886292, 0.15017499029636383, 0.14804258942604065, 0.14592963457107544, 0.14464136958122253, 0.14366620779037476, 0.1423962116241455, 0.14061154425144196, 0.13838452100753784, 0.1362917721271515, 0.1344820261001587, 0.13278436660766602, 0.1310269832611084, 0.12927861511707306, 0.12797954678535461, 0.12644298374652863, 0.12476855516433716, 0.12310057133436203, 0.12148662656545639, 0.11988843977451324, 0.11829215288162231, 0.116917684674263, 0.11556054651737213, 0.11458861827850342, 0.11468815803527832, 0.114383265376091, 0.11268332600593567, 0.10872994363307953, 0.11132212728261948, 0.1113063246011734, 0.10626347362995148, 0.11094573140144348, 0.10486572980880737, 0.10617983341217041, 0.10421431064605713, 0.1020602136850357, 0.10219356417655945, 0.10121810436248779, 0.1007467657327652, 0.09817206859588623, 0.09896112233400345, 0.0979984700679779, 0.09671824425458908, 0.096277616918087, 0.0958709716796875, 0.09483273327350616, 0.09440074861049652, 0.09386499971151352, 0.09304314851760864, 0.09292265772819519, 0.09223049134016037, 0.09145257622003555, 0.09152597188949585, 0.0908905565738678, 0.09037014096975327, 0.09009546786546707, 0.0897030457854271, 0.0894179493188858, 0.08894497156143188, 0.08873018622398376, 0.08828578144311905, 0.08799959719181061, 0.08764965087175369, 0.08736225962638855, 0.08706339448690414, 0.08675004541873932, 0.0865548849105835, 0.0863422378897667, 0.08646203577518463, 0.08848705887794495, 0.0934327095746994, 0.10069561004638672, 0.08607126772403717, 0.10275214910507202, 0.09892170876264572, 0.09801293909549713, 0.09736090898513794, 0.08909189701080322, 0.0910542905330658, 0.09065794944763184, 0.09236128628253937, 0.08799456804990768, 0.08966177701950073, 0.08805355429649353, 0.08892753720283508, 0.08672494441270828, 0.08805901557207108, 0.08604197204113007, 0.0867370143532753, 0.08538135886192322, 0.08652667701244354, 0.0846584290266037, 0.08568081259727478, 0.08416382223367691, 0.08484567701816559, 0.08389472961425781, 0.08436800539493561, 0.08314627408981323, 0.08371277153491974, 0.08330461382865906, 0.08276985585689545, 0.08251245319843292, 0.08285083621740341, 0.08237887173891068, 0.08209580928087234, 0.08187171816825867, 0.08197865635156631, 0.08151058852672577, 0.08154436200857162, 0.08125580847263336, 0.08121657371520996, 0.08092617988586426, 0.08087465167045593, 0.0807182788848877, 0.08057034015655518, 0.08042281866073608, 0.0802876353263855, 0.08020224422216415, 0.0799834206700325, 0.07997482270002365, 0.07979640364646912, 0.07962047308683395, 0.07959365844726562, 0.07941418141126633, 0.07930552959442139, 0.07920446246862411, 0.07907548546791077, 0.0789686068892479, 0.07888197153806686, 0.07874046266078949, 0.07864774763584137, 0.07857143878936768, 0.07843399047851562, 0.07832938432693481, 0.07824543118476868, 0.07815048098564148, 0.07802555710077286, 0.07792066037654877, 0.07783020287752151, 0.07775571942329407, 0.07766897231340408, 0.07758405804634094, 0.077476866543293, 0.07737726718187332, 0.07729597389698029, 0.07725714147090912, 0.0773276835680008, 0.07754579186439514, 0.07812775671482086, 0.0781155675649643, 0.07842076569795609, 0.0795242190361023, 0.07902482151985168, 0.0792713314294815, 0.07742844521999359, 0.07707542181015015, 0.07792028784751892, 0.07885423302650452, 0.08001834154129028, 0.0773824006319046, 0.07640933990478516, 0.0776231437921524, 0.07801763713359833, 0.07796810567378998, 0.07690173387527466, 0.07680711150169373, 0.07767020910978317, 0.07694393396377563, 0.07602670788764954, 0.07617919147014618, 0.07672448456287384, 0.07697995752096176, 0.07617463171482086, 0.07583583891391754, 0.07601267099380493, 0.07609722018241882, 0.07579068094491959, 0.07551520317792892, 0.07548291236162186, 0.07563547790050507, 0.07584058493375778, 0.0760374441742897, 0.07580018788576126, 0.07595997303724289, 0.07549940049648285, 0.07563628256320953, 0.07592450827360153, 0.07576057314872742, 0.07569152861833572, 0.07552647590637207, 0.07572793960571289, 0.07672955095767975, 0.07505524903535843, 0.07567886263132095, 0.07844583690166473, 0.07526695728302002, 0.08153585344552994, 0.08289327472448349, 0.08485627174377441, 0.0844951942563057, 0.08332587778568268, 0.08178653568029404, 0.08189550042152405, 0.08137382566928864, 0.07962848246097565, 0.07993653416633606, 0.07994811236858368, 0.08012336492538452, 0.07965347170829773, 0.07917530834674835, 0.07923643290996552, 0.07871714979410172, 0.07934428751468658, 0.07963304221630096, 0.0793042853474617, 0.07924327254295349, 0.07867187261581421, 0.07875079661607742, 0.07814797013998032, 0.07833191752433777, 0.07753559947013855, 0.07763421535491943, 0.07712991535663605, 0.07742513716220856, 0.0774962306022644, 0.0775260329246521, 0.07783971726894379, 0.07732196152210236, 0.0774959847331047, 0.07681114971637726, 0.07693393528461456, 0.07646149396896362, 0.07645463943481445, 0.07636209577322006, 0.07625603675842285, 0.07650028169155121, 0.07663043588399887, 0.07759913802146912, 0.07789606600999832, 0.0795801430940628, 0.0784258022904396, 0.07776340842247009, 0.07620552182197571, 0.07581497728824615, 0.07660049945116043, 0.07710717618465424, 0.07754670083522797, 0.07633605599403381, 0.07556919753551483, 0.07574892044067383, 0.07634924352169037, 0.07707426697015762, 0.07642773538827896, 0.0757831260561943, 0.07538348436355591, 0.07550252974033356, 0.07607202231884003, 0.07603483647108078, 0.07586275041103363, 0.07535392045974731, 0.07511334121227264, 0.07523223757743835, 0.07544669508934021, 0.075762078166008, 0.07558591663837433, 0.07540358603000641, 0.07506996393203735, 0.07489773631095886, 0.07491106539964676, 0.07511331140995026, 0.0754535049200058, 0.07535478472709656, 0.07550820708274841, 0.07517637312412262, 0.07489777356386185, 0.07471097260713577, 0.07465118169784546, 0.07483749091625214, 0.07499020546674728, 0.0754212886095047]\n"
     ]
    }
   ],
   "source": [
    "print(loss_history_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_train,color='blue')\n",
    "plt.plot(loss_history_test,color='red')\n",
    "plt.legend(['train','test'])\n",
    "#log \n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
