{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sciml.model.deeponet import DeepONet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = 80\n",
    "d_V = 5\n",
    "epochs = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(d_p,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(d_V, activation='relu'),\n",
    "])\n",
    "\n",
    "\n",
    "external_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(d_V, activation='relu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/test_data/example_data/heat2d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 01:11:25,294 - sciml.model.deeponet.deeponet - INFO - Model initialized with 300 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(regular_params={\"internal_model\": internal_model, \"external_model\": external_model}, hyper_params={\"d_p\": d_p, \"d_V\": d_V,\"device\": \"GPU\",\"n_epochs\":epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 8414.27it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 2339.82it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 3083.25it/s]\n"
     ]
    }
   ],
   "source": [
    "mus, xs, sol = model.get_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 80)\n",
      "(40, 8000, 3)\n",
      "(40, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(mus.shape)\n",
    "print(xs.shape)\n",
    "print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 8859.49it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 5726.99it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 5793.44it/s]\n",
      "2025-03-17 01:11:25.800971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [40,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "Training progress:   0%|          | 0/300 [00:00<?, ?it/s]2025-03-17 01:11:25.826099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-17 01:11:26.051326: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [8,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-17 01:11:26,082 - sciml.model.deeponet.deeponet - INFO - Epoch 1/300\n",
      "2025-03-17 01:11:26,084 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.347757\n",
      "2025-03-17 01:11:26,084 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.326496\n",
      "Training progress:   0%|          | 1/300 [00:00<01:18,  3.82it/s]2025-03-17 01:11:26,244 - sciml.model.deeponet.deeponet - INFO - Epoch 2/300\n",
      "2025-03-17 01:11:26,245 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.345401\n",
      "2025-03-17 01:11:26,247 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.322487\n",
      "Training progress:   1%|          | 2/300 [00:00<01:00,  4.93it/s]2025-03-17 01:11:26,405 - sciml.model.deeponet.deeponet - INFO - Epoch 3/300\n",
      "2025-03-17 01:11:26,406 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.341482\n",
      "2025-03-17 01:11:26,407 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.316654\n",
      "Training progress:   1%|          | 3/300 [00:00<00:54,  5.45it/s]2025-03-17 01:11:26,556 - sciml.model.deeponet.deeponet - INFO - Epoch 4/300\n",
      "2025-03-17 01:11:26,556 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.336029\n",
      "2025-03-17 01:11:26,557 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.309663\n",
      "Training progress:   1%|▏         | 4/300 [00:00<00:50,  5.88it/s]2025-03-17 01:11:26,732 - sciml.model.deeponet.deeponet - INFO - Epoch 5/300\n",
      "2025-03-17 01:11:26,733 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.329441\n",
      "2025-03-17 01:11:26,734 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.301731\n",
      "Training progress:   2%|▏         | 5/300 [00:00<00:51,  5.78it/s]2025-03-17 01:11:26,904 - sciml.model.deeponet.deeponet - INFO - Epoch 6/300\n",
      "2025-03-17 01:11:26,905 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.321888\n",
      "2025-03-17 01:11:26,906 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.292990\n",
      "Training progress:   2%|▏         | 6/300 [00:01<00:50,  5.80it/s]2025-03-17 01:11:27,070 - sciml.model.deeponet.deeponet - INFO - Epoch 7/300\n",
      "2025-03-17 01:11:27,071 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.313398\n",
      "2025-03-17 01:11:27,071 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.283390\n",
      "Training progress:   2%|▏         | 7/300 [00:01<00:49,  5.88it/s]2025-03-17 01:11:27,237 - sciml.model.deeponet.deeponet - INFO - Epoch 8/300\n",
      "2025-03-17 01:11:27,238 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.304062\n",
      "2025-03-17 01:11:27,238 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.273189\n",
      "Training progress:   3%|▎         | 8/300 [00:01<00:49,  5.91it/s]2025-03-17 01:11:27,400 - sciml.model.deeponet.deeponet - INFO - Epoch 9/300\n",
      "2025-03-17 01:11:27,401 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.294287\n",
      "2025-03-17 01:11:27,401 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.262770\n",
      "Training progress:   3%|▎         | 9/300 [00:01<00:48,  5.97it/s]2025-03-17 01:11:27,552 - sciml.model.deeponet.deeponet - INFO - Epoch 10/300\n",
      "2025-03-17 01:11:27,553 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.284686\n",
      "2025-03-17 01:11:27,553 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.252697\n",
      "Training progress:   3%|▎         | 10/300 [00:01<00:47,  6.15it/s]2025-03-17 01:11:27,701 - sciml.model.deeponet.deeponet - INFO - Epoch 11/300\n",
      "2025-03-17 01:11:27,702 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.276427\n",
      "2025-03-17 01:11:27,702 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.243659\n",
      "Training progress:   4%|▎         | 11/300 [00:01<00:45,  6.32it/s]2025-03-17 01:11:27,854 - sciml.model.deeponet.deeponet - INFO - Epoch 12/300\n",
      "2025-03-17 01:11:27,855 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.270876\n",
      "2025-03-17 01:11:27,856 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.236587\n",
      "Training progress:   4%|▍         | 12/300 [00:02<00:45,  6.38it/s]2025-03-17 01:11:28,011 - sciml.model.deeponet.deeponet - INFO - Epoch 13/300\n",
      "2025-03-17 01:11:28,011 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.269086\n",
      "2025-03-17 01:11:28,012 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.231974\n",
      "Training progress:   4%|▍         | 13/300 [00:02<00:44,  6.39it/s]2025-03-17 01:11:28,162 - sciml.model.deeponet.deeponet - INFO - Epoch 14/300\n",
      "2025-03-17 01:11:28,163 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.270167\n",
      "2025-03-17 01:11:28,163 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.229131\n",
      "Training progress:   5%|▍         | 14/300 [00:02<00:44,  6.45it/s]2025-03-17 01:11:28,311 - sciml.model.deeponet.deeponet - INFO - Epoch 15/300\n",
      "2025-03-17 01:11:28,312 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.270435\n",
      "2025-03-17 01:11:28,312 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.226755\n",
      "Training progress:   5%|▌         | 15/300 [00:02<00:43,  6.53it/s]2025-03-17 01:11:28,460 - sciml.model.deeponet.deeponet - INFO - Epoch 16/300\n",
      "2025-03-17 01:11:28,461 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.267355\n",
      "2025-03-17 01:11:28,461 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.224371\n",
      "Training progress:   5%|▌         | 16/300 [00:02<00:43,  6.57it/s]2025-03-17 01:11:28,610 - sciml.model.deeponet.deeponet - INFO - Epoch 17/300\n",
      "2025-03-17 01:11:28,611 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.261619\n",
      "2025-03-17 01:11:28,611 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.222321\n",
      "Training progress:   6%|▌         | 17/300 [00:02<00:42,  6.60it/s]2025-03-17 01:11:28,761 - sciml.model.deeponet.deeponet - INFO - Epoch 18/300\n",
      "2025-03-17 01:11:28,762 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.255351\n",
      "2025-03-17 01:11:28,762 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220994\n",
      "Training progress:   6%|▌         | 18/300 [00:02<00:42,  6.61it/s]2025-03-17 01:11:28,911 - sciml.model.deeponet.deeponet - INFO - Epoch 19/300\n",
      "2025-03-17 01:11:28,911 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.250249\n",
      "2025-03-17 01:11:28,912 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220488\n",
      "Training progress:   6%|▋         | 19/300 [00:03<00:42,  6.64it/s]2025-03-17 01:11:29,062 - sciml.model.deeponet.deeponet - INFO - Epoch 20/300\n",
      "2025-03-17 01:11:29,062 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.246798\n",
      "2025-03-17 01:11:29,063 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220499\n",
      "Training progress:   7%|▋         | 20/300 [00:03<00:42,  6.62it/s]2025-03-17 01:11:29,210 - sciml.model.deeponet.deeponet - INFO - Epoch 21/300\n",
      "2025-03-17 01:11:29,210 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.244599\n",
      "2025-03-17 01:11:29,211 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220461\n",
      "Training progress:   7%|▋         | 21/300 [00:03<00:41,  6.66it/s]2025-03-17 01:11:29,359 - sciml.model.deeponet.deeponet - INFO - Epoch 22/300\n",
      "2025-03-17 01:11:29,360 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.242841\n",
      "2025-03-17 01:11:29,361 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.219856\n",
      "Training progress:   7%|▋         | 22/300 [00:03<00:41,  6.67it/s]2025-03-17 01:11:29,516 - sciml.model.deeponet.deeponet - INFO - Epoch 23/300\n",
      "2025-03-17 01:11:29,517 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.240823\n",
      "2025-03-17 01:11:29,518 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.218394\n",
      "Training progress:   8%|▊         | 23/300 [00:03<00:42,  6.58it/s]2025-03-17 01:11:29,667 - sciml.model.deeponet.deeponet - INFO - Epoch 24/300\n",
      "2025-03-17 01:11:29,668 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.238120\n",
      "2025-03-17 01:11:29,669 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.215984\n",
      "Training progress:   8%|▊         | 24/300 [00:03<00:41,  6.59it/s]2025-03-17 01:11:29,818 - sciml.model.deeponet.deeponet - INFO - Epoch 25/300\n",
      "2025-03-17 01:11:29,818 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.234592\n",
      "2025-03-17 01:11:29,819 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.212683\n",
      "Training progress:   8%|▊         | 25/300 [00:03<00:41,  6.61it/s]2025-03-17 01:11:29,969 - sciml.model.deeponet.deeponet - INFO - Epoch 26/300\n",
      "2025-03-17 01:11:29,969 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.230324\n",
      "2025-03-17 01:11:29,970 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.208844\n",
      "Training progress:   9%|▊         | 26/300 [00:04<00:41,  6.62it/s]2025-03-17 01:11:30,117 - sciml.model.deeponet.deeponet - INFO - Epoch 27/300\n",
      "2025-03-17 01:11:30,118 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.225610\n",
      "2025-03-17 01:11:30,118 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.204944\n",
      "Training progress:   9%|▉         | 27/300 [00:04<00:41,  6.65it/s]2025-03-17 01:11:30,265 - sciml.model.deeponet.deeponet - INFO - Epoch 28/300\n",
      "2025-03-17 01:11:30,266 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.220879\n",
      "2025-03-17 01:11:30,267 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.201430\n",
      "Training progress:   9%|▉         | 28/300 [00:04<00:40,  6.68it/s]2025-03-17 01:11:30,414 - sciml.model.deeponet.deeponet - INFO - Epoch 29/300\n",
      "2025-03-17 01:11:30,414 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.216552\n",
      "2025-03-17 01:11:30,415 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.198656\n",
      "Training progress:  10%|▉         | 29/300 [00:04<00:40,  6.70it/s]2025-03-17 01:11:30,562 - sciml.model.deeponet.deeponet - INFO - Epoch 30/300\n",
      "2025-03-17 01:11:30,563 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.212769\n",
      "2025-03-17 01:11:30,563 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.196661\n",
      "Training progress:  10%|█         | 30/300 [00:04<00:40,  6.71it/s]2025-03-17 01:11:30,711 - sciml.model.deeponet.deeponet - INFO - Epoch 31/300\n",
      "2025-03-17 01:11:30,712 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.209186\n",
      "2025-03-17 01:11:30,712 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.195246\n",
      "Training progress:  10%|█         | 31/300 [00:04<00:40,  6.70it/s]2025-03-17 01:11:30,860 - sciml.model.deeponet.deeponet - INFO - Epoch 32/300\n",
      "2025-03-17 01:11:30,861 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.205231\n",
      "2025-03-17 01:11:30,862 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.194448\n",
      "Training progress:  11%|█         | 32/300 [00:05<00:39,  6.71it/s]2025-03-17 01:11:31,011 - sciml.model.deeponet.deeponet - INFO - Epoch 33/300\n",
      "2025-03-17 01:11:31,012 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.200748\n",
      "2025-03-17 01:11:31,013 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.194670\n",
      "Training progress:  11%|█         | 33/300 [00:05<00:40,  6.67it/s]2025-03-17 01:11:31,161 - sciml.model.deeponet.deeponet - INFO - Epoch 34/300\n",
      "2025-03-17 01:11:31,162 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.196649\n",
      "2025-03-17 01:11:31,162 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.195574\n",
      "Training progress:  11%|█▏        | 34/300 [00:05<00:39,  6.68it/s]2025-03-17 01:11:31,313 - sciml.model.deeponet.deeponet - INFO - Epoch 35/300\n",
      "2025-03-17 01:11:31,313 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.194079\n",
      "2025-03-17 01:11:31,314 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.195763\n",
      "Training progress:  12%|█▏        | 35/300 [00:05<00:39,  6.66it/s]2025-03-17 01:11:31,461 - sciml.model.deeponet.deeponet - INFO - Epoch 36/300\n",
      "2025-03-17 01:11:31,462 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.192177\n",
      "2025-03-17 01:11:31,462 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.194338\n",
      "Training progress:  12%|█▏        | 36/300 [00:05<00:39,  6.68it/s]2025-03-17 01:11:31,613 - sciml.model.deeponet.deeponet - INFO - Epoch 37/300\n",
      "2025-03-17 01:11:31,614 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.189628\n",
      "2025-03-17 01:11:31,615 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.191402\n",
      "Training progress:  12%|█▏        | 37/300 [00:05<00:39,  6.65it/s]2025-03-17 01:11:31,761 - sciml.model.deeponet.deeponet - INFO - Epoch 38/300\n",
      "2025-03-17 01:11:31,761 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.186312\n",
      "2025-03-17 01:11:31,762 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.187640\n",
      "Training progress:  13%|█▎        | 38/300 [00:05<00:39,  6.69it/s]2025-03-17 01:11:29,429 - sciml.model.deeponet.deeponet - INFO - Epoch 39/300\n",
      "2025-03-17 01:11:29,430 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.182878\n",
      "2025-03-17 01:11:29,430 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.183951\n",
      "2025-03-17 01:11:29,577 - sciml.model.deeponet.deeponet - INFO - Epoch 40/300\n",
      "2025-03-17 01:11:29,578 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.179853\n",
      "2025-03-17 01:11:29,579 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.180927\n",
      "2025-03-17 01:11:29,727 - sciml.model.deeponet.deeponet - INFO - Epoch 41/300\n",
      "2025-03-17 01:11:29,728 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.176936\n",
      "2025-03-17 01:11:29,728 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.178793\n",
      "2025-03-17 01:11:29,877 - sciml.model.deeponet.deeponet - INFO - Epoch 42/300\n",
      "2025-03-17 01:11:29,877 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.173549\n",
      "2025-03-17 01:11:29,878 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.177564\n",
      "2025-03-17 01:11:30,028 - sciml.model.deeponet.deeponet - INFO - Epoch 43/300\n",
      "2025-03-17 01:11:30,029 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.169836\n",
      "2025-03-17 01:11:30,030 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.177019\n",
      "2025-03-17 01:11:30,175 - sciml.model.deeponet.deeponet - INFO - Epoch 44/300\n",
      "2025-03-17 01:11:30,176 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.166438\n",
      "2025-03-17 01:11:30,177 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.176458\n",
      "2025-03-17 01:11:30,326 - sciml.model.deeponet.deeponet - INFO - Epoch 45/300\n",
      "2025-03-17 01:11:30,327 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.163481\n",
      "2025-03-17 01:11:30,327 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.175015\n",
      "2025-03-17 01:11:30,472 - sciml.model.deeponet.deeponet - INFO - Epoch 46/300\n",
      "2025-03-17 01:11:30,473 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.160424\n",
      "2025-03-17 01:11:30,474 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.172435\n",
      "2025-03-17 01:11:30,623 - sciml.model.deeponet.deeponet - INFO - Epoch 47/300\n",
      "2025-03-17 01:11:30,624 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.156962\n",
      "2025-03-17 01:11:30,625 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.169210\n",
      "2025-03-17 01:11:30,776 - sciml.model.deeponet.deeponet - INFO - Epoch 48/300\n",
      "2025-03-17 01:11:30,777 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.153442\n",
      "2025-03-17 01:11:30,777 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.166075\n",
      "2025-03-17 01:11:30,923 - sciml.model.deeponet.deeponet - INFO - Epoch 49/300\n",
      "2025-03-17 01:11:30,924 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.150264\n",
      "2025-03-17 01:11:30,924 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.163364\n",
      "2025-03-17 01:11:31,072 - sciml.model.deeponet.deeponet - INFO - Epoch 50/300\n",
      "2025-03-17 01:11:31,073 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.147194\n",
      "2025-03-17 01:11:31,073 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.161048\n",
      "2025-03-17 01:11:31,227 - sciml.model.deeponet.deeponet - INFO - Epoch 51/300\n",
      "2025-03-17 01:11:31,227 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.143903\n",
      "2025-03-17 01:11:31,228 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.159191\n",
      "2025-03-17 01:11:31,376 - sciml.model.deeponet.deeponet - INFO - Epoch 52/300\n",
      "2025-03-17 01:11:31,377 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.140760\n",
      "2025-03-17 01:11:31,378 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.157564\n",
      "2025-03-17 01:11:31,527 - sciml.model.deeponet.deeponet - INFO - Epoch 53/300\n",
      "2025-03-17 01:11:31,527 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.138166\n",
      "2025-03-17 01:11:31,528 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.155390\n",
      "2025-03-17 01:11:31,673 - sciml.model.deeponet.deeponet - INFO - Epoch 54/300\n",
      "2025-03-17 01:11:31,674 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.135743\n",
      "2025-03-17 01:11:31,674 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.152410\n",
      "2025-03-17 01:11:31,821 - sciml.model.deeponet.deeponet - INFO - Epoch 55/300\n",
      "2025-03-17 01:11:31,821 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.133330\n",
      "2025-03-17 01:11:31,822 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.149492\n",
      "2025-03-17 01:11:31,972 - sciml.model.deeponet.deeponet - INFO - Epoch 56/300\n",
      "2025-03-17 01:11:31,973 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.131380\n",
      "2025-03-17 01:11:31,974 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.147224\n",
      "Training progress:  19%|█▊        | 56/300 [00:06<00:06, 36.28it/s]2025-03-17 01:11:32,118 - sciml.model.deeponet.deeponet - INFO - Epoch 57/300\n",
      "2025-03-17 01:11:32,119 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.129653\n",
      "2025-03-17 01:11:32,120 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.145519\n",
      "2025-03-17 01:11:32,263 - sciml.model.deeponet.deeponet - INFO - Epoch 58/300\n",
      "2025-03-17 01:11:32,264 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.127938\n",
      "2025-03-17 01:11:32,264 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.144055\n",
      "2025-03-17 01:11:32,411 - sciml.model.deeponet.deeponet - INFO - Epoch 59/300\n",
      "2025-03-17 01:11:32,412 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.126597\n",
      "2025-03-17 01:11:32,413 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.142048\n",
      "2025-03-17 01:11:32,561 - sciml.model.deeponet.deeponet - INFO - Epoch 60/300\n",
      "2025-03-17 01:11:32,562 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.125245\n",
      "2025-03-17 01:11:32,563 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.139623\n",
      "Training progress:  20%|██        | 60/300 [00:06<00:12, 18.58it/s]2025-03-17 01:11:32,718 - sciml.model.deeponet.deeponet - INFO - Epoch 61/300\n",
      "2025-03-17 01:11:32,719 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.123802\n",
      "2025-03-17 01:11:32,720 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.137603\n",
      "2025-03-17 01:11:32,878 - sciml.model.deeponet.deeponet - INFO - Epoch 62/300\n",
      "2025-03-17 01:11:32,878 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.122544\n",
      "2025-03-17 01:11:32,879 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.136115\n",
      "2025-03-17 01:11:33,037 - sciml.model.deeponet.deeponet - INFO - Epoch 63/300\n",
      "2025-03-17 01:11:33,037 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.121174\n",
      "2025-03-17 01:11:33,038 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.135035\n",
      "Training progress:  21%|██        | 63/300 [00:07<00:17, 13.55it/s]2025-03-17 01:11:33,185 - sciml.model.deeponet.deeponet - INFO - Epoch 64/300\n",
      "2025-03-17 01:11:33,186 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.119981\n",
      "2025-03-17 01:11:33,186 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.133919\n",
      "2025-03-17 01:11:33,338 - sciml.model.deeponet.deeponet - INFO - Epoch 65/300\n",
      "2025-03-17 01:11:33,338 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.118888\n",
      "2025-03-17 01:11:33,339 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.132829\n",
      "Training progress:  22%|██▏       | 65/300 [00:07<00:20, 11.70it/s]2025-03-17 01:11:33,486 - sciml.model.deeponet.deeponet - INFO - Epoch 66/300\n",
      "2025-03-17 01:11:33,486 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.117833\n",
      "2025-03-17 01:11:33,487 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.132224\n",
      "2025-03-17 01:11:33,632 - sciml.model.deeponet.deeponet - INFO - Epoch 67/300\n",
      "2025-03-17 01:11:33,633 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.117005\n",
      "2025-03-17 01:11:33,633 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131888\n",
      "Training progress:  22%|██▏       | 67/300 [00:07<00:22, 10.36it/s]2025-03-17 01:11:33,782 - sciml.model.deeponet.deeponet - INFO - Epoch 68/300\n",
      "2025-03-17 01:11:33,782 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.116124\n",
      "2025-03-17 01:11:33,783 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131720\n",
      "2025-03-17 01:11:33,940 - sciml.model.deeponet.deeponet - INFO - Epoch 69/300\n",
      "2025-03-17 01:11:33,940 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.115453\n",
      "2025-03-17 01:11:33,941 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131367\n",
      "Training progress:  23%|██▎       | 69/300 [00:08<00:25,  9.23it/s]2025-03-17 01:11:34,091 - sciml.model.deeponet.deeponet - INFO - Epoch 70/300\n",
      "2025-03-17 01:11:34,092 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114731\n",
      "2025-03-17 01:11:34,093 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.130901\n",
      "2025-03-17 01:11:34,238 - sciml.model.deeponet.deeponet - INFO - Epoch 71/300\n",
      "2025-03-17 01:11:34,239 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114035\n",
      "2025-03-17 01:11:34,240 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.130289\n",
      "Training progress:  24%|██▎       | 71/300 [00:08<00:26,  8.50it/s]2025-03-17 01:11:34,393 - sciml.model.deeponet.deeponet - INFO - Epoch 72/300\n",
      "2025-03-17 01:11:34,393 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.113263\n",
      "2025-03-17 01:11:34,394 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.129532\n",
      "Training progress:  24%|██▍       | 72/300 [00:08<00:27,  8.15it/s]2025-03-17 01:11:34,545 - sciml.model.deeponet.deeponet - INFO - Epoch 73/300\n",
      "2025-03-17 01:11:34,546 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.112422\n",
      "2025-03-17 01:11:34,547 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.128617\n",
      "Training progress:  24%|██▍       | 73/300 [00:08<00:28,  7.83it/s]2025-03-17 01:11:34,696 - sciml.model.deeponet.deeponet - INFO - Epoch 74/300\n",
      "2025-03-17 01:11:34,697 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.111603\n",
      "2025-03-17 01:11:34,697 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.127530\n",
      "Training progress:  25%|██▍       | 74/300 [00:08<00:29,  7.58it/s]2025-03-17 01:11:34,846 - sciml.model.deeponet.deeponet - INFO - Epoch 75/300\n",
      "2025-03-17 01:11:34,846 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.110743\n",
      "2025-03-17 01:11:34,847 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.126516\n",
      "Training progress:  25%|██▌       | 75/300 [00:09<00:30,  7.36it/s]2025-03-17 01:11:34,997 - sciml.model.deeponet.deeponet - INFO - Epoch 76/300\n",
      "2025-03-17 01:11:34,998 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.109996\n",
      "2025-03-17 01:11:34,998 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125611\n",
      "Training progress:  25%|██▌       | 76/300 [00:09<00:31,  7.17it/s]2025-03-17 01:11:35,148 - sciml.model.deeponet.deeponet - INFO - Epoch 77/300\n",
      "2025-03-17 01:11:35,149 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.109256\n",
      "2025-03-17 01:11:35,149 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.124890\n",
      "Training progress:  26%|██▌       | 77/300 [00:09<00:31,  7.02it/s]2025-03-17 01:11:35,296 - sciml.model.deeponet.deeponet - INFO - Epoch 78/300\n",
      "2025-03-17 01:11:35,297 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108675\n",
      "2025-03-17 01:11:35,298 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.124101\n",
      "Training progress:  26%|██▌       | 78/300 [00:09<00:31,  6.94it/s]2025-03-17 01:11:35,448 - sciml.model.deeponet.deeponet - INFO - Epoch 79/300\n",
      "2025-03-17 01:11:35,449 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108059\n",
      "2025-03-17 01:11:35,450 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.123473\n",
      "Training progress:  26%|██▋       | 79/300 [00:09<00:32,  6.84it/s]2025-03-17 01:11:35,604 - sciml.model.deeponet.deeponet - INFO - Epoch 80/300\n",
      "2025-03-17 01:11:35,604 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.107556\n",
      "2025-03-17 01:11:35,605 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.122958\n",
      "Training progress:  27%|██▋       | 80/300 [00:09<00:32,  6.72it/s]2025-03-17 01:11:35,756 - sciml.model.deeponet.deeponet - INFO - Epoch 81/300\n",
      "2025-03-17 01:11:35,757 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106999\n",
      "2025-03-17 01:11:35,758 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.122447\n",
      "Training progress:  27%|██▋       | 81/300 [00:09<00:32,  6.68it/s]2025-03-17 01:11:35,916 - sciml.model.deeponet.deeponet - INFO - Epoch 82/300\n",
      "2025-03-17 01:11:35,917 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106477\n",
      "2025-03-17 01:11:35,917 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121728\n",
      "Training progress:  27%|██▋       | 82/300 [00:10<00:33,  6.55it/s]2025-03-17 01:11:36,076 - sciml.model.deeponet.deeponet - INFO - Epoch 83/300\n",
      "2025-03-17 01:11:36,077 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105893\n",
      "2025-03-17 01:11:36,077 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121125\n",
      "Training progress:  28%|██▊       | 83/300 [00:10<00:33,  6.46it/s]2025-03-17 01:11:36,233 - sciml.model.deeponet.deeponet - INFO - Epoch 84/300\n",
      "2025-03-17 01:11:36,234 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105356\n",
      "2025-03-17 01:11:36,234 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.120751\n",
      "Training progress:  28%|██▊       | 84/300 [00:10<00:33,  6.43it/s]2025-03-17 01:11:36,392 - sciml.model.deeponet.deeponet - INFO - Epoch 85/300\n",
      "2025-03-17 01:11:36,392 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104817\n",
      "2025-03-17 01:11:36,393 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.120405\n",
      "Training progress:  28%|██▊       | 85/300 [00:10<00:33,  6.39it/s]2025-03-17 01:11:36,549 - sciml.model.deeponet.deeponet - INFO - Epoch 86/300\n",
      "2025-03-17 01:11:36,549 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104323\n",
      "2025-03-17 01:11:36,550 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.120016\n",
      "Training progress:  29%|██▊       | 86/300 [00:10<00:33,  6.39it/s]2025-03-17 01:11:36,704 - sciml.model.deeponet.deeponet - INFO - Epoch 87/300\n",
      "2025-03-17 01:11:36,705 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103865\n",
      "2025-03-17 01:11:36,705 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.119685\n",
      "Training progress:  29%|██▉       | 87/300 [00:10<00:33,  6.41it/s]2025-03-17 01:11:36,858 - sciml.model.deeponet.deeponet - INFO - Epoch 88/300\n",
      "2025-03-17 01:11:36,859 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103436\n",
      "2025-03-17 01:11:36,860 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.119237\n",
      "Training progress:  29%|██▉       | 88/300 [00:11<00:33,  6.42it/s]2025-03-17 01:11:37,016 - sciml.model.deeponet.deeponet - INFO - Epoch 89/300\n",
      "2025-03-17 01:11:37,017 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103038\n",
      "2025-03-17 01:11:37,017 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.118487\n",
      "Training progress:  30%|██▉       | 89/300 [00:11<00:32,  6.40it/s]2025-03-17 01:11:37,181 - sciml.model.deeponet.deeponet - INFO - Epoch 90/300\n",
      "2025-03-17 01:11:37,182 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102615\n",
      "2025-03-17 01:11:37,183 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.117673\n",
      "Training progress:  30%|███       | 90/300 [00:11<00:33,  6.28it/s]2025-03-17 01:11:37,335 - sciml.model.deeponet.deeponet - INFO - Epoch 91/300\n",
      "2025-03-17 01:11:37,336 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102203\n",
      "2025-03-17 01:11:37,337 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116913\n",
      "Training progress:  30%|███       | 91/300 [00:11<00:32,  6.35it/s]2025-03-17 01:11:37,503 - sciml.model.deeponet.deeponet - INFO - Epoch 92/300\n",
      "2025-03-17 01:11:37,504 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101796\n",
      "2025-03-17 01:11:37,504 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116078\n",
      "Training progress:  31%|███       | 92/300 [00:11<00:33,  6.23it/s]2025-03-17 01:11:37,657 - sciml.model.deeponet.deeponet - INFO - Epoch 93/300\n",
      "2025-03-17 01:11:37,657 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101386\n",
      "2025-03-17 01:11:37,658 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115406\n",
      "Training progress:  31%|███       | 93/300 [00:11<00:32,  6.32it/s]2025-03-17 01:11:37,813 - sciml.model.deeponet.deeponet - INFO - Epoch 94/300\n",
      "2025-03-17 01:11:37,813 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100999\n",
      "2025-03-17 01:11:37,814 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114814\n",
      "Training progress:  31%|███▏      | 94/300 [00:11<00:32,  6.34it/s]2025-03-17 01:11:37,962 - sciml.model.deeponet.deeponet - INFO - Epoch 95/300\n",
      "2025-03-17 01:11:37,963 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100642\n",
      "2025-03-17 01:11:37,963 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114264\n",
      "Training progress:  32%|███▏      | 95/300 [00:12<00:31,  6.44it/s]2025-03-17 01:11:38,116 - sciml.model.deeponet.deeponet - INFO - Epoch 96/300\n",
      "2025-03-17 01:11:38,116 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100301\n",
      "2025-03-17 01:11:38,117 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113898\n",
      "Training progress:  32%|███▏      | 96/300 [00:12<00:31,  6.46it/s]2025-03-17 01:11:38,268 - sciml.model.deeponet.deeponet - INFO - Epoch 97/300\n",
      "2025-03-17 01:11:38,269 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099958\n",
      "2025-03-17 01:11:38,270 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113415\n",
      "Training progress:  32%|███▏      | 97/300 [00:12<00:31,  6.48it/s]2025-03-17 01:11:38,426 - sciml.model.deeponet.deeponet - INFO - Epoch 98/300\n",
      "2025-03-17 01:11:38,427 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099591\n",
      "2025-03-17 01:11:38,427 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113040\n",
      "Training progress:  33%|███▎      | 98/300 [00:12<00:31,  6.44it/s]2025-03-17 01:11:38,574 - sciml.model.deeponet.deeponet - INFO - Epoch 99/300\n",
      "2025-03-17 01:11:38,575 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099197\n",
      "2025-03-17 01:11:38,575 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112646\n",
      "Training progress:  33%|███▎      | 99/300 [00:12<00:30,  6.54it/s]2025-03-17 01:11:38,722 - sciml.model.deeponet.deeponet - INFO - Epoch 100/300\n",
      "2025-03-17 01:11:38,723 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098815\n",
      "2025-03-17 01:11:38,723 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112432\n",
      "Training progress:  33%|███▎      | 100/300 [00:12<00:30,  6.60it/s]2025-03-17 01:11:38,873 - sciml.model.deeponet.deeponet - INFO - Epoch 101/300\n",
      "2025-03-17 01:11:38,874 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098445\n",
      "2025-03-17 01:11:38,875 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112262\n",
      "Training progress:  34%|███▎      | 101/300 [00:13<00:30,  6.60it/s]2025-03-17 01:11:39,022 - sciml.model.deeponet.deeponet - INFO - Epoch 102/300\n",
      "2025-03-17 01:11:39,022 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098086\n",
      "2025-03-17 01:11:39,023 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112226\n",
      "Training progress:  34%|███▍      | 102/300 [00:13<00:29,  6.65it/s]2025-03-17 01:11:39,167 - sciml.model.deeponet.deeponet - INFO - Epoch 103/300\n",
      "2025-03-17 01:11:39,168 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097735\n",
      "2025-03-17 01:11:39,169 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112054\n",
      "Training progress:  34%|███▍      | 103/300 [00:13<00:29,  6.71it/s]2025-03-17 01:11:39,317 - sciml.model.deeponet.deeponet - INFO - Epoch 104/300\n",
      "2025-03-17 01:11:39,317 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097392\n",
      "2025-03-17 01:11:39,318 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111802\n",
      "Training progress:  35%|███▍      | 104/300 [00:13<00:29,  6.71it/s]2025-03-17 01:11:39,470 - sciml.model.deeponet.deeponet - INFO - Epoch 105/300\n",
      "2025-03-17 01:11:39,471 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097047\n",
      "2025-03-17 01:11:39,471 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111340\n",
      "Training progress:  35%|███▌      | 105/300 [00:13<00:29,  6.64it/s]2025-03-17 01:11:39,624 - sciml.model.deeponet.deeponet - INFO - Epoch 106/300\n",
      "2025-03-17 01:11:39,625 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096712\n",
      "2025-03-17 01:11:39,625 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110906\n",
      "Training progress:  35%|███▌      | 106/300 [00:13<00:29,  6.60it/s]2025-03-17 01:11:39,796 - sciml.model.deeponet.deeponet - INFO - Epoch 107/300\n",
      "2025-03-17 01:11:39,797 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096394\n",
      "2025-03-17 01:11:39,797 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110401\n",
      "Training progress:  36%|███▌      | 107/300 [00:13<00:30,  6.34it/s]2025-03-17 01:11:39,944 - sciml.model.deeponet.deeponet - INFO - Epoch 108/300\n",
      "2025-03-17 01:11:39,944 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096083\n",
      "2025-03-17 01:11:39,945 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110190\n",
      "Training progress:  36%|███▌      | 108/300 [00:14<00:29,  6.46it/s]2025-03-17 01:11:40,092 - sciml.model.deeponet.deeponet - INFO - Epoch 109/300\n",
      "2025-03-17 01:11:40,092 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095809\n",
      "2025-03-17 01:11:40,093 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109731\n",
      "Training progress:  36%|███▋      | 109/300 [00:14<00:29,  6.55it/s]2025-03-17 01:11:40,239 - sciml.model.deeponet.deeponet - INFO - Epoch 110/300\n",
      "2025-03-17 01:11:40,240 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095739\n",
      "2025-03-17 01:11:40,240 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110909\n",
      "Training progress:  37%|███▋      | 110/300 [00:14<00:28,  6.62it/s]2025-03-17 01:11:40,390 - sciml.model.deeponet.deeponet - INFO - Epoch 111/300\n",
      "2025-03-17 01:11:40,390 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096482\n",
      "2025-03-17 01:11:40,391 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110395\n",
      "Training progress:  37%|███▋      | 111/300 [00:14<00:28,  6.63it/s]2025-03-17 01:11:40,541 - sciml.model.deeponet.deeponet - INFO - Epoch 112/300\n",
      "2025-03-17 01:11:40,542 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097730\n",
      "2025-03-17 01:11:40,542 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111055\n",
      "Training progress:  37%|███▋      | 112/300 [00:14<00:28,  6.63it/s]2025-03-17 01:11:40,689 - sciml.model.deeponet.deeponet - INFO - Epoch 113/300\n",
      "2025-03-17 01:11:40,689 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096786\n",
      "2025-03-17 01:11:40,689 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108568\n",
      "Training progress:  38%|███▊      | 113/300 [00:14<00:28,  6.67it/s]2025-03-17 01:11:40,837 - sciml.model.deeponet.deeponet - INFO - Epoch 114/300\n",
      "2025-03-17 01:11:40,837 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094497\n",
      "2025-03-17 01:11:40,838 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109291\n",
      "Training progress:  38%|███▊      | 114/300 [00:15<00:27,  6.69it/s]2025-03-17 01:11:40,984 - sciml.model.deeponet.deeponet - INFO - Epoch 115/300\n",
      "2025-03-17 01:11:40,985 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096806\n",
      "2025-03-17 01:11:40,986 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109802\n",
      "Training progress:  38%|███▊      | 115/300 [00:15<00:27,  6.70it/s]2025-03-17 01:11:41,133 - sciml.model.deeponet.deeponet - INFO - Epoch 116/300\n",
      "2025-03-17 01:11:41,134 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095442\n",
      "2025-03-17 01:11:41,134 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108809\n",
      "Training progress:  39%|███▊      | 116/300 [00:15<00:27,  6.72it/s]2025-03-17 01:11:41,282 - sciml.model.deeponet.deeponet - INFO - Epoch 117/300\n",
      "2025-03-17 01:11:41,283 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094442\n",
      "2025-03-17 01:11:41,283 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108683\n",
      "Training progress:  39%|███▉      | 117/300 [00:15<00:27,  6.72it/s]2025-03-17 01:11:41,430 - sciml.model.deeponet.deeponet - INFO - Epoch 118/300\n",
      "2025-03-17 01:11:41,431 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096029\n",
      "2025-03-17 01:11:41,431 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107713\n",
      "Training progress:  39%|███▉      | 118/300 [00:15<00:27,  6.74it/s]2025-03-17 01:11:41,579 - sciml.model.deeponet.deeponet - INFO - Epoch 119/300\n",
      "2025-03-17 01:11:41,580 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093587\n",
      "2025-03-17 01:11:41,580 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109011\n",
      "Training progress:  40%|███▉      | 119/300 [00:15<00:26,  6.72it/s]2025-03-17 01:11:41,730 - sciml.model.deeponet.deeponet - INFO - Epoch 120/300\n",
      "2025-03-17 01:11:41,730 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094804\n",
      "2025-03-17 01:11:41,731 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106892\n",
      "Training progress:  40%|████      | 120/300 [00:15<00:26,  6.69it/s]2025-03-17 01:11:41,878 - sciml.model.deeponet.deeponet - INFO - Epoch 121/300\n",
      "2025-03-17 01:11:41,879 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093547\n",
      "2025-03-17 01:11:41,879 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106743\n",
      "Training progress:  40%|████      | 121/300 [00:16<00:26,  6.71it/s]2025-03-17 01:11:42,024 - sciml.model.deeponet.deeponet - INFO - Epoch 122/300\n",
      "2025-03-17 01:11:42,025 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093683\n",
      "2025-03-17 01:11:42,025 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107766\n",
      "Training progress:  41%|████      | 122/300 [00:16<00:26,  6.76it/s]2025-03-17 01:11:42,173 - sciml.model.deeponet.deeponet - INFO - Epoch 123/300\n",
      "2025-03-17 01:11:42,174 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093948\n",
      "2025-03-17 01:11:42,174 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106524\n",
      "Training progress:  41%|████      | 123/300 [00:16<00:26,  6.74it/s]2025-03-17 01:11:42,321 - sciml.model.deeponet.deeponet - INFO - Epoch 124/300\n",
      "2025-03-17 01:11:42,322 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092962\n",
      "2025-03-17 01:11:42,323 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106297\n",
      "Training progress:  41%|████▏     | 124/300 [00:16<00:26,  6.74it/s]2025-03-17 01:11:42,470 - sciml.model.deeponet.deeponet - INFO - Epoch 125/300\n",
      "2025-03-17 01:11:42,470 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093958\n",
      "2025-03-17 01:11:42,471 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105879\n",
      "Training progress:  42%|████▏     | 125/300 [00:16<00:25,  6.74it/s]2025-03-17 01:11:42,619 - sciml.model.deeponet.deeponet - INFO - Epoch 126/300\n",
      "2025-03-17 01:11:42,620 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092539\n",
      "2025-03-17 01:11:42,620 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106656\n",
      "Training progress:  42%|████▏     | 126/300 [00:16<00:25,  6.73it/s]2025-03-17 01:11:42,770 - sciml.model.deeponet.deeponet - INFO - Epoch 127/300\n",
      "2025-03-17 01:11:42,771 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093175\n",
      "2025-03-17 01:11:42,772 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105225\n",
      "Training progress:  42%|████▏     | 127/300 [00:16<00:25,  6.69it/s]2025-03-17 01:11:42,919 - sciml.model.deeponet.deeponet - INFO - Epoch 128/300\n",
      "2025-03-17 01:11:42,920 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092438\n",
      "2025-03-17 01:11:42,920 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104997\n",
      "Training progress:  43%|████▎     | 128/300 [00:17<00:25,  6.70it/s]2025-03-17 01:11:43,068 - sciml.model.deeponet.deeponet - INFO - Epoch 129/300\n",
      "2025-03-17 01:11:43,068 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092497\n",
      "2025-03-17 01:11:43,069 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105706\n",
      "Training progress:  43%|████▎     | 129/300 [00:17<00:25,  6.71it/s]2025-03-17 01:11:43,215 - sciml.model.deeponet.deeponet - INFO - Epoch 130/300\n",
      "2025-03-17 01:11:43,216 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092591\n",
      "2025-03-17 01:11:43,216 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104827\n",
      "Training progress:  43%|████▎     | 130/300 [00:17<00:25,  6.73it/s]2025-03-17 01:11:43,365 - sciml.model.deeponet.deeponet - INFO - Epoch 131/300\n",
      "2025-03-17 01:11:43,366 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091981\n",
      "2025-03-17 01:11:43,366 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104449\n",
      "Training progress:  44%|████▎     | 131/300 [00:17<00:25,  6.71it/s]2025-03-17 01:11:43,515 - sciml.model.deeponet.deeponet - INFO - Epoch 132/300\n",
      "2025-03-17 01:11:43,516 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092527\n",
      "2025-03-17 01:11:43,516 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104390\n",
      "Training progress:  44%|████▍     | 132/300 [00:17<00:25,  6.69it/s]2025-03-17 01:11:43,662 - sciml.model.deeponet.deeponet - INFO - Epoch 133/300\n",
      "2025-03-17 01:11:43,663 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091712\n",
      "2025-03-17 01:11:43,663 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104709\n",
      "Training progress:  44%|████▍     | 133/300 [00:17<00:24,  6.73it/s]2025-03-17 01:11:43,816 - sciml.model.deeponet.deeponet - INFO - Epoch 134/300\n",
      "2025-03-17 01:11:43,816 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091963\n",
      "2025-03-17 01:11:43,817 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103733\n",
      "Training progress:  45%|████▍     | 134/300 [00:17<00:24,  6.66it/s]2025-03-17 01:11:43,964 - sciml.model.deeponet.deeponet - INFO - Epoch 135/300\n",
      "2025-03-17 01:11:43,965 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091694\n",
      "2025-03-17 01:11:43,965 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103494\n",
      "Training progress:  45%|████▌     | 135/300 [00:18<00:24,  6.69it/s]2025-03-17 01:11:44,111 - sciml.model.deeponet.deeponet - INFO - Epoch 136/300\n",
      "2025-03-17 01:11:44,112 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091406\n",
      "2025-03-17 01:11:44,112 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104061\n",
      "Training progress:  45%|████▌     | 136/300 [00:18<00:24,  6.72it/s]2025-03-17 01:11:44,261 - sciml.model.deeponet.deeponet - INFO - Epoch 137/300\n",
      "2025-03-17 01:11:44,262 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091623\n",
      "2025-03-17 01:11:44,262 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103208\n",
      "Training progress:  46%|████▌     | 137/300 [00:18<00:24,  6.71it/s]2025-03-17 01:11:44,408 - sciml.model.deeponet.deeponet - INFO - Epoch 138/300\n",
      "2025-03-17 01:11:44,409 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091103\n",
      "2025-03-17 01:11:44,410 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103029\n",
      "Training progress:  46%|████▌     | 138/300 [00:18<00:24,  6.73it/s]2025-03-17 01:11:44,557 - sciml.model.deeponet.deeponet - INFO - Epoch 139/300\n",
      "2025-03-17 01:11:44,558 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091286\n",
      "2025-03-17 01:11:44,558 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103430\n",
      "Training progress:  46%|████▋     | 139/300 [00:18<00:23,  6.73it/s]2025-03-17 01:11:44,706 - sciml.model.deeponet.deeponet - INFO - Epoch 140/300\n",
      "2025-03-17 01:11:44,707 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091069\n",
      "2025-03-17 01:11:44,708 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103077\n",
      "Training progress:  47%|████▋     | 140/300 [00:18<00:23,  6.71it/s]2025-03-17 01:11:44,854 - sciml.model.deeponet.deeponet - INFO - Epoch 141/300\n",
      "2025-03-17 01:11:44,854 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090829\n",
      "2025-03-17 01:11:44,855 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102628\n",
      "Training progress:  47%|████▋     | 141/300 [00:19<00:23,  6.74it/s]2025-03-17 01:11:45,003 - sciml.model.deeponet.deeponet - INFO - Epoch 142/300\n",
      "2025-03-17 01:11:45,004 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090968\n",
      "2025-03-17 01:11:45,004 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102675\n",
      "Training progress:  47%|████▋     | 142/300 [00:19<00:23,  6.72it/s]2025-03-17 01:11:45,151 - sciml.model.deeponet.deeponet - INFO - Epoch 143/300\n",
      "2025-03-17 01:11:45,151 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090611\n",
      "2025-03-17 01:11:45,152 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102706\n",
      "Training progress:  48%|████▊     | 143/300 [00:19<00:23,  6.75it/s]2025-03-17 01:11:45,300 - sciml.model.deeponet.deeponet - INFO - Epoch 144/300\n",
      "2025-03-17 01:11:45,300 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090606\n",
      "2025-03-17 01:11:45,301 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102127\n",
      "Training progress:  48%|████▊     | 144/300 [00:19<00:23,  6.73it/s]2025-03-17 01:11:45,450 - sciml.model.deeponet.deeponet - INFO - Epoch 145/300\n",
      "2025-03-17 01:11:45,450 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090574\n",
      "2025-03-17 01:11:45,451 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102152\n",
      "Training progress:  48%|████▊     | 145/300 [00:19<00:23,  6.71it/s]2025-03-17 01:11:45,598 - sciml.model.deeponet.deeponet - INFO - Epoch 146/300\n",
      "2025-03-17 01:11:45,599 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090280\n",
      "2025-03-17 01:11:45,599 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102417\n",
      "Training progress:  49%|████▊     | 146/300 [00:19<00:22,  6.72it/s]2025-03-17 01:11:45,746 - sciml.model.deeponet.deeponet - INFO - Epoch 147/300\n",
      "2025-03-17 01:11:45,747 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090336\n",
      "2025-03-17 01:11:45,747 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101785\n",
      "Training progress:  49%|████▉     | 147/300 [00:19<00:22,  6.73it/s]2025-03-17 01:11:45,895 - sciml.model.deeponet.deeponet - INFO - Epoch 148/300\n",
      "2025-03-17 01:11:45,896 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090228\n",
      "2025-03-17 01:11:45,896 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101753\n",
      "Training progress:  49%|████▉     | 148/300 [00:20<00:22,  6.73it/s]2025-03-17 01:11:46,043 - sciml.model.deeponet.deeponet - INFO - Epoch 149/300\n",
      "2025-03-17 01:11:46,044 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089998\n",
      "2025-03-17 01:11:46,045 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102037\n",
      "Training progress:  50%|████▉     | 149/300 [00:20<00:22,  6.73it/s]2025-03-17 01:11:46,193 - sciml.model.deeponet.deeponet - INFO - Epoch 150/300\n",
      "2025-03-17 01:11:46,194 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090051\n",
      "2025-03-17 01:11:46,194 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101388\n",
      "Training progress:  50%|█████     | 150/300 [00:20<00:22,  6.72it/s]2025-03-17 01:11:46,341 - sciml.model.deeponet.deeponet - INFO - Epoch 151/300\n",
      "2025-03-17 01:11:46,341 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089904\n",
      "2025-03-17 01:11:46,342 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101315\n",
      "Training progress:  50%|█████     | 151/300 [00:20<00:22,  6.73it/s]2025-03-17 01:11:46,486 - sciml.model.deeponet.deeponet - INFO - Epoch 152/300\n",
      "2025-03-17 01:11:46,487 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089715\n",
      "2025-03-17 01:11:46,487 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101488\n",
      "Training progress:  51%|█████     | 152/300 [00:20<00:21,  6.78it/s]2025-03-17 01:11:46,633 - sciml.model.deeponet.deeponet - INFO - Epoch 153/300\n",
      "2025-03-17 01:11:46,634 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089725\n",
      "2025-03-17 01:11:46,635 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100917\n",
      "Training progress:  51%|█████     | 153/300 [00:20<00:21,  6.77it/s]2025-03-17 01:11:46,786 - sciml.model.deeponet.deeponet - INFO - Epoch 154/300\n",
      "2025-03-17 01:11:46,787 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089609\n",
      "2025-03-17 01:11:46,787 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101024\n",
      "Training progress:  51%|█████▏    | 154/300 [00:20<00:21,  6.71it/s]2025-03-17 01:11:46,935 - sciml.model.deeponet.deeponet - INFO - Epoch 155/300\n",
      "2025-03-17 01:11:46,935 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089437\n",
      "2025-03-17 01:11:46,936 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101108\n",
      "Training progress:  52%|█████▏    | 155/300 [00:21<00:21,  6.71it/s]2025-03-17 01:11:47,080 - sciml.model.deeponet.deeponet - INFO - Epoch 156/300\n",
      "2025-03-17 01:11:47,081 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089384\n",
      "2025-03-17 01:11:47,081 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100733\n",
      "Training progress:  52%|█████▏    | 156/300 [00:21<00:21,  6.76it/s]2025-03-17 01:11:47,231 - sciml.model.deeponet.deeponet - INFO - Epoch 157/300\n",
      "2025-03-17 01:11:47,231 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089300\n",
      "2025-03-17 01:11:47,232 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100747\n",
      "Training progress:  52%|█████▏    | 157/300 [00:21<00:21,  6.72it/s]2025-03-17 01:11:47,377 - sciml.model.deeponet.deeponet - INFO - Epoch 158/300\n",
      "2025-03-17 01:11:47,377 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089161\n",
      "2025-03-17 01:11:47,378 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100647\n",
      "Training progress:  53%|█████▎    | 158/300 [00:21<00:21,  6.76it/s]2025-03-17 01:11:47,524 - sciml.model.deeponet.deeponet - INFO - Epoch 159/300\n",
      "2025-03-17 01:11:47,525 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089083\n",
      "2025-03-17 01:11:47,525 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100256\n",
      "Training progress:  53%|█████▎    | 159/300 [00:21<00:20,  6.77it/s]2025-03-17 01:11:47,674 - sciml.model.deeponet.deeponet - INFO - Epoch 160/300\n",
      "2025-03-17 01:11:47,675 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089011\n",
      "2025-03-17 01:11:47,675 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100409\n",
      "Training progress:  53%|█████▎    | 160/300 [00:21<00:20,  6.75it/s]2025-03-17 01:11:47,820 - sciml.model.deeponet.deeponet - INFO - Epoch 161/300\n",
      "2025-03-17 01:11:47,821 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088898\n",
      "2025-03-17 01:11:47,822 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100158\n",
      "Training progress:  54%|█████▎    | 161/300 [00:21<00:20,  6.76it/s]2025-03-17 01:11:47,970 - sciml.model.deeponet.deeponet - INFO - Epoch 162/300\n",
      "2025-03-17 01:11:47,971 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088780\n",
      "2025-03-17 01:11:47,972 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099931\n",
      "Training progress:  54%|█████▍    | 162/300 [00:22<00:20,  6.74it/s]2025-03-17 01:11:48,116 - sciml.model.deeponet.deeponet - INFO - Epoch 163/300\n",
      "2025-03-17 01:11:48,117 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088705\n",
      "2025-03-17 01:11:48,118 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100113\n",
      "Training progress:  54%|█████▍    | 163/300 [00:22<00:20,  6.77it/s]2025-03-17 01:11:48,266 - sciml.model.deeponet.deeponet - INFO - Epoch 164/300\n",
      "2025-03-17 01:11:48,266 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088623\n",
      "2025-03-17 01:11:48,267 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099789\n",
      "Training progress:  55%|█████▍    | 164/300 [00:22<00:20,  6.75it/s]2025-03-17 01:11:48,414 - sciml.model.deeponet.deeponet - INFO - Epoch 165/300\n",
      "2025-03-17 01:11:48,415 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088499\n",
      "2025-03-17 01:11:48,416 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099821\n",
      "Training progress:  55%|█████▌    | 165/300 [00:22<00:20,  6.74it/s]2025-03-17 01:11:48,563 - sciml.model.deeponet.deeponet - INFO - Epoch 166/300\n",
      "2025-03-17 01:11:48,564 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088396\n",
      "2025-03-17 01:11:48,564 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099826\n",
      "Training progress:  55%|█████▌    | 166/300 [00:22<00:19,  6.74it/s]2025-03-17 01:11:48,716 - sciml.model.deeponet.deeponet - INFO - Epoch 167/300\n",
      "2025-03-17 01:11:48,717 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088311\n",
      "2025-03-17 01:11:48,718 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099498\n",
      "Training progress:  56%|█████▌    | 167/300 [00:22<00:19,  6.67it/s]2025-03-17 01:11:48,872 - sciml.model.deeponet.deeponet - INFO - Epoch 168/300\n",
      "2025-03-17 01:11:48,873 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088223\n",
      "2025-03-17 01:11:48,873 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099643\n",
      "Training progress:  56%|█████▌    | 168/300 [00:23<00:20,  6.59it/s]2025-03-17 01:11:49,051 - sciml.model.deeponet.deeponet - INFO - Epoch 169/300\n",
      "2025-03-17 01:11:49,052 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088137\n",
      "2025-03-17 01:11:49,052 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099280\n",
      "Training progress:  56%|█████▋    | 169/300 [00:23<00:20,  6.26it/s]2025-03-17 01:11:49,209 - sciml.model.deeponet.deeponet - INFO - Epoch 170/300\n",
      "2025-03-17 01:11:49,210 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088038\n",
      "2025-03-17 01:11:49,211 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099220\n",
      "Training progress:  57%|█████▋    | 170/300 [00:23<00:20,  6.28it/s]2025-03-17 01:11:49,366 - sciml.model.deeponet.deeponet - INFO - Epoch 171/300\n",
      "2025-03-17 01:11:49,367 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087935\n",
      "2025-03-17 01:11:49,367 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099052\n",
      "Training progress:  57%|█████▋    | 171/300 [00:23<00:20,  6.31it/s]2025-03-17 01:11:49,516 - sciml.model.deeponet.deeponet - INFO - Epoch 172/300\n",
      "2025-03-17 01:11:49,517 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087850\n",
      "2025-03-17 01:11:49,517 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098825\n",
      "Training progress:  57%|█████▋    | 172/300 [00:23<00:19,  6.41it/s]2025-03-17 01:11:49,667 - sciml.model.deeponet.deeponet - INFO - Epoch 173/300\n",
      "2025-03-17 01:11:49,668 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087781\n",
      "2025-03-17 01:11:49,668 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099079\n",
      "Training progress:  58%|█████▊    | 173/300 [00:23<00:19,  6.47it/s]2025-03-17 01:11:49,816 - sciml.model.deeponet.deeponet - INFO - Epoch 174/300\n",
      "2025-03-17 01:11:49,817 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087719\n",
      "2025-03-17 01:11:49,818 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098667\n",
      "Training progress:  58%|█████▊    | 174/300 [00:23<00:19,  6.54it/s]2025-03-17 01:11:49,972 - sciml.model.deeponet.deeponet - INFO - Epoch 175/300\n",
      "2025-03-17 01:11:49,972 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087662\n",
      "2025-03-17 01:11:49,973 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099105\n",
      "Training progress:  58%|█████▊    | 175/300 [00:24<00:19,  6.51it/s]2025-03-17 01:11:50,120 - sciml.model.deeponet.deeponet - INFO - Epoch 176/300\n",
      "2025-03-17 01:11:50,121 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087613\n",
      "2025-03-17 01:11:50,122 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098452\n",
      "Training progress:  59%|█████▊    | 176/300 [00:24<00:18,  6.57it/s]2025-03-17 01:11:50,269 - sciml.model.deeponet.deeponet - INFO - Epoch 177/300\n",
      "2025-03-17 01:11:50,269 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087501\n",
      "2025-03-17 01:11:50,270 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098535\n",
      "Training progress:  59%|█████▉    | 177/300 [00:24<00:18,  6.63it/s]2025-03-17 01:11:50,457 - sciml.model.deeponet.deeponet - INFO - Epoch 178/300\n",
      "2025-03-17 01:11:50,458 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087367\n",
      "2025-03-17 01:11:50,459 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098018\n",
      "Training progress:  59%|█████▉    | 178/300 [00:24<00:19,  6.16it/s]2025-03-17 01:11:50,606 - sciml.model.deeponet.deeponet - INFO - Epoch 179/300\n",
      "2025-03-17 01:11:50,607 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087261\n",
      "2025-03-17 01:11:50,608 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098061\n",
      "Training progress:  60%|█████▉    | 179/300 [00:24<00:19,  6.31it/s]2025-03-17 01:11:50,758 - sciml.model.deeponet.deeponet - INFO - Epoch 180/300\n",
      "2025-03-17 01:11:50,758 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087168\n",
      "2025-03-17 01:11:50,759 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097952\n",
      "Training progress:  60%|██████    | 180/300 [00:24<00:18,  6.40it/s]2025-03-17 01:11:50,905 - sciml.model.deeponet.deeponet - INFO - Epoch 181/300\n",
      "2025-03-17 01:11:50,905 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087075\n",
      "2025-03-17 01:11:50,906 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097925\n",
      "Training progress:  60%|██████    | 181/300 [00:25<00:18,  6.52it/s]2025-03-17 01:11:51,052 - sciml.model.deeponet.deeponet - INFO - Epoch 182/300\n",
      "2025-03-17 01:11:51,053 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086987\n",
      "2025-03-17 01:11:51,053 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097919\n",
      "Training progress:  61%|██████    | 182/300 [00:25<00:17,  6.59it/s]2025-03-17 01:11:51,199 - sciml.model.deeponet.deeponet - INFO - Epoch 183/300\n",
      "2025-03-17 01:11:51,200 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086907\n",
      "2025-03-17 01:11:51,200 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097703\n",
      "Training progress:  61%|██████    | 183/300 [00:25<00:17,  6.66it/s]2025-03-17 01:11:51,349 - sciml.model.deeponet.deeponet - INFO - Epoch 184/300\n",
      "2025-03-17 01:11:51,349 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086825\n",
      "2025-03-17 01:11:51,350 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097837\n",
      "Training progress:  61%|██████▏   | 184/300 [00:25<00:17,  6.66it/s]2025-03-17 01:11:51,497 - sciml.model.deeponet.deeponet - INFO - Epoch 185/300\n",
      "2025-03-17 01:11:51,498 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086757\n",
      "2025-03-17 01:11:51,498 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097393\n",
      "Training progress:  62%|██████▏   | 185/300 [00:25<00:17,  6.69it/s]2025-03-17 01:11:51,647 - sciml.model.deeponet.deeponet - INFO - Epoch 186/300\n",
      "2025-03-17 01:11:51,648 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086704\n",
      "2025-03-17 01:11:51,648 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097998\n",
      "Training progress:  62%|██████▏   | 186/300 [00:25<00:17,  6.69it/s]2025-03-17 01:11:51,797 - sciml.model.deeponet.deeponet - INFO - Epoch 187/300\n",
      "2025-03-17 01:11:51,798 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086704\n",
      "2025-03-17 01:11:51,798 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097305\n",
      "Training progress:  62%|██████▏   | 187/300 [00:25<00:16,  6.67it/s]2025-03-17 01:11:51,945 - sciml.model.deeponet.deeponet - INFO - Epoch 188/300\n",
      "2025-03-17 01:11:51,946 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086837\n",
      "2025-03-17 01:11:51,947 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099022\n",
      "Training progress:  63%|██████▎   | 188/300 [00:26<00:16,  6.70it/s]2025-03-17 01:11:52,096 - sciml.model.deeponet.deeponet - INFO - Epoch 189/300\n",
      "2025-03-17 01:11:52,097 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087308\n",
      "2025-03-17 01:11:52,098 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097446\n",
      "Training progress:  63%|██████▎   | 189/300 [00:26<00:16,  6.67it/s]2025-03-17 01:11:52,244 - sciml.model.deeponet.deeponet - INFO - Epoch 190/300\n",
      "2025-03-17 01:11:52,245 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087776\n",
      "2025-03-17 01:11:52,246 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100628\n",
      "Training progress:  63%|██████▎   | 190/300 [00:26<00:16,  6.70it/s]2025-03-17 01:11:52,393 - sciml.model.deeponet.deeponet - INFO - Epoch 191/300\n",
      "2025-03-17 01:11:52,394 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088757\n",
      "2025-03-17 01:11:52,394 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097191\n",
      "Training progress:  64%|██████▎   | 191/300 [00:26<00:16,  6.70it/s]2025-03-17 01:11:52,543 - sciml.model.deeponet.deeponet - INFO - Epoch 192/300\n",
      "2025-03-17 01:11:52,544 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087613\n",
      "2025-03-17 01:11:52,544 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097806\n",
      "Training progress:  64%|██████▍   | 192/300 [00:26<00:16,  6.70it/s]2025-03-17 01:11:52,694 - sciml.model.deeponet.deeponet - INFO - Epoch 193/300\n",
      "2025-03-17 01:11:52,695 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086472\n",
      "2025-03-17 01:11:52,695 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097068\n",
      "Training progress:  64%|██████▍   | 193/300 [00:26<00:16,  6.67it/s]2025-03-17 01:11:52,842 - sciml.model.deeponet.deeponet - INFO - Epoch 194/300\n",
      "2025-03-17 01:11:52,842 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086074\n",
      "2025-03-17 01:11:52,843 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096568\n",
      "Training progress:  65%|██████▍   | 194/300 [00:27<00:15,  6.70it/s]2025-03-17 01:11:52,992 - sciml.model.deeponet.deeponet - INFO - Epoch 195/300\n",
      "2025-03-17 01:11:52,993 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086774\n",
      "2025-03-17 01:11:52,993 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099247\n",
      "Training progress:  65%|██████▌   | 195/300 [00:27<00:15,  6.69it/s]2025-03-17 01:11:53,143 - sciml.model.deeponet.deeponet - INFO - Epoch 196/300\n",
      "2025-03-17 01:11:53,144 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087579\n",
      "2025-03-17 01:11:53,145 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096637\n",
      "Training progress:  65%|██████▌   | 196/300 [00:27<00:15,  6.66it/s]2025-03-17 01:11:53,291 - sciml.model.deeponet.deeponet - INFO - Epoch 197/300\n",
      "2025-03-17 01:11:53,292 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086509\n",
      "2025-03-17 01:11:53,292 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096975\n",
      "Training progress:  66%|██████▌   | 197/300 [00:27<00:15,  6.70it/s]2025-03-17 01:11:53,437 - sciml.model.deeponet.deeponet - INFO - Epoch 198/300\n",
      "2025-03-17 01:11:53,438 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085786\n",
      "2025-03-17 01:11:53,438 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097736\n",
      "Training progress:  66%|██████▌   | 198/300 [00:27<00:15,  6.75it/s]2025-03-17 01:11:53,587 - sciml.model.deeponet.deeponet - INFO - Epoch 199/300\n",
      "2025-03-17 01:11:53,588 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086109\n",
      "2025-03-17 01:11:53,588 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096639\n",
      "Training progress:  66%|██████▋   | 199/300 [00:27<00:15,  6.72it/s]2025-03-17 01:11:53,737 - sciml.model.deeponet.deeponet - INFO - Epoch 200/300\n",
      "2025-03-17 01:11:53,738 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086460\n",
      "2025-03-17 01:11:53,738 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097715\n",
      "Training progress:  67%|██████▋   | 200/300 [00:27<00:14,  6.71it/s]2025-03-17 01:11:53,888 - sciml.model.deeponet.deeponet - INFO - Epoch 201/300\n",
      "2025-03-17 01:11:53,889 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086224\n",
      "2025-03-17 01:11:53,889 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096249\n",
      "Training progress:  67%|██████▋   | 201/300 [00:28<00:14,  6.68it/s]2025-03-17 01:11:54,035 - sciml.model.deeponet.deeponet - INFO - Epoch 202/300\n",
      "2025-03-17 01:11:54,036 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085574\n",
      "2025-03-17 01:11:54,036 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096121\n",
      "Training progress:  67%|██████▋   | 202/300 [00:28<00:14,  6.72it/s]2025-03-17 01:11:54,185 - sciml.model.deeponet.deeponet - INFO - Epoch 203/300\n",
      "2025-03-17 01:11:54,186 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085691\n",
      "2025-03-17 01:11:54,186 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097670\n",
      "Training progress:  68%|██████▊   | 203/300 [00:28<00:14,  6.70it/s]2025-03-17 01:11:54,335 - sciml.model.deeponet.deeponet - INFO - Epoch 204/300\n",
      "2025-03-17 01:11:54,335 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086120\n",
      "2025-03-17 01:11:54,336 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096114\n",
      "Training progress:  68%|██████▊   | 204/300 [00:28<00:14,  6.70it/s]2025-03-17 01:11:54,483 - sciml.model.deeponet.deeponet - INFO - Epoch 205/300\n",
      "2025-03-17 01:11:54,484 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085756\n",
      "2025-03-17 01:11:54,484 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096331\n",
      "Training progress:  68%|██████▊   | 205/300 [00:28<00:14,  6.71it/s]2025-03-17 01:11:54,631 - sciml.model.deeponet.deeponet - INFO - Epoch 206/300\n",
      "2025-03-17 01:11:54,632 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085327\n",
      "2025-03-17 01:11:54,632 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096422\n",
      "Training progress:  69%|██████▊   | 206/300 [00:28<00:13,  6.72it/s]2025-03-17 01:11:54,780 - sciml.model.deeponet.deeponet - INFO - Epoch 207/300\n",
      "2025-03-17 01:11:54,780 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085376\n",
      "2025-03-17 01:11:54,781 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095632\n",
      "Training progress:  69%|██████▉   | 207/300 [00:28<00:13,  6.72it/s]2025-03-17 01:11:54,931 - sciml.model.deeponet.deeponet - INFO - Epoch 208/300\n",
      "2025-03-17 01:11:54,931 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085547\n",
      "2025-03-17 01:11:54,932 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096615\n",
      "Training progress:  69%|██████▉   | 208/300 [00:29<00:13,  6.69it/s]2025-03-17 01:11:55,079 - sciml.model.deeponet.deeponet - INFO - Epoch 209/300\n",
      "2025-03-17 01:11:55,080 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085488\n",
      "2025-03-17 01:11:55,081 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095534\n",
      "Training progress:  70%|██████▉   | 209/300 [00:29<00:13,  6.71it/s]2025-03-17 01:11:55,226 - sciml.model.deeponet.deeponet - INFO - Epoch 210/300\n",
      "2025-03-17 01:11:55,227 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085134\n",
      "2025-03-17 01:11:55,227 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095481\n",
      "Training progress:  70%|███████   | 210/300 [00:29<00:13,  6.74it/s]2025-03-17 01:11:55,379 - sciml.model.deeponet.deeponet - INFO - Epoch 211/300\n",
      "2025-03-17 01:11:55,379 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085039\n",
      "2025-03-17 01:11:55,380 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096171\n",
      "Training progress:  70%|███████   | 211/300 [00:29<00:13,  6.68it/s]2025-03-17 01:11:55,537 - sciml.model.deeponet.deeponet - INFO - Epoch 212/300\n",
      "2025-03-17 01:11:55,538 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085192\n",
      "2025-03-17 01:11:55,538 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095212\n",
      "Training progress:  71%|███████   | 212/300 [00:29<00:13,  6.56it/s]2025-03-17 01:11:55,689 - sciml.model.deeponet.deeponet - INFO - Epoch 213/300\n",
      "2025-03-17 01:11:55,690 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085208\n",
      "2025-03-17 01:11:55,691 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095960\n",
      "Training progress:  71%|███████   | 213/300 [00:29<00:13,  6.56it/s]2025-03-17 01:11:55,839 - sciml.model.deeponet.deeponet - INFO - Epoch 214/300\n",
      "2025-03-17 01:11:55,840 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085042\n",
      "2025-03-17 01:11:55,840 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095171\n",
      "Training progress:  71%|███████▏  | 214/300 [00:30<00:13,  6.60it/s]2025-03-17 01:11:55,993 - sciml.model.deeponet.deeponet - INFO - Epoch 215/300\n",
      "2025-03-17 01:11:55,994 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084795\n",
      "2025-03-17 01:11:55,995 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094999\n",
      "Training progress:  72%|███████▏  | 215/300 [00:30<00:12,  6.57it/s]2025-03-17 01:11:56,146 - sciml.model.deeponet.deeponet - INFO - Epoch 216/300\n",
      "2025-03-17 01:11:56,146 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084762\n",
      "2025-03-17 01:11:56,147 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095724\n",
      "Training progress:  72%|███████▏  | 216/300 [00:30<00:12,  6.56it/s]2025-03-17 01:11:56,334 - sciml.model.deeponet.deeponet - INFO - Epoch 217/300\n",
      "2025-03-17 01:11:56,334 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084864\n",
      "2025-03-17 01:11:56,335 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094853\n",
      "Training progress:  72%|███████▏  | 217/300 [00:30<00:13,  6.14it/s]2025-03-17 01:11:56,486 - sciml.model.deeponet.deeponet - INFO - Epoch 218/300\n",
      "2025-03-17 01:11:56,487 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084907\n",
      "2025-03-17 01:11:56,488 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095854\n",
      "Training progress:  73%|███████▎  | 218/300 [00:30<00:13,  6.25it/s]2025-03-17 01:11:56,636 - sciml.model.deeponet.deeponet - INFO - Epoch 219/300\n",
      "2025-03-17 01:11:56,636 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084857\n",
      "2025-03-17 01:11:56,637 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094725\n",
      "Training progress:  73%|███████▎  | 219/300 [00:30<00:12,  6.38it/s]2025-03-17 01:11:56,786 - sciml.model.deeponet.deeponet - INFO - Epoch 220/300\n",
      "2025-03-17 01:11:56,786 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084637\n",
      "2025-03-17 01:11:56,787 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094996\n",
      "Training progress:  73%|███████▎  | 220/300 [00:30<00:12,  6.47it/s]2025-03-17 01:11:56,935 - sciml.model.deeponet.deeponet - INFO - Epoch 221/300\n",
      "2025-03-17 01:11:56,936 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084453\n",
      "2025-03-17 01:11:56,936 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094778\n",
      "Training progress:  74%|███████▎  | 221/300 [00:31<00:12,  6.52it/s]2025-03-17 01:11:57,093 - sciml.model.deeponet.deeponet - INFO - Epoch 222/300\n",
      "2025-03-17 01:11:57,094 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084374\n",
      "2025-03-17 01:11:57,094 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094424\n",
      "Training progress:  74%|███████▍  | 222/300 [00:31<00:12,  6.47it/s]2025-03-17 01:11:57,242 - sciml.model.deeponet.deeponet - INFO - Epoch 223/300\n",
      "2025-03-17 01:11:57,243 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084406\n",
      "2025-03-17 01:11:57,243 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095215\n",
      "Training progress:  74%|███████▍  | 223/300 [00:31<00:11,  6.53it/s]2025-03-17 01:11:57,391 - sciml.model.deeponet.deeponet - INFO - Epoch 224/300\n",
      "2025-03-17 01:11:57,391 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084460\n",
      "2025-03-17 01:11:57,392 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094327\n",
      "Training progress:  75%|███████▍  | 224/300 [00:31<00:11,  6.59it/s]2025-03-17 01:11:57,537 - sciml.model.deeponet.deeponet - INFO - Epoch 225/300\n",
      "2025-03-17 01:11:57,537 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084490\n",
      "2025-03-17 01:11:57,538 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095472\n",
      "Training progress:  75%|███████▌  | 225/300 [00:31<00:11,  6.68it/s]2025-03-17 01:11:57,687 - sciml.model.deeponet.deeponet - INFO - Epoch 226/300\n",
      "2025-03-17 01:11:57,688 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084517\n",
      "2025-03-17 01:11:57,688 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094241\n",
      "Training progress:  75%|███████▌  | 226/300 [00:31<00:11,  6.66it/s]2025-03-17 01:11:57,835 - sciml.model.deeponet.deeponet - INFO - Epoch 227/300\n",
      "2025-03-17 01:11:57,836 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084411\n",
      "2025-03-17 01:11:57,836 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095146\n",
      "Training progress:  76%|███████▌  | 227/300 [00:32<00:10,  6.70it/s]2025-03-17 01:11:57,982 - sciml.model.deeponet.deeponet - INFO - Epoch 228/300\n",
      "2025-03-17 01:11:57,982 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084323\n",
      "2025-03-17 01:11:57,983 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093988\n",
      "Training progress:  76%|███████▌  | 228/300 [00:32<00:10,  6.73it/s]2025-03-17 01:11:58,130 - sciml.model.deeponet.deeponet - INFO - Epoch 229/300\n",
      "2025-03-17 01:11:58,131 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084177\n",
      "2025-03-17 01:11:58,131 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094576\n",
      "Training progress:  76%|███████▋  | 229/300 [00:32<00:10,  6.73it/s]2025-03-17 01:11:58,278 - sciml.model.deeponet.deeponet - INFO - Epoch 230/300\n",
      "2025-03-17 01:11:58,279 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084044\n",
      "2025-03-17 01:11:58,279 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093965\n",
      "Training progress:  77%|███████▋  | 230/300 [00:32<00:10,  6.74it/s]2025-03-17 01:11:58,427 - sciml.model.deeponet.deeponet - INFO - Epoch 231/300\n",
      "2025-03-17 01:11:58,428 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083926\n",
      "2025-03-17 01:11:58,428 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094225\n",
      "Training progress:  77%|███████▋  | 231/300 [00:32<00:10,  6.73it/s]2025-03-17 01:11:58,581 - sciml.model.deeponet.deeponet - INFO - Epoch 232/300\n",
      "2025-03-17 01:11:58,582 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083838\n",
      "2025-03-17 01:11:58,582 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094060\n",
      "Training progress:  77%|███████▋  | 232/300 [00:32<00:10,  6.65it/s]2025-03-17 01:11:58,732 - sciml.model.deeponet.deeponet - INFO - Epoch 233/300\n",
      "2025-03-17 01:11:58,733 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083776\n",
      "2025-03-17 01:11:58,734 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093876\n",
      "Training progress:  78%|███████▊  | 233/300 [00:32<00:10,  6.64it/s]2025-03-17 01:11:58,882 - sciml.model.deeponet.deeponet - INFO - Epoch 234/300\n",
      "2025-03-17 01:11:58,883 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083732\n",
      "2025-03-17 01:11:58,883 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094066\n",
      "Training progress:  78%|███████▊  | 234/300 [00:33<00:09,  6.65it/s]2025-03-17 01:11:59,033 - sciml.model.deeponet.deeponet - INFO - Epoch 235/300\n",
      "2025-03-17 01:11:59,034 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083710\n",
      "2025-03-17 01:11:59,034 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093552\n",
      "Training progress:  78%|███████▊  | 235/300 [00:33<00:09,  6.66it/s]2025-03-17 01:11:59,183 - sciml.model.deeponet.deeponet - INFO - Epoch 236/300\n",
      "2025-03-17 01:11:59,184 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083730\n",
      "2025-03-17 01:11:59,185 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094396\n",
      "Training progress:  79%|███████▊  | 236/300 [00:33<00:09,  6.65it/s]2025-03-17 01:11:59,334 - sciml.model.deeponet.deeponet - INFO - Epoch 237/300\n",
      "2025-03-17 01:11:59,335 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083843\n",
      "2025-03-17 01:11:59,335 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093345\n",
      "Training progress:  79%|███████▉  | 237/300 [00:33<00:09,  6.64it/s]2025-03-17 01:11:59,483 - sciml.model.deeponet.deeponet - INFO - Epoch 238/300\n",
      "2025-03-17 01:11:59,484 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084095\n",
      "2025-03-17 01:11:59,485 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095863\n",
      "Training progress:  79%|███████▉  | 238/300 [00:33<00:09,  6.66it/s]2025-03-17 01:11:59,631 - sciml.model.deeponet.deeponet - INFO - Epoch 239/300\n",
      "2025-03-17 01:11:59,632 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084832\n",
      "2025-03-17 01:11:59,632 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093782\n",
      "Training progress:  80%|███████▉  | 239/300 [00:33<00:09,  6.69it/s]2025-03-17 01:11:59,779 - sciml.model.deeponet.deeponet - INFO - Epoch 240/300\n",
      "2025-03-17 01:11:59,780 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085494\n",
      "2025-03-17 01:11:59,781 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098371\n",
      "Training progress:  80%|████████  | 240/300 [00:33<00:08,  6.70it/s]2025-03-17 01:11:59,934 - sciml.model.deeponet.deeponet - INFO - Epoch 241/300\n",
      "2025-03-17 01:11:59,935 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087053\n",
      "2025-03-17 01:11:59,935 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093615\n",
      "Training progress:  80%|████████  | 241/300 [00:34<00:08,  6.63it/s]2025-03-17 01:12:00,084 - sciml.model.deeponet.deeponet - INFO - Epoch 242/300\n",
      "2025-03-17 01:12:00,084 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085677\n",
      "2025-03-17 01:12:00,085 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094735\n",
      "Training progress:  81%|████████  | 242/300 [00:34<00:08,  6.65it/s]2025-03-17 01:12:00,230 - sciml.model.deeponet.deeponet - INFO - Epoch 243/300\n",
      "2025-03-17 01:12:00,231 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084181\n",
      "2025-03-17 01:12:00,232 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093262\n",
      "Training progress:  81%|████████  | 243/300 [00:34<00:08,  6.70it/s]2025-03-17 01:12:00,381 - sciml.model.deeponet.deeponet - INFO - Epoch 244/300\n",
      "2025-03-17 01:12:00,382 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083331\n",
      "2025-03-17 01:12:00,382 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093068\n",
      "Training progress:  81%|████████▏ | 244/300 [00:34<00:08,  6.68it/s]2025-03-17 01:12:00,527 - sciml.model.deeponet.deeponet - INFO - Epoch 245/300\n",
      "2025-03-17 01:12:00,528 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084295\n",
      "2025-03-17 01:12:00,528 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096610\n",
      "Training progress:  82%|████████▏ | 245/300 [00:34<00:08,  6.73it/s]2025-03-17 01:12:00,671 - sciml.model.deeponet.deeponet - INFO - Epoch 246/300\n",
      "2025-03-17 01:12:00,671 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085575\n",
      "2025-03-17 01:12:00,672 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093178\n",
      "Training progress:  82%|████████▏ | 246/300 [00:34<00:07,  6.80it/s]2025-03-17 01:12:00,844 - sciml.model.deeponet.deeponet - INFO - Epoch 247/300\n",
      "2025-03-17 01:12:00,844 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084119\n",
      "2025-03-17 01:12:00,845 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093394\n",
      "Training progress:  82%|████████▏ | 247/300 [00:35<00:08,  6.45it/s]2025-03-17 01:12:00,992 - sciml.model.deeponet.deeponet - INFO - Epoch 248/300\n",
      "2025-03-17 01:12:00,993 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083163\n",
      "2025-03-17 01:12:00,993 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094727\n",
      "Training progress:  83%|████████▎ | 248/300 [00:35<00:07,  6.53it/s]2025-03-17 01:12:01,141 - sciml.model.deeponet.deeponet - INFO - Epoch 249/300\n",
      "2025-03-17 01:12:01,141 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083840\n",
      "2025-03-17 01:12:01,142 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093214\n",
      "Training progress:  83%|████████▎ | 249/300 [00:35<00:07,  6.59it/s]2025-03-17 01:12:01,286 - sciml.model.deeponet.deeponet - INFO - Epoch 250/300\n",
      "2025-03-17 01:12:01,287 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084255\n",
      "2025-03-17 01:12:01,288 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094404\n",
      "Training progress:  83%|████████▎ | 250/300 [00:35<00:07,  6.68it/s]2025-03-17 01:12:01,432 - sciml.model.deeponet.deeponet - INFO - Epoch 251/300\n",
      "2025-03-17 01:12:01,433 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083808\n",
      "2025-03-17 01:12:01,433 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092915\n",
      "Training progress:  84%|████████▎ | 251/300 [00:35<00:07,  6.73it/s]2025-03-17 01:11:59,101 - sciml.model.deeponet.deeponet - INFO - Epoch 252/300\n",
      "2025-03-17 01:11:59,102 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083082\n",
      "2025-03-17 01:11:59,103 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092835\n",
      "2025-03-17 01:11:59,247 - sciml.model.deeponet.deeponet - INFO - Epoch 253/300\n",
      "2025-03-17 01:11:59,248 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083530\n",
      "2025-03-17 01:11:59,249 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095108\n",
      "2025-03-17 01:11:59,398 - sciml.model.deeponet.deeponet - INFO - Epoch 254/300\n",
      "2025-03-17 01:11:59,399 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084140\n",
      "2025-03-17 01:11:59,400 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092893\n",
      "2025-03-17 01:11:59,550 - sciml.model.deeponet.deeponet - INFO - Epoch 255/300\n",
      "2025-03-17 01:11:59,551 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083315\n",
      "2025-03-17 01:11:59,551 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092899\n",
      "2025-03-17 01:11:59,703 - sciml.model.deeponet.deeponet - INFO - Epoch 256/300\n",
      "2025-03-17 01:11:59,704 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082902\n",
      "2025-03-17 01:11:59,704 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093821\n",
      "2025-03-17 01:11:59,856 - sciml.model.deeponet.deeponet - INFO - Epoch 257/300\n",
      "2025-03-17 01:11:59,857 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083286\n",
      "2025-03-17 01:11:59,857 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092670\n",
      "2025-03-17 01:12:00,006 - sciml.model.deeponet.deeponet - INFO - Epoch 258/300\n",
      "2025-03-17 01:12:00,007 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083330\n",
      "2025-03-17 01:12:00,008 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093525\n",
      "2025-03-17 01:12:00,184 - sciml.model.deeponet.deeponet - INFO - Epoch 259/300\n",
      "2025-03-17 01:12:00,185 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083011\n",
      "2025-03-17 01:12:00,186 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092811\n",
      "2025-03-17 01:12:00,342 - sciml.model.deeponet.deeponet - INFO - Epoch 260/300\n",
      "2025-03-17 01:12:00,343 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082733\n",
      "2025-03-17 01:12:00,344 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092464\n",
      "2025-03-17 01:12:00,490 - sciml.model.deeponet.deeponet - INFO - Epoch 261/300\n",
      "2025-03-17 01:12:00,490 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082895\n",
      "2025-03-17 01:12:00,491 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093494\n",
      "2025-03-17 01:12:00,637 - sciml.model.deeponet.deeponet - INFO - Epoch 262/300\n",
      "2025-03-17 01:12:00,638 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083057\n",
      "2025-03-17 01:12:00,639 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092328\n",
      "2025-03-17 01:12:00,786 - sciml.model.deeponet.deeponet - INFO - Epoch 263/300\n",
      "2025-03-17 01:12:00,787 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082782\n",
      "2025-03-17 01:12:00,787 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092523\n",
      "2025-03-17 01:12:00,933 - sciml.model.deeponet.deeponet - INFO - Epoch 264/300\n",
      "2025-03-17 01:12:00,933 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082595\n",
      "2025-03-17 01:12:00,934 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092782\n",
      "2025-03-17 01:12:01,081 - sciml.model.deeponet.deeponet - INFO - Epoch 265/300\n",
      "2025-03-17 01:12:01,082 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082648\n",
      "2025-03-17 01:12:01,082 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092139\n",
      "2025-03-17 01:12:01,228 - sciml.model.deeponet.deeponet - INFO - Epoch 266/300\n",
      "2025-03-17 01:12:01,228 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082751\n",
      "2025-03-17 01:12:01,229 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093020\n",
      "2025-03-17 01:12:01,373 - sciml.model.deeponet.deeponet - INFO - Epoch 267/300\n",
      "2025-03-17 01:12:01,374 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082726\n",
      "2025-03-17 01:12:01,374 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092164\n",
      "2025-03-17 01:12:01,520 - sciml.model.deeponet.deeponet - INFO - Epoch 268/300\n",
      "2025-03-17 01:12:01,521 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082518\n",
      "2025-03-17 01:12:01,521 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092308\n",
      "2025-03-17 01:12:01,667 - sciml.model.deeponet.deeponet - INFO - Epoch 269/300\n",
      "2025-03-17 01:12:01,668 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082426\n",
      "2025-03-17 01:12:01,669 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092667\n",
      "Training progress:  90%|████████▉ | 269/300 [00:35<00:00, 34.95it/s]2025-03-17 01:12:01,817 - sciml.model.deeponet.deeponet - INFO - Epoch 270/300\n",
      "2025-03-17 01:12:01,818 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082484\n",
      "2025-03-17 01:12:01,818 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091922\n",
      "2025-03-17 01:12:01,965 - sciml.model.deeponet.deeponet - INFO - Epoch 271/300\n",
      "2025-03-17 01:12:01,966 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082545\n",
      "2025-03-17 01:12:01,966 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092608\n",
      "2025-03-17 01:12:02,109 - sciml.model.deeponet.deeponet - INFO - Epoch 272/300\n",
      "2025-03-17 01:12:02,110 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082495\n",
      "2025-03-17 01:12:02,119 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091874\n",
      "Training progress:  91%|█████████ | 272/300 [00:36<00:01, 20.08it/s]2025-03-17 01:12:02,272 - sciml.model.deeponet.deeponet - INFO - Epoch 273/300\n",
      "2025-03-17 01:12:02,272 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082332\n",
      "2025-03-17 01:12:02,273 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092073\n",
      "2025-03-17 01:12:02,426 - sciml.model.deeponet.deeponet - INFO - Epoch 274/300\n",
      "2025-03-17 01:12:02,427 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082259\n",
      "2025-03-17 01:12:02,427 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092372\n",
      "2025-03-17 01:12:02,576 - sciml.model.deeponet.deeponet - INFO - Epoch 275/300\n",
      "2025-03-17 01:12:02,577 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082274\n",
      "2025-03-17 01:12:02,577 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091881\n",
      "Training progress:  92%|█████████▏| 275/300 [00:36<00:01, 14.23it/s]2025-03-17 01:12:02,728 - sciml.model.deeponet.deeponet - INFO - Epoch 276/300\n",
      "2025-03-17 01:12:02,729 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082309\n",
      "2025-03-17 01:12:02,729 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092580\n",
      "2025-03-17 01:12:02,893 - sciml.model.deeponet.deeponet - INFO - Epoch 277/300\n",
      "2025-03-17 01:12:02,893 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082315\n",
      "2025-03-17 01:12:02,894 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091774\n",
      "Training progress:  92%|█████████▏| 277/300 [00:37<00:01, 11.86it/s]2025-03-17 01:12:03,040 - sciml.model.deeponet.deeponet - INFO - Epoch 278/300\n",
      "2025-03-17 01:12:03,041 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082224\n",
      "2025-03-17 01:12:03,042 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092183\n",
      "2025-03-17 01:12:03,185 - sciml.model.deeponet.deeponet - INFO - Epoch 279/300\n",
      "2025-03-17 01:12:03,186 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082138\n",
      "2025-03-17 01:12:03,187 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091830\n",
      "Training progress:  93%|█████████▎| 279/300 [00:37<00:02, 10.44it/s]2025-03-17 01:12:03,331 - sciml.model.deeponet.deeponet - INFO - Epoch 280/300\n",
      "2025-03-17 01:12:03,332 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082062\n",
      "2025-03-17 01:12:03,332 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091779\n",
      "2025-03-17 01:12:03,476 - sciml.model.deeponet.deeponet - INFO - Epoch 281/300\n",
      "2025-03-17 01:12:03,477 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082031\n",
      "2025-03-17 01:12:03,477 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092067\n",
      "Training progress:  94%|█████████▎| 281/300 [00:37<00:02,  9.41it/s]2025-03-17 01:12:03,623 - sciml.model.deeponet.deeponet - INFO - Epoch 282/300\n",
      "2025-03-17 01:12:03,623 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082032\n",
      "2025-03-17 01:12:03,624 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091594\n",
      "2025-03-17 01:12:03,767 - sciml.model.deeponet.deeponet - INFO - Epoch 283/300\n",
      "2025-03-17 01:12:03,768 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082034\n",
      "2025-03-17 01:12:03,768 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092215\n",
      "Training progress:  94%|█████████▍| 283/300 [00:37<00:01,  8.68it/s]2025-03-17 01:12:03,917 - sciml.model.deeponet.deeponet - INFO - Epoch 284/300\n",
      "2025-03-17 01:12:03,918 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082044\n",
      "2025-03-17 01:12:03,918 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091412\n",
      "Training progress:  95%|█████████▍| 284/300 [00:38<00:01,  8.32it/s]2025-03-17 01:12:04,088 - sciml.model.deeponet.deeponet - INFO - Epoch 285/300\n",
      "2025-03-17 01:12:04,089 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082039\n",
      "2025-03-17 01:12:04,090 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092198\n",
      "Training progress:  95%|█████████▌| 285/300 [00:38<00:01,  7.76it/s]2025-03-17 01:12:04,236 - sciml.model.deeponet.deeponet - INFO - Epoch 286/300\n",
      "2025-03-17 01:12:04,236 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082045\n",
      "2025-03-17 01:12:04,237 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091323\n",
      "Training progress:  95%|█████████▌| 286/300 [00:38<00:01,  7.56it/s]2025-03-17 01:12:04,383 - sciml.model.deeponet.deeponet - INFO - Epoch 287/300\n",
      "2025-03-17 01:12:04,384 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082031\n",
      "2025-03-17 01:12:04,384 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092273\n",
      "Training progress:  96%|█████████▌| 287/300 [00:38<00:01,  7.37it/s]2025-03-17 01:12:04,530 - sciml.model.deeponet.deeponet - INFO - Epoch 288/300\n",
      "2025-03-17 01:12:04,531 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082029\n",
      "2025-03-17 01:12:04,532 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091224\n",
      "Training progress:  96%|█████████▌| 288/300 [00:38<00:01,  7.22it/s]2025-03-17 01:12:04,684 - sciml.model.deeponet.deeponet - INFO - Epoch 289/300\n",
      "2025-03-17 01:12:04,684 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081991\n",
      "2025-03-17 01:12:04,685 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092164\n",
      "Training progress:  96%|█████████▋| 289/300 [00:38<00:01,  7.03it/s]2025-03-17 01:12:04,836 - sciml.model.deeponet.deeponet - INFO - Epoch 290/300\n",
      "2025-03-17 01:12:04,837 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081986\n",
      "2025-03-17 01:12:04,837 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091106\n",
      "Training progress:  97%|█████████▋| 290/300 [00:39<00:01,  6.90it/s]2025-03-17 01:12:04,985 - sciml.model.deeponet.deeponet - INFO - Epoch 291/300\n",
      "2025-03-17 01:12:04,986 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081959\n",
      "2025-03-17 01:12:04,987 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092238\n",
      "Training progress:  97%|█████████▋| 291/300 [00:39<00:01,  6.84it/s]2025-03-17 01:12:05,137 - sciml.model.deeponet.deeponet - INFO - Epoch 292/300\n",
      "2025-03-17 01:12:05,138 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081980\n",
      "2025-03-17 01:12:05,138 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091116\n",
      "Training progress:  97%|█████████▋| 292/300 [00:39<00:01,  6.78it/s]2025-03-17 01:12:05,284 - sciml.model.deeponet.deeponet - INFO - Epoch 293/300\n",
      "2025-03-17 01:12:05,285 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081972\n",
      "2025-03-17 01:12:05,285 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092414\n",
      "Training progress:  98%|█████████▊| 293/300 [00:39<00:01,  6.78it/s]2025-03-17 01:12:05,438 - sciml.model.deeponet.deeponet - INFO - Epoch 294/300\n",
      "2025-03-17 01:12:05,439 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082075\n",
      "2025-03-17 01:12:05,439 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090947\n",
      "Training progress:  98%|█████████▊| 294/300 [00:39<00:00,  6.70it/s]2025-03-17 01:12:05,591 - sciml.model.deeponet.deeponet - INFO - Epoch 295/300\n",
      "2025-03-17 01:12:05,592 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082084\n",
      "2025-03-17 01:12:05,593 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092599\n",
      "Training progress:  98%|█████████▊| 295/300 [00:39<00:00,  6.64it/s]2025-03-17 01:12:05,741 - sciml.model.deeponet.deeponet - INFO - Epoch 296/300\n",
      "2025-03-17 01:12:05,741 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082225\n",
      "2025-03-17 01:12:05,742 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090903\n",
      "Training progress:  99%|█████████▊| 296/300 [00:39<00:00,  6.67it/s]2025-03-17 01:12:05,886 - sciml.model.deeponet.deeponet - INFO - Epoch 297/300\n",
      "2025-03-17 01:12:05,887 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082151\n",
      "2025-03-17 01:12:05,887 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092637\n",
      "Training progress:  99%|█████████▉| 297/300 [00:40<00:00,  6.73it/s]2025-03-17 01:12:06,036 - sciml.model.deeponet.deeponet - INFO - Epoch 298/300\n",
      "2025-03-17 01:12:06,037 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082225\n",
      "2025-03-17 01:12:06,037 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090864\n",
      "Training progress:  99%|█████████▉| 298/300 [00:40<00:00,  6.71it/s]2025-03-17 01:12:06,185 - sciml.model.deeponet.deeponet - INFO - Epoch 299/300\n",
      "2025-03-17 01:12:06,186 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082006\n",
      "2025-03-17 01:12:06,187 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092211\n",
      "Training progress: 100%|█████████▉| 299/300 [00:40<00:00,  6.69it/s]2025-03-17 01:12:06,333 - sciml.model.deeponet.deeponet - INFO - Epoch 300/300\n",
      "2025-03-17 01:12:06,334 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081888\n",
      "2025-03-17 01:12:06,335 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090857\n",
      "Training progress: 100%|██████████| 300/300 [00:40<00:00,  7.41it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_history_train,loss_history_test = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAGdCAYAAAD3zLwdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYANJREFUeJzt3Xd4FFUXBvB3d9NJo6QQQu+hhA4BkRZKQKRYEFCagmjwQxC7gooCoiKgESsgCIIgRWlKRyB0AoZOqEIIHVIgbe/3x8lmE5JAErI17+959pnJzuzs3XFjDveee65GKaVARERERNBaugFERERE1oKBEREREVEGBkZEREREGRgYEREREWVgYERERESUgYERERERUQYGRkREREQZGBgRERERZXCwdANsjV6vx8WLF+Hh4QGNRmPp5hAREVE+KKUQHx+PgIAAaLV59wsxMCqgixcvonz58pZuBhERERXC+fPnERgYmOdxBkYF5OHhAUBurKenZ5FdNzU1FX///Tc6deoER0fHIruuPeK9Khjer/zjvSoY3q/8470qGFPcr9u3b6N8+fKZf8fzwsCogAzDZ56enkUeGLm5ucHT05O/NA/Ae1UwvF/5x3tVMLxf+cd7VTCmvF8PSoNh8jURERFRBgZGRERERBkYGBERERFlYI4RERGRFVBKIS0tDenp6ZZuisWlpqbCwcEBd+/ezff90Ol0cHBweOhSOgyMiIiILCwlJQWxsbFISkqydFOsglIK/v7+OH/+fIECHTc3N5QtWxZOTk6Ffm8GRkRERBak1+tx+vRp6HQ6BAQEwMnJqdgXENbr9UhISIC7u/t9izEaKKWQkpKCK1eu4PTp06hevXq+XpcbBkZEREQWlJKSAr1ej/Lly8PNzc3SzbEKer0eKSkpcHFxyXeA4+rqCkdHR5w9ezbztYXB5GsiIiIrUNgeDjIqinvI/wpEREREGRgYEREREWVgYEREREQWV6lSJUydOtXSzWDyNRERERVO27Zt0aBBgyIJaHbv3o0SJUo8fKMeEnuMrMR332nx7bf1oZSlW0JERFQ0DEUr88PHx8cqZuUxMLICx48DI0dqsWZNZbz5ppbBERFRMacUkJho/kdB/v4MGjQImzdvxrRp06DRaKDRaDB79mxoNBqsXr0ajRs3hrOzM7Zu3YqYmBj06NEDfn5+cHd3R9OmTbFu3bps17t3KK1kyZL48ccf0atXL7i5uaF69er4448/iugO542BkRWoUQP49lspeT51qg5ffmnhBhERkUUlJQHu7uZ/FKTw9rRp0xASEoKhQ4ciNjYWsbGxKF++PADgrbfewqRJk3DkyBHUr18fCQkJ6Nq1K9avX4/9+/ejS5cu6N69O86dO3ff9xg/fjyefvppHDx4EF27dkX//v1x/fr1h7m1D8TAyEoMGqQweHA0AGDsWCA21sINIiIiug8vLy84OTnBzc0N/v7+8Pf3h06nAwB89NFH6NixI6pWrYpSpUohODgYL774IurWrYvq1atj/PjxqFq16gN7gAYOHIi+ffuiWrVqmDBhAhISErBr1y6Tfi4mX1uRxx+PwaFDQdi1S4t33wVmzrR0i4iIyBLc3ICEBMu8b1Fo0qRJtp8TEhLwwQcfYOXKlYiNjUVaWhru3LnzwB6jevXqZe6XKFECnp6euHz5ctE0Mg8MjKyIRgN88YUerVtrMXs28NZbMsxGRETFi0YDWMEErUK7d3bZmDFjsHbtWnz++eeoVq0aXF1d8eSTTyIlJeW+13F0dMz2s0ajgV6vL/L2ZsWhNCvTvLlC166SAPf995ZuDRERUd6cnJyQnp7+wPO2bduGQYMGoVevXqhXrx78/f1x5swZ0zewEBgYWaHhw2U7ezZw965Fm0JERJSnSpUqYefOnThz5gyuXr2aZ29O9erVsWTJEkRFReHAgQPo16+fyXt+CouBkRUKCwMCA4Fr14Dff7d0a4iIiHI3ZswY6HQ6BAUFwcfHJ8+coSlTpqBkyZJo2bIlunfvjs6dO6NRo0Zmbm3+MMfICjk4AC+8AHzwgfQa9e9v6RYRERHlVKNGDURGRmZ7btCgQTnOq1SpEjZs2JDtufDw8Gw/3zu0duPGDXh6emZ77ubNm4Vua36xx8hK9esn240bpeeIiIiITI+BkZWqXh0IDgbS0wEzFPokIiIiMDCyak8+KdvFiy3bDiIiouKCgZEVMwRGa9cCZhhWJSIiKvYYGFkR5xs3sv1cq5Y8UlOBe9baIyIiIhNgYGQNLl6ErksXtB09OscKfl26yPavvyzQLiIiomKGgZE1KF0ampgYuNy4Ae2MGdkOGQKjNWukGjYRERGZDgMja+DsjPT33wcAaD/7DLh1K/PQo48CLi7Af/8Bhw9bqoFERETFAwMjK6H690d8YCA0168D06ZlPu/qCrRpI/scTiMiIjItBkbWQqfDsaeekv2ZM4Esa8h07izbtWst0C4iIqI8tG3bFq+++mqRXW/QoEHo2bNnkV2vMBgYWZHYFi2gPDyAs2eB7dszn2/XTrbbtgFpaRZqHBERUTHAwMiK6J2doQyR8rx5mc/Xqwd4eQHx8cCBA5ZpGxERUVaDBg3C5s2bMW3aNGg0Gmg0Gpw5cwbR0dEICwuDu7s7/Pz88Nxzz+Hq1auZr1u8eDHq1asHV1dXlC5dGqGhoUhMTMQHH3yAn3/+GcuXL4dOp0PJkiWxadMms38uBkZWRt+3r+z89huQkgIA0OmARx6Rp7dssVDDiIjIfJQCEhPN/yjA9Odp06YhJCQEQ4cORWxsLGJjY+Hh4YH27dujYcOG2LNnD9asWYO4uDg8/fTTAIDY2Fj07dsXQ4YMwZEjR7Bp0yb07t0bSimMGTMGTz/9NLp06YILFy7g6NGjaNmypanucJ4czP6OdF+qXTvAzw+IiwP++Qfo0AGAzE5buVICo1GjLNxIIiIyraQkwN3d/O+bkACUKJGvU728vODk5AQ3Nzf4+/sDAD7++GM0bNgQEyZMyDxv5syZKF++PI4fP46EhASkpaWhd+/eqFixIgCgXr16mee6uroiOTkZ/v7+cHNzg5OTUxF+uPxhj5G10emArl1lf+XKzKcNM9O2bMmWl01ERGQ1Dhw4gI0bN8Ld3T3zUatWLQBATEwMgoOD0aFDB9SrVw9PPfUUfvjhB9y4Z9UHS2OPkTXq2hWYNQtYtQqYMgUA0KgR4OYGXL8OHDkC1Klj4TYSEZHpuLlJ740l3vchJCQkoHv37vj0009zHCtbtix0Oh3Wrl2L7du34++//8ZXX32Fd999Fzt37kTlypUf6r2LCgMja9SxI+DgABw7BsTEAFWrwtERaNoU2LwZ2LmTgRERkV3TaPI9pGVJTk5OSE9Pz/y5UaNG+P3331GpUiU4OOQeYmg0GrRq1QqtWrXC2LFjUbFiRSxduhSjR4/OcT1L4FCaNfLyMmZbr1qV+XTz5rLdudMCbSIiIrpHpUqVsHPnTpw5cwZXr15FeHg4rl+/jr59+2L37t2IiYnBX3/9hcGDByM9PR07d+7EhAkTsGfPHpw7dw5LlizBlStXULt27czrHTx4EMeOHcO1a9eQmppq9s/EwMhahYXJNku5awZGRERkTcaMGQOdToegoCD4+PggJSUF27ZtQ3p6Ojp16oR69erh1Vdfhbe3N7RaLTw9PbFlyxZ07doVNWrUwHvvvYcvvvgCYRl/84YOHYqaNWuiWbNmqFatGrZt22b2z8ShNGuVMRsN//wjVR0dHDIDo3//lVmVNtDLSkREdqxGjRqIjIzM8fySJUtyPb927dpYs2ZNntfz8fHB33//Db1ej9u3b8PT07PI2ppfxbrHqFevXihZsiSefPJJSzclpwYNAE9P4PZtICoKAFCunDz0emDvXou2joiIyC4V68Bo5MiRmDNnjqWbkTudTooXAUCWyp8cTiMiIjKdYh0YtW3bFh4eHpZuRt7atpUtAyMiIiKzKHBgNGPGDNSvXx+enp7w9PRESEgIVq9eXaSN2rJlC7p3746AgABoNBosW7Ys1/MiIiJQqVIluLi4oHnz5ti1a1eRtsPiDIGRIc8IQJMm8tS+fZZpEhERkT0rcGAUGBiISZMmYe/evdizZw/at2+PHj164NChQ7mev23btlyn2x0+fBhxcXG5viYxMRHBwcGIiIjIsx0LFy7E6NGjMW7cOOzbtw/BwcHo3LkzLl++nHlOgwYNULdu3RyPixcvFvBTW0jWPKOM1WMbNZJDp08DVlYslIiIyOYVODDq3r07unbtiurVq6NGjRr45JNP4O7ujh07duQ4V6/XIzw8HP369ctWsOnYsWNo3749fv7551zfIywsDB9//DF69eqVZzumTJmCoUOHYvDgwQgKCsK3334LNzc3zJw5M/OcqKgoREdH53gEBAQU9GNbhk4HtGgh+xn319sbqFJFnmKvERGR/VAFWMCVclcU9/ChcozS09OxYMECJCYmIiQkJOfFtVqsWrUK+/fvx4ABA6DX6xETE4P27dujZ8+eeOONNwr1vikpKdi7dy9CQ0OzvVdoaGiu0waLQkREBIKCgtC0aVOTXD9PhvuaJfBs3Fi2DIyIiGyfo6MjACApKcnCLbF9hntouKeFUag6Rv/++y9CQkJw9+5duLu7Y+nSpQgKCsr13ICAAGzYsAGtW7dGv379EBkZidDQUMyYMaPQjb569SrS09Ph5+eX7Xk/Pz8cPXo039cJDQ3FgQMHkJiYiMDAQCxatCjXAA8AwsPDER4ejtu3b8PLy6vQbS8wQ3uyBHyNGgGLFnHKPhGRPdDpdPD29s5MBXFzc4NGo7FwqyxLr9cjJSUFd+/ehVb74D4cpRSSkpJw+fJleHt7Q6fTFfq9CxUY1axZE1FRUbh16xYWL16MgQMHYvPmzXkGRxUqVMDcuXPRpk0bVKlSBT/99JNV/Edft26dpZvwYM2ayTYmBrhyBfDxYY8REZGd8ff3B4BsebLFmVIKd+7cgaura4HiBW9v78x7WViFCoycnJxQrVo1AEDjxo2xe/duTJs2Dd99912u58fFxWHYsGHo3r07du/ejVGjRuGrr74qdKPLlCkDnU6XI3k7Li7uoW+I1SlZEqhdGzhyROboP/ZYZgL2iRPArVuytBoREdkujUaDsmXLwtfX1yLrg1mb1NRUbNmyBY8++mi+h8UcHR0fqqfIoEiWBNHr9UhOTs712NWrV9GhQwfUrl0bixYtwvHjx9G2bVs4Ozvj888/L9T7OTk5oXHjxli/fj169uyZ2Yb169djxIgRhf0Y1qtFCwmMIiOBxx5D6dJAxYrA2bNSFLtNG0s3kIiIioJOpyuSP+62TqfTIS0tDS4uLg+VL1QYBQ6M3n77bYSFhaFChQqIj4/H/PnzsWnTJvyVZbFTA71ej7CwMFSsWBELFy6Eg4MDgoKCsHbtWrRv3x7lypXDqFGjcrwuISEBJ0+ezPz59OnTiIqKQqlSpVChQgUAwOjRozFw4EA0adIEzZo1w9SpU5GYmIjBgwcX9CNZvxYtgFmzgCx1mho1ksBo714GRkREREWlwIHR5cuXMWDAAMTGxsLLywv169fHX3/9hY4dO+Y4V6vVYsKECWjdujWcnJwynw8ODsa6devg4+OT63vs2bMH7dq1y/x59OjRAICBAwdi9uzZAIA+ffrgypUrGDt2LC5duoQGDRpgzZo1ORKy7YIhqWj/fkApQKNBo0bA0qXMMyIiIipKBQ6MfvrppwKdn1vABAANGzbM8zVt27bNVy2CESNG2OfQ2b3q1gUcHIBr14Dz54EKFTJjJc5MIyIiKjrFeq00m+HsLMERkNlFZEjAPnYMSEiwULuIiIjsDAMjW2GIhDICIz8/oFw5GVmLirJcs4iIiOwJAyNbcU9glMdTRERE9BAYGNmKXKIg5hkREREVLQZGtqJ+fUCjAWJjgUuXAABNmsihLLP4iYiI6CEwMLIVJUoANWrI/r//AgCaN5cfjx4Frl+3ULuIiIjsCAMjW1KvnmyjowEAZcoA1avLU+w1IiIiengMjGyJYcp+RmAESFFsQFYLISIioofDwMiW5BIYhYTIdscOC7SHiIjIzjAwsiWGwOjQIUCvB2DsMdq5M/MpIiIiKiQGRrakalXAyQlITJQVZCFpR25uwK1b2TqSiIiIqBAYGNkSBwegdm3Zz4iCHByAtm3lqT//tEyziIiI7AUDI1uTS55Rr16yXbLEAu0hIiKyIwyMbE0ugdHjjwNarRTFPnPGMs0iIiKyBwyMbE0ugZGvL9C6texn7TWKjwdu3zZj24iIiGwcAyNbYwiMjh4FUlMzn37iCdl+/DHw+edAtWqApydQtixw8KAF2klERGSDGBjZmgoVAHd3ICUFOHky8+nnn5ep+zduAK+/DsTEyPNJScCoUYBSFmovERGRDWFgZGu0WqBOHdnPMpzm5gasWQO0bAm4ugKffALs3w84OwMbNnDGGhERUX4wMLJFueQZAYCXF/DPP7Kg7DvvAA0aSG8RAEyaZN4mEhER2SIGRrYoj8AIkA4lFxfjzyNGyHbHDuDyZTO0jYiIyIYxMLJF9wmM7lWuHNCokeQYrVpl4nYRERHZOAZGtsgQGJ08Cdy588DTH3tMtitWmLBNREREdoCBkS3y8wNKl5ZVY48ceeDp3bvL9q+/gORkE7eNiIjIhjEwskUajbHX6NChB57eqBHg7w8kJEhyNhEREeWOgZGtKkCekVYLdO4s+2vXmrBNRERENo6Bka0qQGAEAB07ynbdOhO1h4iIyA4wMLJVBQyMOnSQ7f79wNWrJmoTERGRjWNgZKsM1a/PncvXSrH+/kC9ejJtf/16E7eNiIjIRjEwslUlS0qRIiDfvUahobJlnhEREVHuGBjZsgIOp3XqJNtVq2SmPxEREWXHwMiWFTAwatcO8PQEYmNliRAiIiLKjoGRLStgYOTsbKyCvWSJidpERERkwxgY2bICBkYA8MQTsl2yRBKxiYiIyIiBkS0LCpIq2FeuAJcv5+slnTsDrq7A6dPAnj0mbh8REZGNYWBky9zcgKpVZT+fvUYlSgC9esn+lCkmahcREZGNYmBk6woxnDZmjGx/+w04dcoEbSIiIrJRDIxsXSECo4YNZUhNrwcmTjRRu4iIiGwQAyNbV4jACADefVe2P/4IrF5dxG0iIiKyUQyMbF3WwKgA08xatwZGjJD9gQOB//4zQduIiIhsDAMjW1e9OuDoCMTHy7ppBfDZZ0D9+jKprUsX4MYNE7WRiIjIRjAwsnVOTkDt2rK/b1+BXuriAvzxB1C2LHDokNQ4SkszQRuJiIhsBAMje9CihWwLsc5HxYrAmjWAuzuwcaMx94iIiKg4YmBkD0JCZBsZWaiX168PzJwp+5MnA+vXF1G7iIiIbAwDI3tg6DHaswdITS3UJZ56CnjpJdkfOZJDakREVDwxMLIHNWoA3t7AnTvAwYOFvswnnwClS0u+0fffF13ziIiIbAUDI3ug1T5UnpFByZLARx/J/vjxQEpKEbSNiIjIhjAwsheGwGj79oe6zAsvyCy1S5eARYuKoF1EREQ2hIGRvWjbVrarVxc6zwiQ2f/h4bI/bVqBakYSERHZPAZG9uKRRwBfX6nSuGHDQ11q2DDA2RnYvRvYubOI2kdERGQDGBjZC50O6N1b9hcvfqhL+fgATz8t+3PnPmS7iIiIbAgDI3vy5JOyXbr0oYbTAODZZ2X7228PfSkiIiKbwcDInrRpA5QpA1y7BixZ8lCXat9eRuauXgXWri2i9hEREVk5Bkb2xMEBGDFC9seOfagqjQ4OwDPPyP68eUXQNiIiIhvAwMjejB4tvUbHjwOzZz/Upfr2le0ffwDJyQ/fNCIiImvHwMjeeHgA77wj++++K7PUCqlZMyAgAEhI4PppRERUPDAwskfh4UDt2sDly8YgqRC0WqBnT9lfurRomkZERGTNGBjZIycnYMYM2f/uu4daJqRXL9kuXw6kpxdB24iIiKwYAyN71aYNMHCglK4ePrzQidht2sj6tFeuPPRqI0RERFaPgZE9++wzWRn2wAFZ36MQHB2Bxx6TfQ6nERGRvWNgZM98fIDJk2X/3XeBQ4cKdRnDcNrSpVw7jYiI7BsDI3v3/PNAWJjMt+/XD0hMLPAlOncGXFyAM2eAgweLvolERETWgoGRvdNogJkzpbbRwYNAx45SzroASpSQ4AjgcBoREdk3BkbFgb8/8Oefkm8UGQkEBgKdOslc/N69gWHDgG3b7jtOlnU4jYiIyF45WLoBZCYtWgBbtkg56+jonAug/fAD8MQTwPz5Mt3/Ht27AzqddDqdOgVUqWKmdhMREZkRe4yKk7p1JbLZtw/48UepcTRjBjBkiARDv/8ueUi5TO0vVUqm7gPsNSIiIvvFwKi40WiAhg0lKXvYMKlx9NNPUsHREBxFROT6Ug6nERGRvWNgRKJLF2Oto3HjpKLjPXr0kO327UBcnBnbRkREZCYMjMho6FDpTbp1C3jvvRyHy5cHmjaVHO0lSyzQPiIiIhNjYERGOp2x12j2bFmE9h7PPCPbuXPN1ywiIiJzYWBE2bVuDTRrBqSkSIL2Pfr2BbRamfV/8qQF2kdERGRCDIwopxEjZDtjRo4ZamXLSo1IAJg3z8ztIiIiMjEGRpTTU0/JOmv//QesXJnj8LPPynbuXK6dRkRE9oWBEeXk4gIMGCD7v/yS43CvXrJMSEwMsGOHmdtGRERkQgyMKHeGbqE//5RZalmUKCEriQBMwiYiIvvCwIhyFxwMBAUByclS9PEezz0n24ULJU+biIjIHjAwotxpNMZeo1yG09q3BwICgOvXgVWrzNw2IiIiE2FgRHnr10+2mzZJInYWOp3xMIfTiIjIXjAworxVrCh1jZQCfv01x2HDcNqKFcCNG2ZuGxERkQkwMKL7u89wWv368khJARYtMnO7iIiITICBEd3fU08BTk7AwYPAv//mOJy1phEREZGtK9aBUa9evVCyZEk8+eSTlm6K9SpZEujaVfZzKXXdt69st23LdWk1IiIim1KsA6ORI0dizpw5lm6G9TN0C82fD+j12Q4FBgKNG0saUi5FsomIiGxKsQ6M2rZtCw8PD0s3w/p16wZ4eQHnzwP//JPj8OOPy/aPP8zcLiIioiJW4MBo4sSJaNq0KTw8PODr64uePXvi2LFjRdqoLVu2oHv37ggICIBGo8GyZctyPS8iIgKVKlWCi4sLmjdvjl27dhVpOyiDiwtgGG7MJZnIEBj9/Tdw544Z20VERFTEChwYbd68GeHh4dixYwfWrl2L1NRUdOrUCYmJibmev23bNqSmpuZ4/vDhw4iLi8v1NYmJiQgODkZERESe7Vi4cCFGjx6NcePGYd++fQgODkbnzp1xOUuiS4MGDVC3bt0cj4sXLxbwU1Pm3PwFC4Br17IdCg4GypcHkpKADRss0DYiIqIiUuDAaM2aNRg0aBDq1KmD4OBgzJ49G+fOncPevXtznKvX6xEeHo5+/fohPT098/ljx46hffv2+Pnnn3N9j7CwMHz88cfo1atXnu2YMmUKhg4disGDByMoKAjffvst3NzcMHPmzMxzoqKiEB0dneMREBBQ0I9Njz4KNGgAJCYC9wSsGg3QvbvscziNiIhs2UPnGN3KWGC0VKlSOS+u1WLVqlXYv38/BgwYAL1ej5iYGLRv3x49e/bEG2+8Uaj3TElJwd69exEaGprtvUJDQxEZGVm4D/IAERERCAoKQtOmTU1yfaun0QBvvSX706dLgJSFYThtxYoc+dlEREQ246ECI71ej1dffRWtWrVC3bp1cz0nICAAGzZswNatW9GvXz+0b98eoaGhmDFjRqHf9+rVq0hPT4efn1+25/38/HDp0qV8Xyc0NBRPPfUUVq1ahcDAwPsGVeHh4Th8+DB2795d6HbbvCeeAKpWlaG0Tz/NdqhtW8DdHbh4Edi3zzLNIyIielgPFRiFh4cjOjoaCxYsuO95FSpUwNy5c7Fw4UI4ODjgp59+gkajeZi3LhLr1q3DlStXkJSUhP/++w8hISGWbpJ1c3AAJk6U/UmTgOjozEPOzkDnzrLP4TQiIrJVhQ6MRowYgRUrVmDjxo0IDAy877lxcXEYNmwYunfvjqSkJIwaNaqwbwsAKFOmDHQ6XY7k7bi4OPj7+z/UtekBnnwS6NEDSE2VhOz4+MxDhuG03xcrqJScCfdERETWrsCBkVIKI0aMwNKlS7FhwwZUrlz5vudfvXoVHTp0QO3atbFkyRKsX78eCxcuxJgxYwrdaCcnJzRu3Bjr16/PfE6v12P9+vXs9TE1jUaSr318gKgoGV5LSgIA9Kh1DGt1nRF5xAv6Eu5cQI2IiGyOQ0FfEB4ejvnz52P58uXw8PDIzOnx8vKCq6trtnP1ej3CwsJQsWLFzGG0oKAgrF27Fu3bt0e5cuVy7T1KSEjAyZMnM38+ffo0oqKiUKpUKVSoUAEAMHr0aAwcOBBNmjRBs2bNMHXqVCQmJmLw4MEF/UhUUOXKSZnrtm2BtWuBevWARx6B16JFCE3PKGSUBqhnn4XG1xdo08aizSUiIsqvAgdGhqTptm3bZnt+1qxZGDRoULbntFotJkyYgNatW8PJySnz+eDgYKxbtw4+Pj65vseePXvQrl27zJ9Hjx4NABg4cCBmz54NAOjTpw+uXLmCsWPH4tKlS2jQoAHWrFmTIyGbTKRpUwmOnnsOOHVKHgBSWnfAo7u/wOt3P8ITKUtkMbUzZ2QhWiIiIitX4MBIKVWg8zt27Jjr8w0bNszzNW3bts3X+4wYMQIjRowoUHuoCLVtCxw+DHz7LXD3LtCkCZw6d0a7d7V4dtIvaKWtBv/Yi8DixUC/fpZuLRER0QMV67XSqAh4eACvvw68/z4QFgZotXj/fSCwmisi9MPlnOnTLdtGIiKifGJgREXOzQ2YORP4HsOQDCdg506gONd/IiIim8HAiEyidWugeXc/LEbG4rO//GLZBhEREeUDAyMymffeAxbgGQBA2m+/c60QIiKyegyMyGSaNQP07TviNjzgcOmCDKkRERFZMQZGZFJDXnbBn+gOANAv+t3CrSEiIro/BkZkUo89BqxxewIAkDx/MVDAcg9ERETmxMCITMrZGSjZtwsS4QbXuLPAvn2WbhIREVGeGBiRyfV93g0r0Q0AkDJ/sYVbQ0RElDcGRmRyLVoA2/xkOO3uPA6nERGR9WJgRCan0QBln++KO3CBZ9xJ4N9/Ld0kIiKiXDEwIrN4+nkPrEEXAED8DBZ7JCIi68TAiMyiShVgd+2BAADtLz8DqakWbhEREVFODIzIbKr+rxti4Y8SCZeh/lxh6eYQERHlwMCIzOaJZxzxi24QAOD2lB8s2xgiIqJcMDAis/H2Bs53eh56aOC1bTWwe7elm0RERJQNAyMyq87h1TAXzwEA9GNe59R9IiKyKgyMyKw6dQKmlR6Pu3CGdstm4BfOUCMiIuvBwIjMytERaPNcBUzGG/LEkCHAsmUWbRMREZEBAyMyu+eeAz7EOCzU9gXS0oBevYB27YB16zi0RkREFsXAiMyuYUOgdh0dntX/jEPtRkg30qZNQMeOwGOPASkplm4iEREVUwyMyOw0GmDAACANjngp7SsgJgZ45RXAxQVYtQoYPdrSTSQiomKKgRFZRP/+EiD98w9wOq08MH06sGiRHIyIAJYssWwDiYioWGJgRBZRrhwQGir7mRPTHnsMeCMjKXviROYbERGR2TEwIot5TsoZYc6cLDHQmDEypLZnD7B9u8XaRkRExRMDI7KYXr0kBjp5EoiOznjSxwd49lnZnzrVUk0jIqJiioERWYy7u3E4bfnyLAdGjpTt0qXA5ctmbxcRERVfDIzIonr2lG22Go916wJNmgDp6cDvv1ugVUREVFwxMCKLeuwxmZ22dy9w/nyWA888I9tff7VIu4iIqHhiYEQW5ecHtGwp+3/8keXA00/L9p9/gP/+M3u7iIioeGJgRBbXo4dss+UZlS8PtG4t+wsXmr1NRERUPDEwIoszBEYbNwI3b2Y5YBhOW7DA3E0iIqJiioERWVyNGkDt2rKe7OrVWQ48+SSg00lNo5MnLdY+IiIqPhgYkVXIdTjN1xfo0EH22WtERERmwMCIrIJh2v6qVcCdO1kOZJ2dxiVCiIjIxBgYkVVo2hSoUAGIjwdWrsxyoFcvwNkZOHxYhtSIiIhMiIERWQWtFujbV/bnz89ywNtbco0A4IcfzN0sIiIqZhgYkdXo10+2K1feMztt6FDZ/vorkJBg7mYREVExwsCIrEa9ekCdOkBKCrBkSZYDjz4qU9cSElgJm4iITIqBEVkNjQbo31/2582758CLL8r+l18Cer3Z20ZERMUDAyOyKoZJaBs3AhcvZjnwwguApydw5Ag0a9ZYpG1ERGT/GBiRValcWdZOU+qelUA8PYFhwwAA2ilTLNM4IiKyewyMyOrkOpwGACNHAo6O0G7ZAp+oKHM3i4iIigEGRmR1nnpKpu/v3QucO5flQGAgEB4OAKgzaxaQnm6ZBhIRkd1iYERWx8dHhtMAYMWKew6+/z5UyZLwOnsWmlmzzN42IiKybwyMyCo99phscwRGpUpB/957AADdO+8AcXHmbRgREdk1BkZklbp3l+2GDUBiYvZj+pdews0qVaC5eRN49VVzN42IiOwYAyOySrVrywy15GRg/fp7Djo4IOrll6G0WmDBAoCJ2EREVEQYGJFV0mjuM5wG4Fa1alBPPSU/fPqp+RpGRER2jYERWa2sgVFuxa7Tx4yRnd9+A2JizNcwIiKyWwyMyGq1aQO4uwOxscD+/bmcEBwMhIVJ1BQRYfb2ERGR/WFgRFbL2Rno1En2cxtOAwAMHy7b337jGmpERPTQGBiRVbtfnhEAiZw8PYELF4AdO8zWLiIisk8MjMiqde0q2z177llU1sDFBejRQ/Z/+81s7SIiIvvEwIismp8f0KyZ7K9alcdJTz8t20WLOJxGREQPhYERWT1Dscc8h9M6dpThtIsXge3bzdYuIiKyPwyMyOoZ8ozWrgXu3s3lBGdnoGdP2edwGhERPQQGRmT1goOBcuWApCRg48Y8TjIMpy1eDKSnm61tRERkXxgYkdV7UBVsADKc5uUlRY+2bTNb24iIyL4wMCKbkDUwUiqXE5ycgF69ZP+XX8zWLiIisi8MjMgmdOgAuLoC584B0dF5nDR4sGznzQNu3DBb24iIyH4wMCKb4OoqwREArFyZx9e2dWugfn1JRpo503yNIyIiu8HAiGyGYTht1SpN7idoNMCIEbIfEQGkpZmnYUREZDcYGJHN6NZNtjt3anDrllPuJ/XvD5QuDZw+zV4jIiIqMAZGZDMCA4EGDQClNNi3zy/3k9zcgPffl/2xY4H4eLO1j4iIbB8DI7IphirYu3fnERgBwEsvAdWqAXFxwCefmKdhRERkFxgYkU0x5Bnt3++LlJQ8TnJyAr74QvY//xyIijJH04iIyA4wMCKb0qQJ4OurcOeOI7ZuzSMJGwAefxx44gmpgv3CC1xcloiI8oWBEdkUrRYIC5MKj3nOTjP4+muphr13L/DHH2ZoHRER2ToGRmRzunWT3p+VK7W5V8E28PcHwsNl/9NP8yiZTUREZMTAiGxOhw4KDg7piInR4NixB5z8yiuAszOwYwfXUCMiogdiYEQ2x8MDqFv3GoD7LCpr4O8PDBwo+9Onm7ZhRERk8xgYkU1q0uQSgHwERgDw8suyXb4cuH7ddI0iIiKbx8CIbFLTpnEAgK1bgStXHnBycLBUhkxJAebPN3nbiIjIdjEwIpvk55eERo30SE8HfvstHy8YPFi2s2ebsllERGTjGBiRzerXT2aZ/fJLvk4GHB1l6v7u3aZtGBER2SwGRmSznn5aD61WJpzFxDzg5DJlgGeekf0vvzR524iIyDYxMCKb5e8PhIbK/rx5+XjBqFGy/e034Px5k7WLiIhsFwMjsmnPPivbX37JR/3Ghg2Bdu1kmZDPPzd524iIyPYwMCKb1rMn4OoKnDgB7NmTjxe8/bZsIyKAQ4dM2TQiIrJBDIzIpnl4SHAE5DMJu2NHeUF6OjBiBBeXJSKibBgYkc0zDKctWACkpeXjBV9+Kd1MmzYBkyaZsmlERGRjGBiRzevYEfDxAS5fBtauzccLKlUyLg/y3nvA6tWmbB4REdkQBkZk8xwdjTPx587N54teeAF48UXJ2O7XDzh50mTtIyIi28HAiOyCYTht2TIgPj6fL5o2DQgJAW7eBHr1AhISTNQ6IiKyFQyMyC40bQrUqAHcuQP8/ns+X+TsDCxeLAWRoqOBIUPyMeefiIjsGQMjsgsaDTBggOzPmFGA+CYgQIIjR0dg0SLglVeAu3dN1k4iIrJuDIzIbgwdKp1Au3YBkZEFeGGrVsDXX8t+RATQoIH8fOIEp/MTERUzDIzIbvj6Av37y36Bl0MbNgz44w+Z3nbsmPQc1aghPUrvvgvExhZ5e4mIyPowMCK78uqrsl2yJB8Ly96re3fg+HGZyh8SAri4AHFxwIQJQLVqwAcfACkpRdxiIiKyJgyMyK7Uqwd06SIjYBMnFuIC3t7SW7R9O3D7tmRyt2gBJCUBH34ItGxZiIiLiIhsBQMjsjtjx8r255+Bs2cf4kKOjkDv3hIkLVgAlCoF7N0rgdKuXUXSViIisi4MjMjuhIQAHTrI8iCffloEF9RogD59gAMHgMaNgatXgfbtC5jhTUREtoCBEdml99+X7U8/ARcuFNFFAwNlfbXQUCAxEejWDTh0qIguTkRE1oCBEdmlNm2A1q0lV3ry5CK8sLu7lNdu0QK4cUMStq9fL8I3ICIiS2JgRHbLkGv0/fcPmWt0rxIlgBUrgMqVgdOnpUZAenoRvgEREVkKAyOyWx06AG3bSiHrkSOL+OKlSwNLlwKursCaNTJjjYiIbB4DI7JbGo0UsnZwAJYvB/78s4jfIDhYuqMAYPx4eRMiIrJpDIzIrgUFAa+9Jvv/+5+UIypSzz4rdY8AoF8/YMeOIn4DIiIyJwZGZPfefx8oXx44cwb45BMTvMEXX0hVyaQkmam2e7cJ3oSIiMyBgRHZvRIlZJUPAPjsM+DkySJ+A0dHYNEioHlzmaHWtq0kZxMRkc1hYETFQo8e0qmTmgq8+aYJ3sDdHVi7FujcWXqOevQAvvvOBG9ERESmxMCIigWNBvj8c0CrlQVm//nHBG/i4SEZ3oMHy2Jtw4cD774LKGWCNyMiIlNgYETFRp06wAsvyH54uPQeFTlHRym3/cEH8vOECbLeWmysCd6MiIiKGgMjKlY++QQoUwb491/JNzIJjQYYN04CJAcHqZQdFCQ/s/eIiMiqMTCiYqVMGeDLL2X/o4+AU6dM+GZDhgB79sjCszdvSndVz54mqBlARERFhYERFTv9+0tV7ORk4PXXTfxmwcFS2+iLLwBnZ+CPP4COHYHLl038xkREVBgMjKjY0WiAqVMBnU4SsTdsMPEbOjgAo0fLrDVvb2D7dqBhQ2D1ag6tERFZGQZGVCzVrQu89JLsDxsGJCaa4U1bt5agqHZt4OJFoGtXoEULmcnGAImIyCowMKJia/x4IDAQiIkxUW2j3NSuDezaBYwaJQvQ7toFPP649CAtWgSkp5upIURElBsGRlRseXsDs2bJfkQEsG6dmd7Y3R2YMkXWKHnrLfn5wAHg6aelK2vuXCAtzUyNISKirBgYUbEWGgq8/LLsDx4M3Lplxjf39QUmTgTOnpW6R97ewNGjwIABQK1aQHS0GRtDREQAAyMiTJ4MVK0K/PcfMGKEBRpQqpTUPTp7Fpg0CfDxkfG9Dh2AI0cs0CAiouKLgREVeyVKAHPmyHIhv/wiI1kW4ekpyU5Hj0rO0eXLQPv2wLFjFmoQEVHxw8CICEDLlsZVPF56CYiKsmBjSpWSqf316wOXLgHt2gHHj1uwQURExQcDI6IM77wjo1eJiTKT/uxZCzamdGnJBq9bV9ZZY3BERGQWDIyIMuh0wOLFxlgkLAy4ft2CDfLxAdavl9VvL16UqO38eQs2iIjI/jEwIsrC21sKUgcGSt5zjx5AQoIFG+TrK6W5a9WS7PDOnYErVyzYICIi+8bAiOgegYESHHl5AVu3ypR+i/Yc+foCf/0FlCsn0VrLljJrjYiIihwDI6Jc1K0L/P235EHv3Ak8+qiMZllMhQoyrFaxInDyJNCsGbBmjQUbRERknxgYEeWhWTNgyxYgIAA4dAh45BELd9TUrAlERgJNmkgXVteuwNixXEaEiKgIMTAiuo86dWQ4rWpV4PRpWQf20CELNqhsWWnQSy/JwrPjxwOtWkn3FheiJSJ6aAyMiB6gcmXgn3+AevVktlrHjhIkWYyzM/DNN1KN0s1Nxvo6dwaeeEIaSEREhcbAiCgfypYFNm0yBkedO0thaovq31/yjV59FXBwAJYuBapXB957D7h508KNIyKyTQyMiPKpVCnJd65UCThxQlJ84uMt3KiyZYEvvwT27AGaN5fqlJ98It1cb7whFbTv3LFwI4mIbAcDI6ICCAiQmfNlygB79wK9egHJyZZuFYDgYEnMXroUCAqSHqPPPgM6dYKDry/ajxgBXZs20ru0ahWQmmrpFhMRWSUGRkQFVKOG1Dlyd5cZ9AMGAHq9pVsFQKMBevYEDh4EFi0CBg4EypWDJjkZHv/9B21kJDBtGtCtm/Q0zZhhJQ0nIrIeDIyICqFJE+mccXQEfvsNGDnSiiaF6XTAk08Cs2cD588j9dAhbB0/Hmk//wwMHw74+QHXrgEvvwy0bZv3GmyGD3TnjqzblpJirk9ARGQxDIyICik0FJg7Vzpqvv5aUnusjkYDVK+Oa/XqQfXtK71E//0HTJ8OlCgh0+3q1wcmTco+vPbTT7I+yujRsoBtx47A559b7GMQEZkLAyOih9Cnj4xOAcD77wPff2/Z9uSLgwPwyitAdDTQqZMkSb39towRvvqq5CqNHAncvi2J3Tt3yuuWLLFos4mIzIGBEdFDeuUV4N13Zf+ll2SIzSZUqiTT7GbPBkqWBM6ckSivZUuZ3VanDuDjA5QvL+fv3QtcuiTHxo6VLjKrGT8kIioaDIyIisD48cALL0guc9++wIYNlm5RPmk0kqR97pxEdCEh8rxOB8yfD1y4ILWSGjWS56dPlwSr8eOlXtK331qu7UREJsDAiKgIaDSSvtOzp4xMde5sYzGDu7s0futWYOFCWWKkfn3JLndykqJNADBxInD0qOQnAZKD9NlnwLFjkqP06KMSOFlFDQMiooJjYERURBwcpJPl6aeBtDQZVhs2zMZiBK1WPkD79tmfDwsz7tevD5w6JdHf3btSSDI4WPKS/vlHhtzWrjVvu4mIiggDI6Ii5OoKLFggk7w0GuCHH2RSl80vYda8OdCmjQy1rVsH+PpKraSJE4HGjSX6mzHDeP6iRbJNT5eiT6y+TUQ2goERURHTaIA335QC097eMsmrcWNgxw5Lt+wh6HSyWNz27ZKQDQAeHsBbb0kCd0CAPOflJdvly6Xu0auvyjDckCGWaDURUYExMCIykS5dgN27ZXJXbKx0uHz/vR1O5CpTBvj9d8kvWr5cqmrfugWMGiUFngDpRouMtGw7iYjygYERkQlVqybxQO/e0oHy4ovAc8/JjHe70qIFsHmzRH9PPCHPffONbEuVku1LL8kaKnq9dKdVqgTMmmWR5hIR5YWBEZGJeXhIys2kSTIiNW8e8MgjwNmzlm6ZibzzDvD880Dt2pJgtXOnzHo7cEDKhTdtKkuWnD0rY45JSZZuMRFRJgZGRGag1UoMsHGjpOhERUl8sGWLpVtmAmXLAj/+CBw+LAWdqlUDtm2TQk8eHsC+fcZk7CtXJEM9LQ343/+Axx8HbtywbPuJqFhjYERkRq1bA3v2AA0bSkzQoQMwdaod5h3dq359CYCOHQOGDgX69TOuvTZhAtC9O/DVV8CffwIDBshwGxGRBTAwIjKzChWkjuIzz0hHyahRMrJ065alW2YGZctKBvq8ecCIEUDVqsDlyzKzzcEBcHYGVqyQ4OjMGeDaNRmDfOcdSdIiIjIxB0s3gKg4cnOTYpCtWknx6CVLZHhtzhx5rlhwdpbM9DlzZIxx+HDg6lVg8GAJnObNy36+TidLkQASNJUvL88RERUh9hgRWYhGI50mW7cCFStKMenWraWAtN3NWsuLjw/w2mvSS/TYY8CgQZKP9MgjxnOqVZPthAmSxf7KK0DlylJ5Oy3NIs0mIvvFwIjIwpo1k96iwYMl12j6dEnJ+esvS7fMQlq2lKVFkpMlEev4calxoNfLciWG2kjr18s45IULUkiyY0cZkrP7hC0iMiUGRkRWwNsbmDlT/q6XLy+9R126AH36ABcvWrp1FuLkJMUjNRqpifS//wGlS8sCtqNGyTlffw0EBgLTpslSJWFhQLducgNjY2XB28uXLfs5iMimMDAisiKdOwOHDsnffa0W+O03oFYt6UVKT7d06yzI3V2Cn0uXgLg4YMoUCZYqVJDjQUHAyy9LMLV6tSR1BwRILaWyZeW1AHD6NPDZZ8CuXZb7LERk1YplYNSrVy+ULFkSTz75pKWbQpSDh4f83d+zR4bZ4uMl76hZM1lipFhzcJAeI0AqaZ85I8Nt//4LRETImGRIiBzXaORm6vUy1ObjIwHTG2/I8iVLl0pv0vTpkrd09aqFPhQRWZNiGRiNHDkSc+bMsXQziO6rYUNZs3XGDBlq27dPFrl/6SXg+nVLt85KaDQy3KbN+F9Z7dpy0xISJDH71i3g00/lvKtXJf+ocmXJX+rdG/Dzk6jz66+B9u2BY8fgGhcHza+/AkeOWPazEZFFFMvAqG3btvDw8LB0M4geSKeTWexHjwLPPit/17/9FqhZU5YZYx3EPJQoIcGSRiM9ROfPAwcPylDcsWPAsGHGqf5BQYC/P/Dvv3CsVw+dXnwRDgMHAk2aSMmAFSuAL7+UekqXLln2cxGRyVldYLRlyxZ0794dAQEB0Gg0WLZsWY5zIiIiUKlSJbi4uKB58+bYxXwBsnN+fsDcuVLuJyhIOj+GDJFlRTZutHTrbEC5ckC9enIjHR2B774DUlNlnbboaFkAt1kzKCcn6LVaqPLl5dizz0pV7tGjgbffBqpXl+Tuxx+XRLANGyz9yQrv8GGZ/UdE2VhdYJSYmIjg4GBERETkenzhwoUYPXo0xo0bh3379iE4OBidO3fG5SwzTxo0aIC6devmeFwsttN7yF60bStpNJ99Zlx2rH17+TvNkZ8C0mgAV1fZ1qgB7NyJtPh4rFi4EGlHj8osOF9foEED4KmnpAcpIQFYtUqWLpk6VdZ0eeQRyV1q1UrGPa9flyG86Gjr7dJTSjL927WThHQiymR1la/DwsIQFhaW5/EpU6Zg6NChGDx4MADg22+/xcqVKzFz5ky89dZbAICoqKgia09ycjKSk5Mzf759+zYAIDU1FampqUX2PoZrFeU17RXvlaTF9OsHfPyxFt9/r8Wff2qwapXCCy/o8f77evj6Gs/l/cq/1LQ0KEdHpAKylpthPTcA0Ouh+esvIC4OmpQUaPbuhWbOHGi2bZPjp04B27dDjRwp56anQ9WrB31YmPROJSdD1a0L9dxzEmC5u0v1b0uIiYHjf/8BANK2b4cKDCzUZfjdyj/eq4Ixxf3K77U0SllvNTSNRoOlS5eiZ8+eAICUlBS4ublh8eLFmc8BwMCBA3Hz5k0sX74839fetGkTvv76ayxevPi+533wwQf48MMPczw/f/58uLm55fv9iEzlwgV3/PxzEHbtKgsAcHVNRe/eJ/D44zFwdrbSHgs74XHuHMocPIiEcuXgee4cym/cCK8zZwAAegcHaHOpzJ3m4gKHu3eR4uGB408+ieu1aiEhIACpZsx7DNi6FU0zgr7jTzyBI889l+MclytXkOztDeXoaLZ2EZlSUlIS+vXrh1u3bsHT0zPP86yux+h+rl69ivT0dPj5+WV73s/PD0ePHs33dUJDQ3HgwAEkJiYiMDAQixYtQohhiu893n77bYwePTrz59u3b6N8+fLo1KnTfW9sQaWmpmLt2rXo2LEjHPk/ovvivcpp6FBgy5Y0vPmmFnv3OmLevCBs2VIbEyemo2fPFKxbx/uVH0Xx3Uo9cULqKXl4QP30kxSadHICAGgXLoTDhQsAAKf4eNSdNQsAoDQaoEED6Hv3Bm7ehOaff6AfOhSaGzeg/eUXpL/zDlTv3g/9+TSzZ0Nz7ly2oljVEhNRuWvX7OetXw+HoUOR/r//QZ+11+zez8rfxXzjvSoYU9wvw4jPg9hUYFRU1q1bl+9znZ2d4ZxLd7ejo6NJvtymuq494r3KrkMHqVu4YIHkCZ87p8GzzzqgVSstevf2QteuvF/59VDfraAg4/4772Q/9sknUsGzcmVg8WJg9mzgv/+gOX8e2L8fuv37M0/VZplU4tC/v8yuc3WV5VEqVSp4u2JjZYqjXg94eRnf58ABaO/9rH/8AQDQ/f47dFOnSh7WfRSL38UrV6QW1kMqFveqCBXl/crvdawu+fp+ypQpA51Oh7i4uGzPx8XFwd/f30KtIrIeWq3kHh09Cnz0kfwd3bZNizFj2mD4cB1iYy3dwmLOxQVo3BgoVUpKBmzfDpw7J0HLjz/KOjA9egBvvSXnurtLdn16OjBxIjB2rLx++nSpvbRqlRS3PH4cOHsWuHMn53teuSLH5s0zJoPfumU8Hhsr1cSzMsxWu3CBydmABLC+vjKbkeyeTQVGTk5OaNy4MdavX5/5nF6vx/r16/McCiMqjlxdgfffl5I9zzyjh1IazJypRbVq8rc1Pj7/1zp1SgpDZ6TOkCn4+wPPPy/LmSxbJkHQ+fMS0Pz9NzBhgiyg26CBzHobOVL+o3TrJisO16wpvUilSgFdu0p10E6dgDlzgGrV5PHFF9nf08VFeq4AWWOuTx/g5k25fnS08bzNm2W7cKH0gKWkSJsmTTIOyen1stjfiROmvU+WYqiJsWWLZdtBZmF1Q2kJCQk4efJk5s+nT59GVFQUSpUqhQoVKmD06NEYOHAgmjRpgmbNmmHq1KlITEzMnKVGREblywNz5qSjQYOtWLr0EezcqcX48VIkcuxY6bTISH/J0wsvyN+FyEh5cBTATMqUMe6//bZs794FPvgAOHBAot8TJ6S3JzlZjt29K8GVwdq1xv1Ll2QWXN26wN69EmSVKyc9Qvv3y+PaNVlzLqstW2QIqW9fmeZ/9670nCQlQePvD5QsCc2sWVKSvW5dKaT5gKE3m3PqVPYt2TWr6zHas2cPGjZsiIYNGwIARo8ejYYNG2Ls2LEAgD59+uDzzz/H2LFj0aBBA0RFRWHNmjU5ErKJyKhWrRvYsiUdixdLjcIrV6TDIShIFqrNq9zOpk3Gfyzv3QtMniz7u3YBO3eapemUlYuL9NSsXg0sWSLDaJcvy9DY3btS2GrKFPmPaih70qWLPABZBmXiRIlu+/SRYTkDNzdg/XrgiSfkZ0Me04oVxqAIkCrgSUkAAO033wBKQWcYYoqOluFBexMTI1sOKxYLVtdj1LZtWzyogsCIESMwYsQIM7WIyD5oNPI37/HHJZ3lww/l//d9+sg/9N99V+oYGlbKUEp6lQA5Hh0NjB8PDBgghSbT0iS1pTB5wGQCGo0MoWX8oxJPPgmcPCnFJ5OTZYiuUyegdGkJbBwcJKg6cQLo318Cq969ZagMAF57TYbsDIvrtmsH3L4tEbJGAzg4QLt7NyqvWgVN1tpxX38t7xcdLUlvw4dLztSSJcCaNVJM05YkJSEzOS8uDkhMNC5kbDBggPxr488/5b6STbO6HiMiMi1HRxn1OHlSRmU8PORvWN++sgbrrFnyt/GjjyQH19lZOigMf1/HjZMc39RU6TwAJDVlwoScObxkQRqNdA9qtTLs1revBEWA8Y+3r6/kBnXoIPlKmzcDAQFyfu/ewKBB8vOnn0qi9zffACVLAm++KVn+AOr/8INcyxCQLVgg1zPkQT32mOQ3nT4t1cSVkoi6dWvg44/l502bgLxWJtDrLbNqslLyvvf2Et378+XLsl7PmjXZc7PIZjEwIiqm3N0lyDl7VoKgUqWk82DIEPkH8QcfyHlffw0EBkpnAwD8/LPxGj/+KH873nxTepzef9/sH4OKUosW8iU4fVoCop9+kplpb7whw3jNmsl/8IkTgTffhMrIg1JarSSuGSbB+Poah/L++st4/b/+kvVsOncGtm6VL0z//tIb1aABkFGNG3PmSNfmqVNSpMvXN3vuVF7i4qRXqyjMni2B5HvvZX/+3sDo0CHj/sGDRfPeZFEMjIiKuZIl5e/T2bOyAoa/vwyTAcCYMZJ8DQAdO8rWkI/k5iajDB9/DMyfL88VoEQYWSs3N1ls90Fq10ba+fPY8NVXSNu3T4KmlSslAe3CBelhMiSNlysn3ZSARNFnzhh7rX79VbZXrshYb0SE9FT9+af0PM2cKbPfRo2Sbsqs9HpZs+6PP6QLtFo1oHlz6fLctOnhAhXDl/rehczvTcD+91/jfn7f78IFLm5oxTgYSkQApAfptdeAV1+VlIrbt2VozaBdOxmV0eslDykiAhg82DicBhgnOC1dKv/QL1/e7B+DzEmnQ3z58sailiVLAk2bGo+PHw/UqSML8JYrJ2Owx45JT8wnnwDdu0sdp6eekhl0u3bJA5ChwKw1Io4dk/ykCxekttPw4RKUjB0rX8imTWUNuqNHJbD69VcZJ46JMc7wy+9sudTUnEnkGo0Mrx09Ksnt3bpJ12rW4TNDYJSeLknr7dtLG7JSSn6Zzp2T4MhQMoGsBnuMiCgbnU6GzoKCsv8d8faWTgFARlwGDpQRkXt17ix/D4cMMUtzyZrpdDJUVrOmRN6zZknA8eefUn9p7VoZj503T2oj9eghVbl79zb22JQrJ92SgARKqakyJNerl3F2QHo6sGOH8X0NvVDx8VJ+oHZt4NFHJZH81q3sBS6zOn9ehs5WrsyceZfJkEP17bcyY8GwVFRuPUaffAL07AmMGAHcuCHXNNR4io6W/eRk6VUjq8MeIyLKt3795O/PM89I0BQRAdSrJ/8I7tNH8o+uXJFz162Tc5s0kX88OzlJ7cF//pE0lR49LPtZyArUqGGcpda0ac5hqwoVJEovW1Z6m1xdJfJevBiYNk1m0vXvD2zYIN2cTz8tdZcuXZJeoqtX5VxAepyCgyVZWq+X6D4sTGaZ7d8vgc4bb0iNqFyWgUJoqJRDMJg7V0onZO0xiouTbtPp0+XnBQuk63XZMui2bgVGjYI2S4Fi/P03EB4u+5cvS0+aYVooWY6iArl165YCoG7dulWk101JSVHLli1TKSkpRXpde8R7VTBFeb/0eqWOH5etwaFDSh04oNSaNUpJiKSUTifbatWUKlfO+PyMGUo5Ocn+rl0P3Zwix+9WwVj0fp09q9TixUqlpCi1Z49S4eFKXb6s1JIlSjVrptTevUq1by9ftuBgpfz8jF/E/D769DHur12b8/irr8rW0VGpSpVkv0ePPK+37quvVHqXLsbn3N2VSk5WasECpTQapV56Sam0NKX++EOpK1eMn/W//5TascP899iCTPHdyu/fb/YYEVG+GWaAZ2VIL6lSxZiQ/euv0qtkKGLv4CAJ3Yb8WwD46ivg2WdllvbAgfZXLJlMrEIFeQBSqNJQrLJXL3kA0lu0bJkMzV29KsNz3bpJz8yaNTKU5+QkX9rly+U17doZq5q+9poMhWm1wCOPAJ6e0gM0YoRM15w6Vc6rVUt6vs6cMV4nJERKxWdRZeVKaAzLijg5SU7UsmXyi6GUVBS/ckXaXbWqdLm6uQGtWsnsiPXrJW/pXnFxMq2UZemLBAMjIioS7u6S+nHnjsxg02gk5aJ5cxklCQ6WEQ5DkPTrrzIaAcjzb70lfxsSE+VaRA+tZEmZIQBI7lLWehIvvigPQIbW5s6VZOpOnWSYzclJ8oqylhvYvFm+vDVrAosWGQt31asnX/Dff5efDcOCtWpJka/x44H33kOlv/6CRimZ9de+vfwSPPecsaimXm8c+ouJkTylhg0lKAKkJsb27ZIAvmCBjE1fuyalDTp2lNworVbGqi9elMqsD/qlSk83//CdYVhUKflsFSta17+MiqyPqpjgUJrl8V4VjLXcr+XLlXJ2VmrKFKWaN88+yqDRKFWjhlIuLrI/eLCMJtSpo1REhPnaaC33ylbY7f1KTc0+XpybM2eUGjdOqccfl2G7pCT5sm7erFR6upwTHa3U1q1KpacrfZ06xi/8Cy8otXSp8WcXF6Xmz5cvv2E4ztMz+y+JVmscFjQ85+amlI+P8edx45T64gulvLzk54gIpTp3VsrVVakVK6RNly8rNXmyUps2KbVzp1L+/kr16iVDeCkp9//chr97er1St2/L/t27SkVG5nxderpSp07J/rFjSr3yilKXLin1zTfStkWLlPrsM9n//ns578aNzJdbciiNgVEBMTCyPN6rgrHG+/Xnn/I3YNgwpYYPv3+ah1ar1Lx5Sk2frtSWLQ/+e/UwrPFeWTPer/xLuXlTbZ40SaUuWiQBhl6v1JEjkjt0/rycNHWqUgMHKpWQoNT+/Uq1aCG/BJ06KfX669l/KSpWNP5sCITu9/DwUGrIEAmmDP8a8fY2Hu/eXYKxunWVWrlSgpoPP1SqWzdpY+/eSjk4KDV3rlIvvyyJhIsWSVAFSEA2ZYrkTf31l1KjR8vz332nVOvWsj9kiFJVqsh+q1bG/caNJYgDlPrhB7lfzDEiouLkscckvcLNTXryu3aVUYzKlWUprmeekecDA6UYcv/+xteGhEitpZMnJf1j7NicpWKIrI6bG27UqgXVtasxF6hWreznjBxp3G/QANi2TWbM1akjQ3harczQ691bcop69JDjf/0ly64sXiy5VoMHy4y3JUtk7Lp2bSkrMHOmXLtCBamjdPOmVDi/eFFKKAAyy65bt+ztWrnSuD9kiLHQ5nPPycxAQErl370rx154wbi+3OjRMpQHSDVxQ4XYbduM19y711g4c/x4qUNlQQyMiMgi3Nxkq9NJnT+DypVlxvWpU/L//ZYt5f/VLVrIbOnIyOw5revWyd+N69dl3dSnn2aOEtkJrdaYVA5IeYCs1q2TYMTFRfKV5s2T1wDyrwlD/aaGDaUsQMmSUlejXTsJktavByZPliqtM2dKpfL//pMClleuSK2p0qXlPEdHmWlx4IBc35CIDkh5g/h4Y7vOnzfuG4IiwBgU5ebGDdmeOycVYnv2LNCtKkos8EhEVqdlS5mx5uEB7NwpydmRkTLp5803JVezXTvAxweIipK/B6tXA88/L/+gfuQROdazpxQXTkiQHigiu+PiYtzXZvmT7u4uhTE7dZJfht9+k1lv7dtLovPzz8ssvcBA6W26fl3qOE2fLr9waWnSG/X33/ILtm2bzORr1Up6hLZtk1/QOnVkSRbDexqKbgJyPYOXXzbuP/WUcT9r75ShVL5htp+FsMeIiKyam5uxd6lsWflHs+EfzqdOAe+8IyMD3t5SWPnkSWMv/fLlxtnTgPx9+N//ZBJRcrL8A7h2bdbUI8oxK8zws1YrlV0Ntm417p85I4GZm5sU2SxdWgKlO3dkiO5//5Pjvr7yL50VK+QX9ZtvpCSCqyvw/fcyy0+rlX/dNGwoM++iokz8gfPGwIiIbFaVKjJr2eDtt+X/2zExEixNnpx9tvWVK9lnbAPyj9THH5f/l1esqIWHhxeUMk/7iWxaqVLG/XbtjPuTJxv3P/zQuH/smARATk4yPq7TSYXy3btlv3p16b2qX1/KH1y8aPrPkAsGRkRkNzQaoHVreQAyapCeLr1Dd+5IPb+vv5b8UK1W8lHPn5elTYQOQFtMnqxQoYKkVdSvL2kanTpl/ztARAWUddjPz8+4nzUJ/ZVXZGtI8LYABkb5FBERgYiICKQzUYHIpuh0xuG4Z56Rh8HduzJxZ98+ySXds0ePtWv1uHTJAZcuyTnbtgEzZsh+6dLSE1WlisyOa9xYRgH8/a2rPh0RFR4Do3wKDw9HeHg4bt++DS8vL0s3h4iKgIuLpE8YUihSU9OxfPkalCwZhqQkByQkAHv2yHDcoUNSZPjaNclJNRQ5BiSoqlFDgqSgIEmzCAqSVR20Vj7F5cAB+Qd7buumEhVHDIyIiLJwdNTj0UdVZqmZvn0l7eHWLZlJfPaszHTbulXSJM6ckVnLe/bIIys3N1mVoX59Y6J37dqS12QNAVNEhCz7NXCglJghIgZGRET54uUls9nq1ZMCla+/Ls8nJ0uy9/HjsoTVoUPyOHJE1ibdtUseWbm5SQ9TtWo5H2XLmidounxZlt4CgDlzpAxC7dqmf18ia8fAiIjoITg7S29QUFD259PTpXTAwYOS5H3kiDyOH5eAKSoq9xnJrq4yBGcIlKpUkWCpUiV5Dyenh2+zXi8Lx9+6JT8rJSVv5s3Lft7du9JWJp1TccLAiIjIBHQ6yTmqWTN7Pbu0NOlhOnFCtidPGh+nT8vsuehoedzLUHy4YUN5NGggs5oLkvaYmAgMGCBJ5wDw1VcyEejXX6WUgWGC0N27Usvv+HGZTX3v6hVE9oqBERGRGTk4GAOme6WmSh5T1mDp1CkgLk5KwNy8KcnSBw5kzwmqUkWud++wXOXKxmW5ALnWE09IT5Wjo9TWGzRIVpZYvlx6jX75Rc59+22ZrQcA770ny3AVdx99JIHrhAmchWjPGBgREVkJR0cZRqtaFejcOfsxpSTx2zAEt3+/bM+dk4DHsAZnVlqtFB328pIeoLNn5XkfH+kxeuQR+XnsWAmMfv1VgqBTp4yrMmg0MgNvzx6gSRN57s4dWUHC17fo74G1io4Gxo2T/bAwqW1F9omBERGRDdBoJM+oUqXs62teuyY5TCdOZO9pOnlS8oMuXUJmTSZDAcyff5brGDRqJNW///hDhv0Ma4CGh8uMu7lzZamrf/6R9T1fe02KEoeG6hAWZhzHu3VL1iCtU8fEN8MCsuZfffstAyN7xsCIiMiGlS4NtG0rj6yUkiG4ixdlEV2tVgKWkiVzv86kSbJElSG3KSREyhRcvixLXO3eLT1ZFy4YX7NunRY7drREp07Sg/TMM0BsrCzsPnWqrPZgD/T67IHR4sXy+YpTj1lxYgWVNIiIqKhpNFKRu1Ej6d145JG8gyJApur/+6/kIIWEyPCZs7PUXJo3T6534YIUxfzoI5lh17y5HgkJTmjc2AFt2khQBMj5DRvKYuzr10spgJ49geHDZVkWW/PPP9KL5uUlCe+pqTnrPh0/DnTvDkRGWqKFVJTYY0RERAAkkMotyTosDJg1C9ixA3jjDUnqBoDff09H48Z3EBdXAhqNzHYbNEgCoGPH5HX3+u47Cb7atZPg6uBByX+qWRPo0UOG9IqiJEFRiY+XIpgA8OSTQIsWwNChEhi9/roxCfvNN6Vn7fp1WUaGbBcDIyIieqCBA+WRla8v8Nlnm1GhQic0auQADw95fvduCSZWrpQaSE2bSi9UdDTwww/SG5V1SRXDa375BShXThb/1evl/IsXJVeqTBmgWTPgueeALl2yz7YzFb1elouJjpag8YMPAA8PKW9w5Aiwd68kpJ8+LflZgAxHHjuW+6xDsg0MjIiIqNA8PVPRsqXKFqh4eEiCd26GDZPZb0ePyjBd69ZS1HLbNgmMLlyQZO97JSbKrLpFi2RWXYcOQGCg5E/duCGPmzdlm5IiS7E0bWp8+PgU/LN99pn0Arm4yKy9wEB5vlcv+Qxz5khg9M03EkQZzJ4NTJxo/Dk2VnLByDYwMCIiIrNp1Ege9+rZU+oo/fGHrD+XlibJ4pUrS+B08SKwbJnkL12+DCxYcP/3OXtWeqwMKleWgpWtWsn7V6uWd0Xv5GQZOjQsmfLVV9JbZTBggARG8+cDY8ZILxgADB4sr5szR/KwUlOl52zWLKBDBx0GDTJGj3v2yPDbyy/L0CJZDwZGRERkFZyds1cJz6paNUkinzwZ2LBBilzGxgKenpJUXrIk4O0tW41G6jzt3i2Po0dluOv0aWMBS0DOL1dOkqq9vKRa+fXrUh8qKUnO6dsXeP757G3p2FHKHZw5IwHTrVuyUPA330gwdvGizFpbtEjeHwDWr9fiyJFHERoqJRDCwoCrVyVvq0EDmfFH1oGBERER2QwHB6BTJ3ncj6F4JSCBy86dMly3bZvkB128KENvN2/m/vrAQGDUKOnxubfKtU4nQVDXrlISAQCmTJEht3HjpP7TG2/I86VLA59+Cnz0kcK5c+7o00ePU6ckKNJoJAB7/nng778lSFq1yhg4PfYYK2xbAgMjIiKya15eOYOppCTjciu3bkmApNdLflT9+pI8rb1PQZuwMKnXNG+eTNPv0EGeHzYMiIgADh+WIG7JEunpCg5OQ8uWWmzZogMga8/NnAmEhgKbN8vPp08brz9jBtCmjQRVd+8Cf/4pid1NmwJvvSULC5NpMDAiIqJix81NErTr1i38Nb7/XmbQ9e5tfM7BQXKOBg2S9eYMFbKDg4Fhww7i228boFMnDebPl6G833+X4TpDUNS3rwwHzpwpAVOLFtnfMzJSgqZOnWQYMSZG6k8pBQQEyCy6Ll0kcLp4USqRx8fLDMLGjY0J5JQ3BkZERESF4OYGDBmS8/mWLaXg4706djyHDz6oizJljEnYXbrIYr1ffilDc126yPNvvSXr1s2ZI8NxXbtK4vjcuTIcmDWx3ODUKUlg//jjvNtct670Tjk5SU/UnTvy0GiA6tXlWK1aUvDTx0fyvhyKKFJISpJZg9euSdCXnCwB3IULgJ+f1IkqUaJo3uthMDAiIiIyEy+vnM9VrgxMn579ufLlpeTBN99I7pJORuDw4osyTLdihQQs5cvL0J+LC7BrlySX79sHXLkiieWBgdKzdOGCJJVHRxuXfbnXxo25P6/V5h4c3Zv/5OQkgY2bG+DuLvt6PZCeLr1WJ05kL2twr//9T8o3hITkTHg3JwZGREREViq3HpSgIHncq2LFvGf1AVLmYMcOGbZLT5cyCK6uElSlpkov15EjMovv+HF5DpBgJiXlwW1NTpYA6H50OgmcQkKkXEJsrAwB7tolw4IrV8pj6NAHv5+pMDAiIiIqBnx9ZcmV/EhPlyG25GQZcru3p0epnD+npMhwWWKi8aHVSjDk4iLBXF5J43q91HaKjJQyCPdb18/UGBgRERFRNjqdDIe5u5vn/bRaqQllKKRp6K2yhPtMRiQiIiIqXhgYEREREWVgYERERESUgYFRPkVERCAoKAhNmza1dFOIiIjIRBgY5VN4eDgOHz6M3YYVAYmIiMjuMDAiIiIiysDAiIiIiCgDAyMiIiKiDAyMiIiIiDIwMCIiIiLKwMCIiIiIKAMDIyIiIqIMDIyIiIiIMjhYugG2RikFALh9+3aRXjc1NRVJSUm4ffs2HB0di/Ta9ob3qmB4v/KP96pgeL/yj/eqYExxvwx/tw1/x/PCwKiA4uPjAQDly5e3cEuIiIiooOLj4+Hl5ZXncY16UOhE2ej1ely8eBEeHh7QaDRFdt3bt2+jfPnyOH/+PDw9PYvsuvaI96pgeL/yj/eqYHi/8o/3qmBMcb+UUoiPj0dAQAC02rwzidhjVEBarRaBgYEmu76npyd/afKJ96pgeL/yj/eqYHi/8o/3qmCK+n7dr6fIgMnXRERERBkYGBERERFlYGBkJZydnTFu3Dg4OztbuilWj/eqYHi/8o/3qmB4v/KP96pgLHm/mHxNRERElIE9RkREREQZGBgRERERZWBgRERERJSBgRERERFRBgZGViIiIgKVKlWCi4sLmjdvjl27dlm6SRb3wQcfQKPRZHvUqlUr8/jdu3cRHh6O0qVLw93dHU888QTi4uIs2GLz2bJlC7p3746AgABoNBosW7Ys23GlFMaOHYuyZcvC1dUVoaGhOHHiRLZzrl+/jv79+8PT0xPe3t54/vnnkZCQYMZPYT4Pul+DBg3K8V3r0qVLtnOKy/2aOHEimjZtCg8PD/j6+qJnz544duxYtnPy87t37tw5dOvWDW5ubvD19cXrr7+OtLQ0c34Uk8vPvWrbtm2O79bw4cOznVMc7tWMGTNQv379zIKNISEhWL16deZxa/pOMTCyAgsXLsTo0aMxbtw47Nu3D8HBwejcuTMuX75s6aZZXJ06dRAbG5v52Lp1a+axUaNG4c8//8SiRYuwefNmXLx4Eb1797Zga80nMTERwcHBiIiIyPX45MmTMX36dHz77bfYuXMnSpQogc6dO+Pu3buZ5/Tv3x+HDh3C2rVrsWLFCmzZsgXDhg0z10cwqwfdLwDo0qVLtu/ar7/+mu14cblfmzdvRnh4OHbs2IG1a9ciNTUVnTp1QmJiYuY5D/rdS09PR7du3ZCSkoLt27fj559/xuzZszF27FhLfCSTyc+9AoChQ4dm+25Nnjw581hxuVeBgYGYNGkS9u7diz179qB9+/bo0aMHDh06BMDKvlOKLK5Zs2YqPDw88+f09HQVEBCgJk6caMFWWd64ceNUcHBwrsdu3rypHB0d1aJFizKfO3LkiAKgIiMjzdRC6wBALV26NPNnvV6v/P391WeffZb53M2bN5Wzs7P69ddflVJKHT58WAFQu3fvzjxn9erVSqPRqAsXLpit7ZZw7/1SSqmBAweqHj165Pma4ny/Ll++rACozZs3K6Xy97u3atUqpdVq1aVLlzLPmTFjhvL09FTJycnm/QBmdO+9UkqpNm3aqJEjR+b5muJ6r5RSqmTJkurHH3+0uu8Ue4wsLCUlBXv37kVoaGjmc1qtFqGhoYiMjLRgy6zDiRMnEBAQgCpVqqB///44d+4cAGDv3r1ITU3Ndt9q1aqFChUqFPv7dvr0aVy6dCnbvfHy8kLz5s0z701kZCS8vb3RpEmTzHNCQ0Oh1Wqxc+dOs7fZGmzatAm+vr6oWbMmXnrpJVy7di3zWHG+X7du3QIAlCpVCkD+fvciIyNRr149+Pn5ZZ7TuXNn3L59O7OHwB7de68M5s2bhzJlyqBu3bp4++23kZSUlHmsON6r9PR0LFiwAImJiQgJCbG67xQXkbWwq1evIj09Pdt/bADw8/PD0aNHLdQq69C8eXPMnj0bNWvWRGxsLD788EO0bt0a0dHRuHTpEpycnODt7Z3tNX5+frh06ZJlGmwlDJ8/t++U4dilS5fg6+ub7biDgwNKlSpVLO9fly5d0Lt3b1SuXBkxMTF45513EBYWhsjISOh0umJ7v/R6PV599VW0atUKdevWBYB8/e5dunQp1++f4Zg9yu1eAUC/fv1QsWJFBAQE4ODBg3jzzTdx7NgxLFmyBEDxulf//vsvQkJCcPfuXbi7u2Pp0qUICgpCVFSUVX2nGBiR1QoLC8vcr1+/Ppo3b46KFSvit99+g6urqwVbRvbmmWeeydyvV68e6tevj6pVq2LTpk3o0KGDBVtmWeHh4YiOjs6W20e5y+teZc1Dq1evHsqWLYsOHTogJiYGVatWNXczLapmzZqIiorCrVu3sHjxYgwcOBCbN2+2dLNy4FCahZUpUwY6nS5H9n1cXBz8/f0t1Crr5O3tjRo1auDkyZPw9/dHSkoKbt68me0c3jdkfv77faf8/f1zJPenpaXh+vXrxf7+AUCVKlVQpkwZnDx5EkDxvF8jRozAihUrsHHjRgQGBmY+n5/fPX9//1y/f4Zj9iave5Wb5s2bA0C271ZxuVdOTk6oVq0aGjdujIkTJyI4OBjTpk2zuu8UAyMLc3JyQuPGjbF+/frM5/R6PdavX4+QkBALtsz6JCQkICYmBmXLlkXjxo3h6OiY7b4dO3YM586dK/b3rXLlyvD39892b27fvo2dO3dm3puQkBDcvHkTe/fuzTxnw4YN0Ov1mf/jLs7+++8/XLt2DWXLlgVQvO6XUgojRozA0qVLsWHDBlSuXDnb8fz87oWEhODff//NFkyuXbsWnp6eCAoKMs8HMYMH3avcREVFAUC271ZxuFe50ev1SE5Otr7vVJGmclOhLFiwQDk7O6vZs2erw4cPq2HDhilvb+9s2ffF0WuvvaY2bdqkTp8+rbZt26ZCQ0NVmTJl1OXLl5VSSg0fPlxVqFBBbdiwQe3Zs0eFhISokJAQC7faPOLj49X+/fvV/v37FQA1ZcoUtX//fnX27FmllFKTJk1S3t7eavny5ergwYOqR48eqnLlyurOnTuZ1+jSpYtq2LCh2rlzp9q6dauqXr266tu3r6U+kknd737Fx8erMWPGqMjISHX69Gm1bt061ahRI1W9enV19+7dzGsUl/v10ksvKS8vL7Vp0yYVGxub+UhKSso850G/e2lpaapu3bqqU6dOKioqSq1Zs0b5+Piot99+2xIfyWQedK9OnjypPvroI7Vnzx51+vRptXz5clWlShX16KOPZl6juNyrt956S23evFmdPn1aHTx4UL311ltKo9Gov//+WyllXd8pBkZW4quvvlIVKlRQTk5OqlmzZmrHjh2WbpLF9enTR5UtW1Y5OTmpcuXKqT59+qiTJ09mHr9z5456+eWXVcmSJZWbm5vq1auXio2NtWCLzWfjxo0KQI7HwIEDlVIyZf/9999Xfn5+ytnZWXXo0EEdO3Ys2zWuXbum+vbtq9zd3ZWnp6caPHiwio+Pt8CnMb373a+kpCTVqVMn5ePjoxwdHVXFihXV0KFDc/zDpLjcr9zuEwA1a9aszHPy87t35swZFRYWplxdXVWZMmXUa6+9plJTU838aUzrQffq3Llz6tFHH1WlSpVSzs7Oqlq1aur1119Xt27dynad4nCvhgwZoipWrKicnJyUj4+P6tChQ2ZQpJR1fac0SilVtH1QRERERLaJOUZEREREGRgYEREREWVgYERERESUgYERERERUQYGRkREREQZGBgRERERZWBgRERERJSBgRERERFRBgZGRERERBkYGBERERFlYGBERERElIGBEREREVGG/wPwA9Z6rCeVgwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_train,color='blue')\n",
    "plt.plot(loss_history_test,color='red')\n",
    "plt.legend(['train','test'])\n",
    "#log \n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
