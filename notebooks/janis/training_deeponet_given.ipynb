{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d6faae",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sciml.model.deeponet import DeepONet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sciml.data.preprocessing.process_given_dataset import get_mu_xs_sol\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ddf854",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "d_p = 40\n",
    "d_V = 40\n",
    "epochs = 300    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c0fd49",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "internal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(shape=(100,)),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "])\n",
    "\n",
    "\n",
    "external_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(shape=(1,)),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9a396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/janis/SCIML/summerschool/data/benchmarks/given/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "261ac835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 18:00:29,891 - sciml.model.deeponet.deeponet - INFO - Model initialized with 300 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(regular_params={\"internal_model\": internal_model, \"external_model\": external_model}, hyper_params={\"d_p\": d_p, \"d_V\": d_V,\"device\": \"GPU\",\"n_epochs\":epochs},folder_path=\"../../data/benchmarks/given/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d8385d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mus.shape (2000, 100)\n",
      "xs.shape (2000, 100, 1)\n",
      "sol.shape (2000, 100)\n"
     ]
    }
   ],
   "source": [
    "mus, xs, sol = get_mu_xs_sol(folder_path,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b511c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 100)\n",
      "(2000, 100, 1)\n",
      "(2000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(mus.shape)\n",
    "print(xs.shape)\n",
    "print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b84bff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mus.shape (2000, 100)\n",
      "xs.shape (2000, 100, 1)\n",
      "sol.shape (2000, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/300 [00:00<?, ?it/s]2025-08-04 18:00:32,716 - sciml.model.deeponet.deeponet - INFO - Epoch 1/300\n",
      "2025-08-04 18:00:32,717 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074977\n",
      "2025-08-04 18:00:32,717 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.064495\n",
      "Training progress:   0%|          | 1/300 [00:02<10:30,  2.11s/it]2025-08-04 18:00:34,716 - sciml.model.deeponet.deeponet - INFO - Epoch 2/300\n",
      "2025-08-04 18:00:34,717 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.064162\n",
      "2025-08-04 18:00:34,718 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.061827\n",
      "Training progress:   1%|          | 2/300 [00:04<10:09,  2.04s/it]2025-08-04 18:00:36,721 - sciml.model.deeponet.deeponet - INFO - Epoch 3/300\n",
      "2025-08-04 18:00:36,722 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.058865\n",
      "2025-08-04 18:00:36,723 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.056827\n",
      "Training progress:   1%|          | 3/300 [00:06<10:01,  2.03s/it]2025-08-04 18:00:38,680 - sciml.model.deeponet.deeponet - INFO - Epoch 4/300\n",
      "2025-08-04 18:00:38,680 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.054904\n",
      "2025-08-04 18:00:38,681 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.054541\n",
      "Training progress:   1%|▏         | 4/300 [00:08<09:51,  2.00s/it]2025-08-04 18:00:40,659 - sciml.model.deeponet.deeponet - INFO - Epoch 5/300\n",
      "2025-08-04 18:00:40,660 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.053049\n",
      "2025-08-04 18:00:40,660 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.052871\n",
      "Training progress:   2%|▏         | 5/300 [00:10<09:47,  1.99s/it]2025-08-04 18:00:42,741 - sciml.model.deeponet.deeponet - INFO - Epoch 6/300\n",
      "2025-08-04 18:00:42,742 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.051904\n",
      "2025-08-04 18:00:42,743 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.052022\n",
      "Training progress:   2%|▏         | 6/300 [00:12<09:54,  2.02s/it]2025-08-04 18:00:44,852 - sciml.model.deeponet.deeponet - INFO - Epoch 7/300\n",
      "2025-08-04 18:00:44,853 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.051170\n",
      "2025-08-04 18:00:44,854 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.051687\n",
      "Training progress:   2%|▏         | 7/300 [00:14<10:01,  2.05s/it]2025-08-04 18:00:46,880 - sciml.model.deeponet.deeponet - INFO - Epoch 8/300\n",
      "2025-08-04 18:00:46,881 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.050743\n",
      "2025-08-04 18:00:46,882 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.051144\n",
      "Training progress:   3%|▎         | 8/300 [00:16<09:56,  2.04s/it]2025-08-04 18:00:48.853236: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-08-04 18:00:48,854 - sciml.model.deeponet.deeponet - INFO - Epoch 9/300\n",
      "2025-08-04 18:00:48,855 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.050433\n",
      "2025-08-04 18:00:48,856 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.051019\n",
      "Training progress:   3%|▎         | 9/300 [00:18<09:48,  2.02s/it]2025-08-04 18:00:50,824 - sciml.model.deeponet.deeponet - INFO - Epoch 10/300\n",
      "2025-08-04 18:00:50,825 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.050351\n",
      "2025-08-04 18:00:50,825 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050850\n",
      "Training progress:   3%|▎         | 10/300 [00:20<09:41,  2.01s/it]2025-08-04 18:00:52,794 - sciml.model.deeponet.deeponet - INFO - Epoch 11/300\n",
      "2025-08-04 18:00:52,795 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.050074\n",
      "2025-08-04 18:00:52,795 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050760\n",
      "Training progress:   4%|▎         | 11/300 [00:22<09:36,  2.00s/it]2025-08-04 18:00:54,795 - sciml.model.deeponet.deeponet - INFO - Epoch 12/300\n",
      "2025-08-04 18:00:54,795 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049894\n",
      "2025-08-04 18:00:54,796 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050562\n",
      "Training progress:   4%|▍         | 12/300 [00:24<09:35,  2.00s/it]2025-08-04 18:00:56,784 - sciml.model.deeponet.deeponet - INFO - Epoch 13/300\n",
      "2025-08-04 18:00:56,785 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049722\n",
      "2025-08-04 18:00:56,785 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050323\n",
      "Training progress:   4%|▍         | 13/300 [00:26<09:32,  1.99s/it]2025-08-04 18:00:58,738 - sciml.model.deeponet.deeponet - INFO - Epoch 14/300\n",
      "2025-08-04 18:00:58,739 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049602\n",
      "2025-08-04 18:00:58,740 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050224\n",
      "Training progress:   5%|▍         | 14/300 [00:28<09:26,  1.98s/it]2025-08-04 18:01:00,780 - sciml.model.deeponet.deeponet - INFO - Epoch 15/300\n",
      "2025-08-04 18:01:00,781 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049973\n",
      "2025-08-04 18:01:00,782 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050098\n",
      "Training progress:   5%|▌         | 15/300 [00:30<09:30,  2.00s/it]2025-08-04 18:01:02,804 - sciml.model.deeponet.deeponet - INFO - Epoch 16/300\n",
      "2025-08-04 18:01:02,805 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049501\n",
      "2025-08-04 18:01:02,805 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049970\n",
      "Training progress:   5%|▌         | 16/300 [00:32<09:30,  2.01s/it]2025-08-04 18:01:04,788 - sciml.model.deeponet.deeponet - INFO - Epoch 17/300\n",
      "2025-08-04 18:01:04,789 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049374\n",
      "2025-08-04 18:01:04,790 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050048\n",
      "Training progress:   6%|▌         | 17/300 [00:34<09:26,  2.00s/it]2025-08-04 18:01:06,749 - sciml.model.deeponet.deeponet - INFO - Epoch 18/300\n",
      "2025-08-04 18:01:06,749 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049353\n",
      "2025-08-04 18:01:06,750 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049962\n",
      "Training progress:   6%|▌         | 18/300 [00:36<09:20,  1.99s/it]2025-08-04 18:01:08,715 - sciml.model.deeponet.deeponet - INFO - Epoch 19/300\n",
      "2025-08-04 18:01:08,716 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049741\n",
      "2025-08-04 18:01:08,717 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049957\n",
      "Training progress:   6%|▋         | 19/300 [00:38<09:16,  1.98s/it]2025-08-04 18:01:10,814 - sciml.model.deeponet.deeponet - INFO - Epoch 20/300\n",
      "2025-08-04 18:01:10,814 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049382\n",
      "2025-08-04 18:01:10,815 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049872\n",
      "Training progress:   7%|▋         | 20/300 [00:40<09:24,  2.02s/it]2025-08-04 18:01:12,829 - sciml.model.deeponet.deeponet - INFO - Epoch 21/300\n",
      "2025-08-04 18:01:12,830 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049254\n",
      "2025-08-04 18:01:12,831 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049833\n",
      "Training progress:   7%|▋         | 21/300 [00:42<09:22,  2.02s/it]2025-08-04 18:01:14,791 - sciml.model.deeponet.deeponet - INFO - Epoch 22/300\n",
      "2025-08-04 18:01:14,793 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049213\n",
      "2025-08-04 18:01:14,793 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049818\n",
      "Training progress:   7%|▋         | 22/300 [00:44<09:16,  2.00s/it]2025-08-04 18:01:16,869 - sciml.model.deeponet.deeponet - INFO - Epoch 23/300\n",
      "2025-08-04 18:01:16,870 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049194\n",
      "2025-08-04 18:01:16,870 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049770\n",
      "Training progress:   8%|▊         | 23/300 [00:46<09:20,  2.02s/it]2025-08-04 18:01:18,883 - sciml.model.deeponet.deeponet - INFO - Epoch 24/300\n",
      "2025-08-04 18:01:18,884 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049512\n",
      "2025-08-04 18:01:18,884 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049871\n",
      "Training progress:   8%|▊         | 24/300 [00:48<09:17,  2.02s/it]2025-08-04 18:01:20,906 - sciml.model.deeponet.deeponet - INFO - Epoch 25/300\n",
      "2025-08-04 18:01:20,907 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049342\n",
      "2025-08-04 18:01:20,907 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049728\n",
      "Training progress:   8%|▊         | 25/300 [00:50<09:15,  2.02s/it]2025-08-04 18:01:22,911 - sciml.model.deeponet.deeponet - INFO - Epoch 26/300\n",
      "2025-08-04 18:01:22,912 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049177\n",
      "2025-08-04 18:01:22,912 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049726\n",
      "Training progress:   9%|▊         | 26/300 [00:52<09:12,  2.02s/it]2025-08-04 18:01:24,903 - sciml.model.deeponet.deeponet - INFO - Epoch 27/300\n",
      "2025-08-04 18:01:24,904 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049130\n",
      "2025-08-04 18:01:24,905 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049696\n",
      "Training progress:   9%|▉         | 27/300 [00:54<09:08,  2.01s/it]2025-08-04 18:01:26,931 - sciml.model.deeponet.deeponet - INFO - Epoch 28/300\n",
      "2025-08-04 18:01:26,932 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049125\n",
      "2025-08-04 18:01:26,932 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049710\n",
      "Training progress:   9%|▉         | 28/300 [00:56<09:07,  2.01s/it]2025-08-04 18:01:28,884 - sciml.model.deeponet.deeponet - INFO - Epoch 29/300\n",
      "2025-08-04 18:01:28,885 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049114\n",
      "2025-08-04 18:01:28,886 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049658\n",
      "Training progress:  10%|▉         | 29/300 [00:58<09:00,  2.00s/it]2025-08-04 18:01:30,850 - sciml.model.deeponet.deeponet - INFO - Epoch 30/300\n",
      "2025-08-04 18:01:30,851 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049165\n",
      "2025-08-04 18:01:30,852 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049705\n",
      "Training progress:  10%|█         | 30/300 [01:00<08:56,  1.99s/it]2025-08-04 18:01:32,809 - sciml.model.deeponet.deeponet - INFO - Epoch 31/300\n",
      "2025-08-04 18:01:32,810 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049204\n",
      "2025-08-04 18:01:32,811 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049647\n",
      "Training progress:  10%|█         | 31/300 [01:02<08:52,  1.98s/it]2025-08-04 18:01:34,768 - sciml.model.deeponet.deeponet - INFO - Epoch 32/300\n",
      "2025-08-04 18:01:34,769 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049079\n",
      "2025-08-04 18:01:34,770 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049630\n",
      "Training progress:  11%|█         | 32/300 [01:04<08:48,  1.97s/it]2025-08-04 18:01:36,751 - sciml.model.deeponet.deeponet - INFO - Epoch 33/300\n",
      "2025-08-04 18:01:36,752 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049084\n",
      "2025-08-04 18:01:36,753 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049612\n",
      "Training progress:  11%|█         | 33/300 [01:06<08:47,  1.98s/it]2025-08-04 18:01:38,695 - sciml.model.deeponet.deeponet - INFO - Epoch 34/300\n",
      "2025-08-04 18:01:38,696 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049177\n",
      "2025-08-04 18:01:38,696 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049652\n",
      "Training progress:  11%|█▏        | 34/300 [01:08<08:43,  1.97s/it]2025-08-04 18:01:40,653 - sciml.model.deeponet.deeponet - INFO - Epoch 35/300\n",
      "2025-08-04 18:01:40,654 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049084\n",
      "2025-08-04 18:01:40,655 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049632\n",
      "Training progress:  12%|█▏        | 35/300 [01:10<08:40,  1.96s/it]2025-08-04 18:01:42,644 - sciml.model.deeponet.deeponet - INFO - Epoch 36/300\n",
      "2025-08-04 18:01:42,645 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049045\n",
      "2025-08-04 18:01:42,645 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049586\n",
      "Training progress:  12%|█▏        | 36/300 [01:12<08:40,  1.97s/it]2025-08-04 18:01:44,595 - sciml.model.deeponet.deeponet - INFO - Epoch 37/300\n",
      "2025-08-04 18:01:44,595 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049024\n",
      "2025-08-04 18:01:44,596 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049583\n",
      "Training progress:  12%|█▏        | 37/300 [01:13<08:36,  1.97s/it]2025-08-04 18:01:46,559 - sciml.model.deeponet.deeponet - INFO - Epoch 38/300\n",
      "2025-08-04 18:01:46,559 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049017\n",
      "2025-08-04 18:01:46,560 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049570\n",
      "Training progress:  13%|█▎        | 38/300 [01:15<08:34,  1.96s/it]2025-08-04 18:01:48,593 - sciml.model.deeponet.deeponet - INFO - Epoch 39/300\n",
      "2025-08-04 18:01:48,594 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049048\n",
      "2025-08-04 18:01:48,595 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049726\n",
      "Training progress:  13%|█▎        | 39/300 [01:17<08:38,  1.99s/it]2025-08-04 18:01:50,632 - sciml.model.deeponet.deeponet - INFO - Epoch 40/300\n",
      "2025-08-04 18:01:50,632 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049199\n",
      "2025-08-04 18:01:50,633 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049926\n",
      "Training progress:  13%|█▎        | 40/300 [01:20<08:40,  2.00s/it]2025-08-04 18:01:52,636 - sciml.model.deeponet.deeponet - INFO - Epoch 41/300\n",
      "2025-08-04 18:01:52,637 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049300\n",
      "2025-08-04 18:01:52,637 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049657\n",
      "Training progress:  14%|█▎        | 41/300 [01:22<08:38,  2.00s/it]2025-08-04 18:01:54,631 - sciml.model.deeponet.deeponet - INFO - Epoch 42/300\n",
      "2025-08-04 18:01:54,631 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049031\n",
      "2025-08-04 18:01:54,632 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049557\n",
      "Training progress:  14%|█▍        | 42/300 [01:24<08:36,  2.00s/it]2025-08-04 18:01:56,621 - sciml.model.deeponet.deeponet - INFO - Epoch 43/300\n",
      "2025-08-04 18:01:56,622 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048995\n",
      "2025-08-04 18:01:56,622 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049537\n",
      "Training progress:  14%|█▍        | 43/300 [01:26<08:33,  2.00s/it]2025-08-04 18:01:58,604 - sciml.model.deeponet.deeponet - INFO - Epoch 44/300\n",
      "2025-08-04 18:01:58,605 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048983\n",
      "2025-08-04 18:01:58,606 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049536\n",
      "Training progress:  15%|█▍        | 44/300 [01:27<08:30,  1.99s/it]2025-08-04 18:02:00,641 - sciml.model.deeponet.deeponet - INFO - Epoch 45/300\n",
      "2025-08-04 18:02:00,642 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049055\n",
      "2025-08-04 18:02:00,643 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049544\n",
      "Training progress:  15%|█▌        | 45/300 [01:30<08:31,  2.01s/it]2025-08-04 18:02:02,719 - sciml.model.deeponet.deeponet - INFO - Epoch 46/300\n",
      "2025-08-04 18:02:02,720 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049014\n",
      "2025-08-04 18:02:02,720 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049535\n",
      "Training progress:  15%|█▌        | 46/300 [01:32<08:35,  2.03s/it]2025-08-04 18:02:04,728 - sciml.model.deeponet.deeponet - INFO - Epoch 47/300\n",
      "2025-08-04 18:02:04,729 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049176\n",
      "2025-08-04 18:02:04,730 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049643\n",
      "Training progress:  16%|█▌        | 47/300 [01:34<08:31,  2.02s/it]2025-08-04 18:02:06,711 - sciml.model.deeponet.deeponet - INFO - Epoch 48/300\n",
      "2025-08-04 18:02:06,712 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049055\n",
      "2025-08-04 18:02:06,712 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049566\n",
      "Training progress:  16%|█▌        | 48/300 [01:36<08:26,  2.01s/it]2025-08-04 18:02:08,681 - sciml.model.deeponet.deeponet - INFO - Epoch 49/300\n",
      "2025-08-04 18:02:08,682 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048979\n",
      "2025-08-04 18:02:08,683 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049528\n",
      "Training progress:  16%|█▋        | 49/300 [01:38<08:21,  2.00s/it]2025-08-04 18:02:10,668 - sciml.model.deeponet.deeponet - INFO - Epoch 50/300\n",
      "2025-08-04 18:02:10,669 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048964\n",
      "2025-08-04 18:02:10,670 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049514\n",
      "Training progress:  17%|█▋        | 50/300 [01:40<08:18,  2.00s/it]2025-08-04 18:02:12,771 - sciml.model.deeponet.deeponet - INFO - Epoch 51/300\n",
      "2025-08-04 18:02:12,772 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049000\n",
      "2025-08-04 18:02:12,773 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049619\n",
      "Training progress:  17%|█▋        | 51/300 [01:42<08:24,  2.03s/it]2025-08-04 18:02:14,771 - sciml.model.deeponet.deeponet - INFO - Epoch 52/300\n",
      "2025-08-04 18:02:14,772 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049144\n",
      "2025-08-04 18:02:14,773 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049624\n",
      "Training progress:  17%|█▋        | 52/300 [01:44<08:20,  2.02s/it]2025-08-04 18:02:16,800 - sciml.model.deeponet.deeponet - INFO - Epoch 53/300\n",
      "2025-08-04 18:02:16,801 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049290\n",
      "2025-08-04 18:02:16,801 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049564\n",
      "Training progress:  18%|█▊        | 53/300 [01:46<08:19,  2.02s/it]2025-08-04 18:02:18,767 - sciml.model.deeponet.deeponet - INFO - Epoch 54/300\n",
      "2025-08-04 18:02:18,768 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049022\n",
      "2025-08-04 18:02:18,769 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049558\n",
      "Training progress:  18%|█▊        | 54/300 [01:48<08:13,  2.01s/it]2025-08-04 18:02:20,869 - sciml.model.deeponet.deeponet - INFO - Epoch 55/300\n",
      "2025-08-04 18:02:20,870 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048973\n",
      "2025-08-04 18:02:20,871 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049499\n",
      "Training progress:  18%|█▊        | 55/300 [01:50<08:18,  2.03s/it]2025-08-04 18:02:22,911 - sciml.model.deeponet.deeponet - INFO - Epoch 56/300\n",
      "2025-08-04 18:02:22,911 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048939\n",
      "2025-08-04 18:02:22,912 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049488\n",
      "Training progress:  19%|█▊        | 56/300 [01:52<08:16,  2.04s/it]2025-08-04 18:02:24,955 - sciml.model.deeponet.deeponet - INFO - Epoch 57/300\n",
      "2025-08-04 18:02:24,955 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048935\n",
      "2025-08-04 18:02:24,956 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049484\n",
      "Training progress:  19%|█▉        | 57/300 [01:54<08:15,  2.04s/it]2025-08-04 18:02:27,103 - sciml.model.deeponet.deeponet - INFO - Epoch 58/300\n",
      "2025-08-04 18:02:27,104 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048940\n",
      "2025-08-04 18:02:27,105 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049478\n",
      "Training progress:  19%|█▉        | 58/300 [01:56<08:21,  2.07s/it]2025-08-04 18:02:29,095 - sciml.model.deeponet.deeponet - INFO - Epoch 59/300\n",
      "2025-08-04 18:02:29,096 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048953\n",
      "2025-08-04 18:02:29,096 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049595\n",
      "Training progress:  20%|█▉        | 59/300 [01:58<08:13,  2.05s/it]2025-08-04 18:02:31,169 - sciml.model.deeponet.deeponet - INFO - Epoch 60/300\n",
      "2025-08-04 18:02:31,169 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049248\n",
      "2025-08-04 18:02:31,170 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049613\n",
      "Training progress:  20%|██        | 60/300 [02:00<08:13,  2.06s/it]2025-08-04 18:02:33,146 - sciml.model.deeponet.deeponet - INFO - Epoch 61/300\n",
      "2025-08-04 18:02:33,146 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048980\n",
      "2025-08-04 18:02:33,147 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049520\n",
      "Training progress:  20%|██        | 61/300 [02:02<08:05,  2.03s/it]2025-08-04 18:02:35,117 - sciml.model.deeponet.deeponet - INFO - Epoch 62/300\n",
      "2025-08-04 18:02:35,118 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048922\n",
      "2025-08-04 18:02:35,119 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049470\n",
      "Training progress:  21%|██        | 62/300 [02:04<07:59,  2.01s/it]2025-08-04 18:02:37,108 - sciml.model.deeponet.deeponet - INFO - Epoch 63/300\n",
      "2025-08-04 18:02:37,109 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048914\n",
      "2025-08-04 18:02:37,110 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049465\n",
      "Training progress:  21%|██        | 63/300 [02:06<07:55,  2.01s/it]2025-08-04 18:02:39,055 - sciml.model.deeponet.deeponet - INFO - Epoch 64/300\n",
      "2025-08-04 18:02:39,056 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048935\n",
      "2025-08-04 18:02:39,057 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049483\n",
      "Training progress:  21%|██▏       | 64/300 [02:08<07:49,  1.99s/it]2025-08-04 18:02:41,015 - sciml.model.deeponet.deeponet - INFO - Epoch 65/300\n",
      "2025-08-04 18:02:41,015 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048904\n",
      "2025-08-04 18:02:41,016 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049463\n",
      "Training progress:  22%|██▏       | 65/300 [02:10<07:45,  1.98s/it]2025-08-04 18:02:43,030 - sciml.model.deeponet.deeponet - INFO - Epoch 66/300\n",
      "2025-08-04 18:02:43,031 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048912\n",
      "2025-08-04 18:02:43,031 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049539\n",
      "Training progress:  22%|██▏       | 66/300 [02:12<07:45,  1.99s/it]2025-08-04 18:02:45,007 - sciml.model.deeponet.deeponet - INFO - Epoch 67/300\n",
      "2025-08-04 18:02:45,007 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048990\n",
      "2025-08-04 18:02:45,008 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049479\n",
      "Training progress:  22%|██▏       | 67/300 [02:14<07:42,  1.99s/it]2025-08-04 18:02:46,995 - sciml.model.deeponet.deeponet - INFO - Epoch 68/300\n",
      "2025-08-04 18:02:46,995 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048992\n",
      "2025-08-04 18:02:46,996 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049476\n",
      "Training progress:  23%|██▎       | 68/300 [02:16<07:40,  1.99s/it]2025-08-04 18:02:48,945 - sciml.model.deeponet.deeponet - INFO - Epoch 69/300\n",
      "2025-08-04 18:02:48,946 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049011\n",
      "2025-08-04 18:02:48,947 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049475\n",
      "Training progress:  23%|██▎       | 69/300 [02:18<07:36,  1.98s/it]2025-08-04 18:02:50,914 - sciml.model.deeponet.deeponet - INFO - Epoch 70/300\n",
      "2025-08-04 18:02:50,915 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048922\n",
      "2025-08-04 18:02:50,916 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049441\n",
      "Training progress:  23%|██▎       | 70/300 [02:20<07:34,  1.97s/it]2025-08-04 18:02:52,966 - sciml.model.deeponet.deeponet - INFO - Epoch 71/300\n",
      "2025-08-04 18:02:52,967 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048931\n",
      "2025-08-04 18:02:52,967 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049485\n",
      "Training progress:  24%|██▎       | 71/300 [02:22<07:37,  2.00s/it]2025-08-04 18:02:54,994 - sciml.model.deeponet.deeponet - INFO - Epoch 72/300\n",
      "2025-08-04 18:02:54,994 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048998\n",
      "2025-08-04 18:02:54,995 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049434\n",
      "Training progress:  24%|██▍       | 72/300 [02:24<07:37,  2.01s/it]2025-08-04 18:02:57.022465: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-08-04 18:02:57,024 - sciml.model.deeponet.deeponet - INFO - Epoch 73/300\n",
      "2025-08-04 18:02:57,025 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048878\n",
      "2025-08-04 18:02:57,025 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049444\n",
      "Training progress:  24%|██▍       | 73/300 [02:26<07:37,  2.01s/it]2025-08-04 18:02:59,029 - sciml.model.deeponet.deeponet - INFO - Epoch 74/300\n",
      "2025-08-04 18:02:59,030 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048946\n",
      "2025-08-04 18:02:59,030 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049436\n",
      "Training progress:  25%|██▍       | 74/300 [02:28<07:34,  2.01s/it]2025-08-04 18:03:01,082 - sciml.model.deeponet.deeponet - INFO - Epoch 75/300\n",
      "2025-08-04 18:03:01,083 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048963\n",
      "2025-08-04 18:03:01,083 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049534\n",
      "Training progress:  25%|██▌       | 75/300 [02:30<07:35,  2.02s/it]2025-08-04 18:03:03,057 - sciml.model.deeponet.deeponet - INFO - Epoch 76/300\n",
      "2025-08-04 18:03:03,058 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048878\n",
      "2025-08-04 18:03:03,059 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049425\n",
      "Training progress:  25%|██▌       | 76/300 [02:32<07:30,  2.01s/it]2025-08-04 18:03:05,076 - sciml.model.deeponet.deeponet - INFO - Epoch 77/300\n",
      "2025-08-04 18:03:05,077 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048872\n",
      "2025-08-04 18:03:05,077 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049431\n",
      "Training progress:  26%|██▌       | 77/300 [02:34<07:28,  2.01s/it]2025-08-04 18:03:07,056 - sciml.model.deeponet.deeponet - INFO - Epoch 78/300\n",
      "2025-08-04 18:03:07,057 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048881\n",
      "2025-08-04 18:03:07,058 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049422\n",
      "Training progress:  26%|██▌       | 78/300 [02:36<07:24,  2.00s/it]2025-08-04 18:03:09,010 - sciml.model.deeponet.deeponet - INFO - Epoch 79/300\n",
      "2025-08-04 18:03:09,011 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049050\n",
      "2025-08-04 18:03:09,011 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049425\n",
      "Training progress:  26%|██▋       | 79/300 [02:38<07:19,  1.99s/it]2025-08-04 18:03:10,975 - sciml.model.deeponet.deeponet - INFO - Epoch 80/300\n",
      "2025-08-04 18:03:10,976 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048874\n",
      "2025-08-04 18:03:10,977 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049467\n",
      "Training progress:  27%|██▋       | 80/300 [02:40<07:15,  1.98s/it]2025-08-04 18:03:12,965 - sciml.model.deeponet.deeponet - INFO - Epoch 81/300\n",
      "2025-08-04 18:03:12,966 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048863\n",
      "2025-08-04 18:03:12,966 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049416\n",
      "Training progress:  27%|██▋       | 81/300 [02:42<07:14,  1.98s/it]2025-08-04 18:03:14,943 - sciml.model.deeponet.deeponet - INFO - Epoch 82/300\n",
      "2025-08-04 18:03:14,944 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048939\n",
      "2025-08-04 18:03:14,945 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049425\n",
      "Training progress:  27%|██▋       | 82/300 [02:44<07:12,  1.98s/it]2025-08-04 18:03:16,961 - sciml.model.deeponet.deeponet - INFO - Epoch 83/300\n",
      "2025-08-04 18:03:16,962 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048898\n",
      "2025-08-04 18:03:16,962 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049512\n",
      "Training progress:  28%|██▊       | 83/300 [02:46<07:12,  1.99s/it]2025-08-04 18:03:18,938 - sciml.model.deeponet.deeponet - INFO - Epoch 84/300\n",
      "2025-08-04 18:03:18,939 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048853\n",
      "2025-08-04 18:03:18,939 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049404\n",
      "Training progress:  28%|██▊       | 84/300 [02:48<07:09,  1.99s/it]2025-08-04 18:03:20,942 - sciml.model.deeponet.deeponet - INFO - Epoch 85/300\n",
      "2025-08-04 18:03:20,943 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048832\n",
      "2025-08-04 18:03:20,943 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049396\n",
      "Training progress:  28%|██▊       | 85/300 [02:50<07:08,  1.99s/it]2025-08-04 18:03:22,927 - sciml.model.deeponet.deeponet - INFO - Epoch 86/300\n",
      "2025-08-04 18:03:22,928 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048868\n",
      "2025-08-04 18:03:22,928 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049437\n",
      "Training progress:  29%|██▊       | 86/300 [02:52<07:05,  1.99s/it]2025-08-04 18:03:24,939 - sciml.model.deeponet.deeponet - INFO - Epoch 87/300\n",
      "2025-08-04 18:03:24,940 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048938\n",
      "2025-08-04 18:03:24,941 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049439\n",
      "Training progress:  29%|██▉       | 87/300 [02:54<07:05,  2.00s/it]2025-08-04 18:03:27,010 - sciml.model.deeponet.deeponet - INFO - Epoch 88/300\n",
      "2025-08-04 18:03:27,011 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049002\n",
      "2025-08-04 18:03:27,012 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049466\n",
      "Training progress:  29%|██▉       | 88/300 [02:56<07:08,  2.02s/it]2025-08-04 18:03:29,058 - sciml.model.deeponet.deeponet - INFO - Epoch 89/300\n",
      "2025-08-04 18:03:29,059 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048856\n",
      "2025-08-04 18:03:29,059 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049377\n",
      "Training progress:  30%|██▉       | 89/300 [02:58<07:07,  2.03s/it]2025-08-04 18:03:31,089 - sciml.model.deeponet.deeponet - INFO - Epoch 90/300\n",
      "2025-08-04 18:03:31,090 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048822\n",
      "2025-08-04 18:03:31,091 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049382\n",
      "Training progress:  30%|███       | 90/300 [03:00<07:06,  2.03s/it]2025-08-04 18:03:33,126 - sciml.model.deeponet.deeponet - INFO - Epoch 91/300\n",
      "2025-08-04 18:03:33,127 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048883\n",
      "2025-08-04 18:03:33,127 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049405\n",
      "Training progress:  30%|███       | 91/300 [03:02<07:04,  2.03s/it]2025-08-04 18:03:35,113 - sciml.model.deeponet.deeponet - INFO - Epoch 92/300\n",
      "2025-08-04 18:03:35,114 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049007\n",
      "2025-08-04 18:03:35,115 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049427\n",
      "Training progress:  31%|███       | 92/300 [03:04<06:59,  2.02s/it]2025-08-04 18:03:37,119 - sciml.model.deeponet.deeponet - INFO - Epoch 93/300\n",
      "2025-08-04 18:03:37,119 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048844\n",
      "2025-08-04 18:03:37,119 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049372\n",
      "Training progress:  31%|███       | 93/300 [03:06<06:56,  2.01s/it]2025-08-04 18:03:39,113 - sciml.model.deeponet.deeponet - INFO - Epoch 94/300\n",
      "2025-08-04 18:03:39,113 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048814\n",
      "2025-08-04 18:03:39,114 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049365\n",
      "Training progress:  31%|███▏      | 94/300 [03:08<06:53,  2.01s/it]2025-08-04 18:03:41,099 - sciml.model.deeponet.deeponet - INFO - Epoch 95/300\n",
      "2025-08-04 18:03:41,100 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048809\n",
      "2025-08-04 18:03:41,101 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049363\n",
      "Training progress:  32%|███▏      | 95/300 [03:10<06:50,  2.00s/it]2025-08-04 18:03:43,090 - sciml.model.deeponet.deeponet - INFO - Epoch 96/300\n",
      "2025-08-04 18:03:43,091 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048821\n",
      "2025-08-04 18:03:43,092 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049381\n",
      "Training progress:  32%|███▏      | 96/300 [03:12<06:47,  2.00s/it]2025-08-04 18:03:45,050 - sciml.model.deeponet.deeponet - INFO - Epoch 97/300\n",
      "2025-08-04 18:03:45,051 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048850\n",
      "2025-08-04 18:03:45,052 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049397\n",
      "Training progress:  32%|███▏      | 97/300 [03:14<06:43,  1.99s/it]2025-08-04 18:03:47,034 - sciml.model.deeponet.deeponet - INFO - Epoch 98/300\n",
      "2025-08-04 18:03:47,035 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048848\n",
      "2025-08-04 18:03:47,036 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049369\n",
      "Training progress:  33%|███▎      | 98/300 [03:16<06:41,  1.99s/it]2025-08-04 18:03:49,063 - sciml.model.deeponet.deeponet - INFO - Epoch 99/300\n",
      "2025-08-04 18:03:49,064 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048822\n",
      "2025-08-04 18:03:49,065 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049392\n",
      "Training progress:  33%|███▎      | 99/300 [03:18<06:41,  2.00s/it]2025-08-04 18:03:51,059 - sciml.model.deeponet.deeponet - INFO - Epoch 100/300\n",
      "2025-08-04 18:03:51,061 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048873\n",
      "2025-08-04 18:03:51,061 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049402\n",
      "Training progress:  33%|███▎      | 100/300 [03:20<06:39,  2.00s/it]2025-08-04 18:03:53,083 - sciml.model.deeponet.deeponet - INFO - Epoch 101/300\n",
      "2025-08-04 18:03:53,083 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049009\n",
      "2025-08-04 18:03:53,084 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049476\n",
      "Training progress:  34%|███▎      | 101/300 [03:22<06:39,  2.01s/it]2025-08-04 18:03:55,044 - sciml.model.deeponet.deeponet - INFO - Epoch 102/300\n",
      "2025-08-04 18:03:55,044 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048824\n",
      "2025-08-04 18:03:55,045 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049348\n",
      "Training progress:  34%|███▍      | 102/300 [03:24<06:34,  1.99s/it]2025-08-04 18:03:57,096 - sciml.model.deeponet.deeponet - INFO - Epoch 103/300\n",
      "2025-08-04 18:03:57,096 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048798\n",
      "2025-08-04 18:03:57,097 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049340\n",
      "Training progress:  34%|███▍      | 103/300 [03:26<06:35,  2.01s/it]2025-08-04 18:03:59,162 - sciml.model.deeponet.deeponet - INFO - Epoch 104/300\n",
      "2025-08-04 18:03:59,163 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048816\n",
      "2025-08-04 18:03:59,164 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049392\n",
      "Training progress:  35%|███▍      | 104/300 [03:28<06:37,  2.03s/it]2025-08-04 18:04:01,379 - sciml.model.deeponet.deeponet - INFO - Epoch 105/300\n",
      "2025-08-04 18:04:01,380 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048995\n",
      "2025-08-04 18:04:01,381 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049467\n",
      "Training progress:  35%|███▌      | 105/300 [03:30<06:46,  2.08s/it]2025-08-04 18:04:03,842 - sciml.model.deeponet.deeponet - INFO - Epoch 106/300\n",
      "2025-08-04 18:04:03,843 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048815\n",
      "2025-08-04 18:04:03,844 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049334\n",
      "Training progress:  35%|███▌      | 106/300 [03:33<07:06,  2.20s/it]2025-08-04 18:04:06,184 - sciml.model.deeponet.deeponet - INFO - Epoch 107/300\n",
      "2025-08-04 18:04:06,185 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048798\n",
      "2025-08-04 18:04:06,185 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049336\n",
      "Training progress:  36%|███▌      | 107/300 [03:35<07:12,  2.24s/it]2025-08-04 18:04:08,482 - sciml.model.deeponet.deeponet - INFO - Epoch 108/300\n",
      "2025-08-04 18:04:08,483 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048904\n",
      "2025-08-04 18:04:08,483 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049404\n",
      "Training progress:  36%|███▌      | 108/300 [03:37<07:13,  2.26s/it]2025-08-04 18:04:10,508 - sciml.model.deeponet.deeponet - INFO - Epoch 109/300\n",
      "2025-08-04 18:04:10,509 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048824\n",
      "2025-08-04 18:04:10,509 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049353\n",
      "Training progress:  36%|███▋      | 109/300 [03:39<06:57,  2.19s/it]2025-08-04 18:04:12,550 - sciml.model.deeponet.deeponet - INFO - Epoch 110/300\n",
      "2025-08-04 18:04:12,551 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048816\n",
      "2025-08-04 18:04:12,552 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049333\n",
      "Training progress:  37%|███▋      | 110/300 [03:41<06:47,  2.14s/it]2025-08-04 18:04:14,531 - sciml.model.deeponet.deeponet - INFO - Epoch 111/300\n",
      "2025-08-04 18:04:14,532 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048941\n",
      "2025-08-04 18:04:14,533 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049368\n",
      "Training progress:  37%|███▋      | 111/300 [03:43<06:36,  2.10s/it]2025-08-04 18:04:16,507 - sciml.model.deeponet.deeponet - INFO - Epoch 112/300\n",
      "2025-08-04 18:04:16,508 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048814\n",
      "2025-08-04 18:04:16,509 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049351\n",
      "Training progress:  37%|███▋      | 112/300 [03:45<06:27,  2.06s/it]2025-08-04 18:04:18,535 - sciml.model.deeponet.deeponet - INFO - Epoch 113/300\n",
      "2025-08-04 18:04:18,535 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048788\n",
      "2025-08-04 18:04:18,536 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049358\n",
      "Training progress:  38%|███▊      | 113/300 [03:47<06:23,  2.05s/it]2025-08-04 18:04:20,493 - sciml.model.deeponet.deeponet - INFO - Epoch 114/300\n",
      "2025-08-04 18:04:20,494 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048800\n",
      "2025-08-04 18:04:20,494 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049360\n",
      "Training progress:  38%|███▊      | 114/300 [03:49<06:16,  2.02s/it]2025-08-04 18:04:22,459 - sciml.model.deeponet.deeponet - INFO - Epoch 115/300\n",
      "2025-08-04 18:04:22,460 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048910\n",
      "2025-08-04 18:04:22,461 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049374\n",
      "Training progress:  38%|███▊      | 115/300 [03:51<06:11,  2.01s/it]2025-08-04 18:04:24,420 - sciml.model.deeponet.deeponet - INFO - Epoch 116/300\n",
      "2025-08-04 18:04:24,421 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048791\n",
      "2025-08-04 18:04:24,421 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049322\n",
      "Training progress:  39%|███▊      | 116/300 [03:53<06:06,  1.99s/it]2025-08-04 18:04:26,391 - sciml.model.deeponet.deeponet - INFO - Epoch 117/300\n",
      "2025-08-04 18:04:26,392 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048781\n",
      "2025-08-04 18:04:26,393 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049320\n",
      "Training progress:  39%|███▉      | 117/300 [03:55<06:03,  1.99s/it]2025-08-04 18:04:28,371 - sciml.model.deeponet.deeponet - INFO - Epoch 118/300\n",
      "2025-08-04 18:04:28,372 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048777\n",
      "2025-08-04 18:04:28,373 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049317\n",
      "Training progress:  39%|███▉      | 118/300 [03:57<06:01,  1.98s/it]2025-08-04 18:04:30,434 - sciml.model.deeponet.deeponet - INFO - Epoch 119/300\n",
      "2025-08-04 18:04:30,435 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048776\n",
      "2025-08-04 18:04:30,436 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049354\n",
      "Training progress:  40%|███▉      | 119/300 [03:59<06:03,  2.01s/it]2025-08-04 18:04:32,470 - sciml.model.deeponet.deeponet - INFO - Epoch 120/300\n",
      "2025-08-04 18:04:32,471 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048815\n",
      "2025-08-04 18:04:32,471 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049454\n",
      "Training progress:  40%|████      | 120/300 [04:01<06:02,  2.02s/it]2025-08-04 18:04:34,494 - sciml.model.deeponet.deeponet - INFO - Epoch 121/300\n",
      "2025-08-04 18:04:34,495 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048884\n",
      "2025-08-04 18:04:34,496 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049343\n",
      "Training progress:  40%|████      | 121/300 [04:03<06:01,  2.02s/it]2025-08-04 18:04:36,467 - sciml.model.deeponet.deeponet - INFO - Epoch 122/300\n",
      "2025-08-04 18:04:36,468 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048975\n",
      "2025-08-04 18:04:36,469 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049646\n",
      "Training progress:  41%|████      | 122/300 [04:05<05:56,  2.00s/it]2025-08-04 18:04:38,429 - sciml.model.deeponet.deeponet - INFO - Epoch 123/300\n",
      "2025-08-04 18:04:38,430 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048887\n",
      "2025-08-04 18:04:38,431 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049326\n",
      "Training progress:  41%|████      | 123/300 [04:07<05:52,  1.99s/it]2025-08-04 18:04:40,444 - sciml.model.deeponet.deeponet - INFO - Epoch 124/300\n",
      "2025-08-04 18:04:40,445 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048785\n",
      "2025-08-04 18:04:40,445 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049314\n",
      "Training progress:  41%|████▏     | 124/300 [04:09<05:51,  2.00s/it]2025-08-04 18:04:42,433 - sciml.model.deeponet.deeponet - INFO - Epoch 125/300\n",
      "2025-08-04 18:04:42,434 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048781\n",
      "2025-08-04 18:04:42,435 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049314\n",
      "Training progress:  42%|████▏     | 125/300 [04:11<05:49,  2.00s/it]2025-08-04 18:04:44,409 - sciml.model.deeponet.deeponet - INFO - Epoch 126/300\n",
      "2025-08-04 18:04:44,410 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048844\n",
      "2025-08-04 18:04:44,410 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049400\n",
      "Training progress:  42%|████▏     | 126/300 [04:13<05:46,  1.99s/it]2025-08-04 18:04:46,369 - sciml.model.deeponet.deeponet - INFO - Epoch 127/300\n",
      "2025-08-04 18:04:46,370 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048843\n",
      "2025-08-04 18:04:46,370 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049339\n",
      "Training progress:  42%|████▏     | 127/300 [04:15<05:42,  1.98s/it]2025-08-04 18:04:48,374 - sciml.model.deeponet.deeponet - INFO - Epoch 128/300\n",
      "2025-08-04 18:04:48,374 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048794\n",
      "2025-08-04 18:04:48,376 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049318\n",
      "Training progress:  43%|████▎     | 128/300 [04:17<05:41,  1.99s/it]2025-08-04 18:04:50,306 - sciml.model.deeponet.deeponet - INFO - Epoch 129/300\n",
      "2025-08-04 18:04:50,306 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048818\n",
      "2025-08-04 18:04:50,307 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049322\n",
      "Training progress:  43%|████▎     | 129/300 [04:19<05:37,  1.97s/it]2025-08-04 18:04:52,261 - sciml.model.deeponet.deeponet - INFO - Epoch 130/300\n",
      "2025-08-04 18:04:52,262 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048869\n",
      "2025-08-04 18:04:52,262 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049395\n",
      "Training progress:  43%|████▎     | 130/300 [04:21<05:34,  1.97s/it]2025-08-04 18:04:54,213 - sciml.model.deeponet.deeponet - INFO - Epoch 131/300\n",
      "2025-08-04 18:04:54,213 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048801\n",
      "2025-08-04 18:04:54,214 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049311\n",
      "Training progress:  44%|████▎     | 131/300 [04:23<05:31,  1.96s/it]2025-08-04 18:04:56,174 - sciml.model.deeponet.deeponet - INFO - Epoch 132/300\n",
      "2025-08-04 18:04:56,174 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048779\n",
      "2025-08-04 18:04:56,175 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049301\n",
      "Training progress:  44%|████▍     | 132/300 [04:25<05:29,  1.96s/it]2025-08-04 18:04:58,152 - sciml.model.deeponet.deeponet - INFO - Epoch 133/300\n",
      "2025-08-04 18:04:58,153 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048786\n",
      "2025-08-04 18:04:58,153 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049303\n",
      "Training progress:  44%|████▍     | 133/300 [04:27<05:28,  1.97s/it]2025-08-04 18:05:00,248 - sciml.model.deeponet.deeponet - INFO - Epoch 134/300\n",
      "2025-08-04 18:05:00,249 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048819\n",
      "2025-08-04 18:05:00,250 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049321\n",
      "Training progress:  45%|████▍     | 134/300 [04:29<05:32,  2.01s/it]2025-08-04 18:05:02,301 - sciml.model.deeponet.deeponet - INFO - Epoch 135/300\n",
      "2025-08-04 18:05:02,302 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048959\n",
      "2025-08-04 18:05:02,302 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049336\n",
      "Training progress:  45%|████▌     | 135/300 [04:31<05:33,  2.02s/it]2025-08-04 18:05:04,392 - sciml.model.deeponet.deeponet - INFO - Epoch 136/300\n",
      "2025-08-04 18:05:04,393 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048830\n",
      "2025-08-04 18:05:04,394 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049339\n",
      "Training progress:  45%|████▌     | 136/300 [04:33<05:34,  2.04s/it]2025-08-04 18:05:06,395 - sciml.model.deeponet.deeponet - INFO - Epoch 137/300\n",
      "2025-08-04 18:05:06,396 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048776\n",
      "2025-08-04 18:05:06,397 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049296\n",
      "Training progress:  46%|████▌     | 137/300 [04:35<05:30,  2.03s/it]2025-08-04 18:05:08,377 - sciml.model.deeponet.deeponet - INFO - Epoch 138/300\n",
      "2025-08-04 18:05:08,378 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048755\n",
      "2025-08-04 18:05:08,379 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049291\n",
      "Training progress:  46%|████▌     | 138/300 [04:37<05:26,  2.02s/it]2025-08-04 18:05:10,363 - sciml.model.deeponet.deeponet - INFO - Epoch 139/300\n",
      "2025-08-04 18:05:10,363 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048775\n",
      "2025-08-04 18:05:10,364 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049294\n",
      "Training progress:  46%|████▋     | 139/300 [04:39<05:23,  2.01s/it]2025-08-04 18:05:12,388 - sciml.model.deeponet.deeponet - INFO - Epoch 140/300\n",
      "2025-08-04 18:05:12,388 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048756\n",
      "2025-08-04 18:05:12,389 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049292\n",
      "Training progress:  47%|████▋     | 140/300 [04:41<05:21,  2.01s/it]2025-08-04 18:05:14,426 - sciml.model.deeponet.deeponet - INFO - Epoch 141/300\n",
      "2025-08-04 18:05:14,427 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048798\n",
      "2025-08-04 18:05:14,428 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049291\n",
      "Training progress:  47%|████▋     | 141/300 [04:43<05:21,  2.02s/it]2025-08-04 18:05:16,400 - sciml.model.deeponet.deeponet - INFO - Epoch 142/300\n",
      "2025-08-04 18:05:16,401 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048783\n",
      "2025-08-04 18:05:16,402 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049299\n",
      "Training progress:  47%|████▋     | 142/300 [04:45<05:16,  2.01s/it]2025-08-04 18:05:18,417 - sciml.model.deeponet.deeponet - INFO - Epoch 143/300\n",
      "2025-08-04 18:05:18,418 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048779\n",
      "2025-08-04 18:05:18,419 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049289\n",
      "Training progress:  48%|████▊     | 143/300 [04:47<05:15,  2.01s/it]2025-08-04 18:05:20,487 - sciml.model.deeponet.deeponet - INFO - Epoch 144/300\n",
      "2025-08-04 18:05:20,487 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048766\n",
      "2025-08-04 18:05:20,488 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049291\n",
      "Training progress:  48%|████▊     | 144/300 [04:49<05:16,  2.03s/it]2025-08-04 18:05:22,443 - sciml.model.deeponet.deeponet - INFO - Epoch 145/300\n",
      "2025-08-04 18:05:22,444 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048741\n",
      "2025-08-04 18:05:22,444 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049282\n",
      "Training progress:  48%|████▊     | 145/300 [04:51<05:10,  2.01s/it]2025-08-04 18:05:24,389 - sciml.model.deeponet.deeponet - INFO - Epoch 146/300\n",
      "2025-08-04 18:05:24,390 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048770\n",
      "2025-08-04 18:05:24,391 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049401\n",
      "Training progress:  49%|████▊     | 146/300 [04:53<05:06,  1.99s/it]2025-08-04 18:05:26,342 - sciml.model.deeponet.deeponet - INFO - Epoch 147/300\n",
      "2025-08-04 18:05:26,342 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048801\n",
      "2025-08-04 18:05:26,343 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049313\n",
      "Training progress:  49%|████▉     | 147/300 [04:55<05:02,  1.98s/it]2025-08-04 18:05:28,346 - sciml.model.deeponet.deeponet - INFO - Epoch 148/300\n",
      "2025-08-04 18:05:28,347 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048759\n",
      "2025-08-04 18:05:28,347 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049291\n",
      "Training progress:  49%|████▉     | 148/300 [04:57<05:01,  1.99s/it]2025-08-04 18:05:30,325 - sciml.model.deeponet.deeponet - INFO - Epoch 149/300\n",
      "2025-08-04 18:05:30,326 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048772\n",
      "2025-08-04 18:05:30,327 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049334\n",
      "Training progress:  50%|████▉     | 149/300 [04:59<04:59,  1.98s/it]2025-08-04 18:05:32,272 - sciml.model.deeponet.deeponet - INFO - Epoch 150/300\n",
      "2025-08-04 18:05:32,273 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048784\n",
      "2025-08-04 18:05:32,274 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049401\n",
      "Training progress:  50%|█████     | 150/300 [05:01<04:55,  1.97s/it]2025-08-04 18:05:34,301 - sciml.model.deeponet.deeponet - INFO - Epoch 151/300\n",
      "2025-08-04 18:05:34,301 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048842\n",
      "2025-08-04 18:05:34,302 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049328\n",
      "Training progress:  50%|█████     | 151/300 [05:03<04:56,  1.99s/it]2025-08-04 18:05:36,332 - sciml.model.deeponet.deeponet - INFO - Epoch 152/300\n",
      "2025-08-04 18:05:36,333 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048761\n",
      "2025-08-04 18:05:36,334 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049346\n",
      "Training progress:  51%|█████     | 152/300 [05:05<04:56,  2.00s/it]2025-08-04 18:05:38,351 - sciml.model.deeponet.deeponet - INFO - Epoch 153/300\n",
      "2025-08-04 18:05:38,352 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048804\n",
      "2025-08-04 18:05:38,353 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049474\n",
      "Training progress:  51%|█████     | 153/300 [05:07<04:55,  2.01s/it]2025-08-04 18:05:40,356 - sciml.model.deeponet.deeponet - INFO - Epoch 154/300\n",
      "2025-08-04 18:05:40,357 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048833\n",
      "2025-08-04 18:05:40,357 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049305\n",
      "Training progress:  51%|█████▏    | 154/300 [05:09<04:52,  2.01s/it]2025-08-04 18:05:42,406 - sciml.model.deeponet.deeponet - INFO - Epoch 155/300\n",
      "2025-08-04 18:05:42,407 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048794\n",
      "2025-08-04 18:05:42,407 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049316\n",
      "Training progress:  52%|█████▏    | 155/300 [05:11<04:52,  2.02s/it]2025-08-04 18:05:44,673 - sciml.model.deeponet.deeponet - INFO - Epoch 156/300\n",
      "2025-08-04 18:05:44,674 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049228\n",
      "2025-08-04 18:05:44,674 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049590\n",
      "Training progress:  52%|█████▏    | 156/300 [05:14<05:01,  2.09s/it]2025-08-04 18:05:46,793 - sciml.model.deeponet.deeponet - INFO - Epoch 157/300\n",
      "2025-08-04 18:05:46,793 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048844\n",
      "2025-08-04 18:05:46,794 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049294\n",
      "Training progress:  52%|█████▏    | 157/300 [05:16<05:00,  2.10s/it]2025-08-04 18:05:48,788 - sciml.model.deeponet.deeponet - INFO - Epoch 158/300\n",
      "2025-08-04 18:05:48,788 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048752\n",
      "2025-08-04 18:05:48,789 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049301\n",
      "Training progress:  53%|█████▎    | 158/300 [05:18<04:53,  2.07s/it]2025-08-04 18:05:50,749 - sciml.model.deeponet.deeponet - INFO - Epoch 159/300\n",
      "2025-08-04 18:05:50,749 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048757\n",
      "2025-08-04 18:05:50,750 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049294\n",
      "Training progress:  53%|█████▎    | 159/300 [05:20<04:47,  2.04s/it]2025-08-04 18:05:52,729 - sciml.model.deeponet.deeponet - INFO - Epoch 160/300\n",
      "2025-08-04 18:05:52,729 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048742\n",
      "2025-08-04 18:05:52,730 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049273\n",
      "Training progress:  53%|█████▎    | 160/300 [05:22<04:42,  2.02s/it]2025-08-04 18:05:54,715 - sciml.model.deeponet.deeponet - INFO - Epoch 161/300\n",
      "2025-08-04 18:05:54,716 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048731\n",
      "2025-08-04 18:05:54,717 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049273\n",
      "Training progress:  54%|█████▎    | 161/300 [05:24<04:39,  2.01s/it]2025-08-04 18:05:56,673 - sciml.model.deeponet.deeponet - INFO - Epoch 162/300\n",
      "2025-08-04 18:05:56,673 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048728\n",
      "2025-08-04 18:05:56,674 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049269\n",
      "Training progress:  54%|█████▍    | 162/300 [05:26<04:35,  1.99s/it]2025-08-04 18:05:58,670 - sciml.model.deeponet.deeponet - INFO - Epoch 163/300\n",
      "2025-08-04 18:05:58,670 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048728\n",
      "2025-08-04 18:05:58,671 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049270\n",
      "Training progress:  54%|█████▍    | 163/300 [05:28<04:33,  2.00s/it]2025-08-04 18:06:00,648 - sciml.model.deeponet.deeponet - INFO - Epoch 164/300\n",
      "2025-08-04 18:06:00,649 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048730\n",
      "2025-08-04 18:06:00,649 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049283\n",
      "Training progress:  55%|█████▍    | 164/300 [05:30<04:30,  1.99s/it]2025-08-04 18:06:02,620 - sciml.model.deeponet.deeponet - INFO - Epoch 165/300\n",
      "2025-08-04 18:06:02,621 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048732\n",
      "2025-08-04 18:06:02,622 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049299\n",
      "Training progress:  55%|█████▌    | 165/300 [05:32<04:27,  1.98s/it]2025-08-04 18:06:04,622 - sciml.model.deeponet.deeponet - INFO - Epoch 166/300\n",
      "2025-08-04 18:06:04,623 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048741\n",
      "2025-08-04 18:06:04,623 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049301\n",
      "Training progress:  55%|█████▌    | 166/300 [05:34<04:26,  1.99s/it]2025-08-04 18:06:06,659 - sciml.model.deeponet.deeponet - INFO - Epoch 167/300\n",
      "2025-08-04 18:06:06,660 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048759\n",
      "2025-08-04 18:06:06,661 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049290\n",
      "Training progress:  56%|█████▌    | 167/300 [05:36<04:26,  2.00s/it]2025-08-04 18:06:08,707 - sciml.model.deeponet.deeponet - INFO - Epoch 168/300\n",
      "2025-08-04 18:06:08,708 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048778\n",
      "2025-08-04 18:06:08,709 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049306\n",
      "Training progress:  56%|█████▌    | 168/300 [05:38<04:26,  2.02s/it]2025-08-04 18:06:10,790 - sciml.model.deeponet.deeponet - INFO - Epoch 169/300\n",
      "2025-08-04 18:06:10,791 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048758\n",
      "2025-08-04 18:06:10,791 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049335\n",
      "Training progress:  56%|█████▋    | 169/300 [05:40<04:26,  2.04s/it]2025-08-04 18:06:12,886 - sciml.model.deeponet.deeponet - INFO - Epoch 170/300\n",
      "2025-08-04 18:06:12,887 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048812\n",
      "2025-08-04 18:06:12,888 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049320\n",
      "Training progress:  57%|█████▋    | 170/300 [05:42<04:27,  2.05s/it]2025-08-04 18:06:14,874 - sciml.model.deeponet.deeponet - INFO - Epoch 171/300\n",
      "2025-08-04 18:06:14,875 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048952\n",
      "2025-08-04 18:06:14,876 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049408\n",
      "Training progress:  57%|█████▋    | 171/300 [05:44<04:22,  2.03s/it]2025-08-04 18:06:16,844 - sciml.model.deeponet.deeponet - INFO - Epoch 172/300\n",
      "2025-08-04 18:06:16,845 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048794\n",
      "2025-08-04 18:06:16,846 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049326\n",
      "Training progress:  57%|█████▋    | 172/300 [05:46<04:17,  2.02s/it]2025-08-04 18:06:18,815 - sciml.model.deeponet.deeponet - INFO - Epoch 173/300\n",
      "2025-08-04 18:06:18,815 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048751\n",
      "2025-08-04 18:06:18,816 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049282\n",
      "Training progress:  58%|█████▊    | 173/300 [05:48<04:14,  2.00s/it]2025-08-04 18:06:20,794 - sciml.model.deeponet.deeponet - INFO - Epoch 174/300\n",
      "2025-08-04 18:06:20,794 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048737\n",
      "2025-08-04 18:06:20,795 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049261\n",
      "Training progress:  58%|█████▊    | 174/300 [05:50<04:11,  1.99s/it]2025-08-04 18:06:22,778 - sciml.model.deeponet.deeponet - INFO - Epoch 175/300\n",
      "2025-08-04 18:06:22,779 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048740\n",
      "2025-08-04 18:06:22,780 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049278\n",
      "Training progress:  58%|█████▊    | 175/300 [05:52<04:08,  1.99s/it]2025-08-04 18:06:24,764 - sciml.model.deeponet.deeponet - INFO - Epoch 176/300\n",
      "2025-08-04 18:06:24,765 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048952\n",
      "2025-08-04 18:06:24,765 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049508\n",
      "Training progress:  59%|█████▊    | 176/300 [05:54<04:06,  1.99s/it]2025-08-04 18:06:26,761 - sciml.model.deeponet.deeponet - INFO - Epoch 177/300\n",
      "2025-08-04 18:06:26,762 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048863\n",
      "2025-08-04 18:06:26,763 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049315\n",
      "Training progress:  59%|█████▉    | 177/300 [05:56<04:05,  1.99s/it]2025-08-04 18:06:28,722 - sciml.model.deeponet.deeponet - INFO - Epoch 178/300\n",
      "2025-08-04 18:06:28,723 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048759\n",
      "2025-08-04 18:06:28,723 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049277\n",
      "Training progress:  59%|█████▉    | 178/300 [05:58<04:01,  1.98s/it]2025-08-04 18:06:30,692 - sciml.model.deeponet.deeponet - INFO - Epoch 179/300\n",
      "2025-08-04 18:06:30,693 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048737\n",
      "2025-08-04 18:06:30,693 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049265\n",
      "Training progress:  60%|█████▉    | 179/300 [06:00<03:59,  1.98s/it]2025-08-04 18:06:32,645 - sciml.model.deeponet.deeponet - INFO - Epoch 180/300\n",
      "2025-08-04 18:06:32,646 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048733\n",
      "2025-08-04 18:06:32,646 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049265\n",
      "Training progress:  60%|██████    | 180/300 [06:02<03:56,  1.97s/it]2025-08-04 18:06:34,589 - sciml.model.deeponet.deeponet - INFO - Epoch 181/300\n",
      "2025-08-04 18:06:34,589 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048745\n",
      "2025-08-04 18:06:34,590 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049266\n",
      "Training progress:  60%|██████    | 181/300 [06:03<03:53,  1.96s/it]2025-08-04 18:06:36,550 - sciml.model.deeponet.deeponet - INFO - Epoch 182/300\n",
      "2025-08-04 18:06:36,551 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048751\n",
      "2025-08-04 18:06:36,552 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049266\n",
      "Training progress:  61%|██████    | 182/300 [06:05<03:51,  1.96s/it]2025-08-04 18:06:38,584 - sciml.model.deeponet.deeponet - INFO - Epoch 183/300\n",
      "2025-08-04 18:06:38,585 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048749\n",
      "2025-08-04 18:06:38,586 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049263\n",
      "Training progress:  61%|██████    | 183/300 [06:07<03:52,  1.98s/it]2025-08-04 18:06:40,670 - sciml.model.deeponet.deeponet - INFO - Epoch 184/300\n",
      "2025-08-04 18:06:40,670 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048737\n",
      "2025-08-04 18:06:40,671 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049267\n",
      "Training progress:  61%|██████▏   | 184/300 [06:10<03:53,  2.01s/it]2025-08-04 18:06:42,677 - sciml.model.deeponet.deeponet - INFO - Epoch 185/300\n",
      "2025-08-04 18:06:42,678 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048745\n",
      "2025-08-04 18:06:42,679 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049260\n",
      "Training progress:  62%|██████▏   | 185/300 [06:12<03:51,  2.01s/it]2025-08-04 18:06:44,717 - sciml.model.deeponet.deeponet - INFO - Epoch 186/300\n",
      "2025-08-04 18:06:44,718 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048735\n",
      "2025-08-04 18:06:44,718 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049262\n",
      "Training progress:  62%|██████▏   | 186/300 [06:14<03:50,  2.02s/it]2025-08-04 18:06:46,695 - sciml.model.deeponet.deeponet - INFO - Epoch 187/300\n",
      "2025-08-04 18:06:46,696 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048727\n",
      "2025-08-04 18:06:46,697 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049259\n",
      "Training progress:  62%|██████▏   | 187/300 [06:16<03:46,  2.01s/it]2025-08-04 18:06:48,669 - sciml.model.deeponet.deeponet - INFO - Epoch 188/300\n",
      "2025-08-04 18:06:48,670 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048755\n",
      "2025-08-04 18:06:48,670 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049279\n",
      "Training progress:  63%|██████▎   | 188/300 [06:18<03:43,  2.00s/it]2025-08-04 18:06:50,634 - sciml.model.deeponet.deeponet - INFO - Epoch 189/300\n",
      "2025-08-04 18:06:50,635 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049228\n",
      "2025-08-04 18:06:50,636 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.050113\n",
      "Training progress:  63%|██████▎   | 189/300 [06:20<03:40,  1.99s/it]2025-08-04 18:06:52,604 - sciml.model.deeponet.deeponet - INFO - Epoch 190/300\n",
      "2025-08-04 18:06:52,605 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048956\n",
      "2025-08-04 18:06:52,606 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049300\n",
      "Training progress:  63%|██████▎   | 190/300 [06:21<03:38,  1.98s/it]2025-08-04 18:06:54,750 - sciml.model.deeponet.deeponet - INFO - Epoch 191/300\n",
      "2025-08-04 18:06:54,751 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048745\n",
      "2025-08-04 18:06:54,751 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049276\n",
      "Training progress:  64%|██████▎   | 191/300 [06:24<03:41,  2.03s/it]2025-08-04 18:06:56,627 - sciml.model.deeponet.deeponet - INFO - Epoch 192/300\n",
      "2025-08-04 18:06:56,628 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048724\n",
      "2025-08-04 18:06:56,628 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049262\n",
      "Training progress:  64%|██████▍   | 192/300 [06:26<03:34,  1.99s/it]2025-08-04 18:06:58,452 - sciml.model.deeponet.deeponet - INFO - Epoch 193/300\n",
      "2025-08-04 18:06:58,453 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048721\n",
      "2025-08-04 18:06:58,454 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049259\n",
      "Training progress:  64%|██████▍   | 193/300 [06:27<03:27,  1.94s/it]2025-08-04 18:07:00,346 - sciml.model.deeponet.deeponet - INFO - Epoch 194/300\n",
      "2025-08-04 18:07:00,347 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048715\n",
      "2025-08-04 18:07:00,348 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049255\n",
      "Training progress:  65%|██████▍   | 194/300 [06:29<03:23,  1.92s/it]2025-08-04 18:07:02,179 - sciml.model.deeponet.deeponet - INFO - Epoch 195/300\n",
      "2025-08-04 18:07:02,179 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048712\n",
      "2025-08-04 18:07:02,180 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049251\n",
      "Training progress:  65%|██████▌   | 195/300 [06:31<03:19,  1.90s/it]2025-08-04 18:07:03,991 - sciml.model.deeponet.deeponet - INFO - Epoch 196/300\n",
      "2025-08-04 18:07:03,992 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048714\n",
      "2025-08-04 18:07:03,993 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  65%|██████▌   | 196/300 [06:33<03:14,  1.87s/it]2025-08-04 18:07:05,829 - sciml.model.deeponet.deeponet - INFO - Epoch 197/300\n",
      "2025-08-04 18:07:05,830 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048714\n",
      "2025-08-04 18:07:05,831 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049251\n",
      "Training progress:  66%|██████▌   | 197/300 [06:35<03:11,  1.86s/it]2025-08-04 18:07:07,604 - sciml.model.deeponet.deeponet - INFO - Epoch 198/300\n",
      "2025-08-04 18:07:07,605 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048720\n",
      "2025-08-04 18:07:07,606 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049253\n",
      "Training progress:  66%|██████▌   | 198/300 [06:36<03:07,  1.84s/it]2025-08-04 18:07:09,400 - sciml.model.deeponet.deeponet - INFO - Epoch 199/300\n",
      "2025-08-04 18:07:09,401 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048712\n",
      "2025-08-04 18:07:09,402 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049252\n",
      "Training progress:  66%|██████▋   | 199/300 [06:38<03:04,  1.82s/it]2025-08-04 18:07:11,283 - sciml.model.deeponet.deeponet - INFO - Epoch 200/300\n",
      "2025-08-04 18:07:11,284 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048721\n",
      "2025-08-04 18:07:11,284 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049257\n",
      "Training progress:  67%|██████▋   | 200/300 [06:40<03:04,  1.84s/it]2025-08-04 18:07:13.189887: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-08-04 18:07:13,191 - sciml.model.deeponet.deeponet - INFO - Epoch 201/300\n",
      "2025-08-04 18:07:13,192 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048763\n",
      "2025-08-04 18:07:13,193 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049254\n",
      "Training progress:  67%|██████▋   | 201/300 [06:42<03:04,  1.86s/it]2025-08-04 18:07:15,123 - sciml.model.deeponet.deeponet - INFO - Epoch 202/300\n",
      "2025-08-04 18:07:15,123 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048756\n",
      "2025-08-04 18:07:15,125 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049264\n",
      "Training progress:  67%|██████▋   | 202/300 [06:44<03:04,  1.88s/it]2025-08-04 18:07:16,958 - sciml.model.deeponet.deeponet - INFO - Epoch 203/300\n",
      "2025-08-04 18:07:16,959 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048862\n",
      "2025-08-04 18:07:16,959 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049455\n",
      "Training progress:  68%|██████▊   | 203/300 [06:46<03:01,  1.87s/it]2025-08-04 18:07:18,838 - sciml.model.deeponet.deeponet - INFO - Epoch 204/300\n",
      "2025-08-04 18:07:18,839 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048793\n",
      "2025-08-04 18:07:18,840 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049408\n",
      "Training progress:  68%|██████▊   | 204/300 [06:48<02:59,  1.87s/it]2025-08-04 18:07:20,753 - sciml.model.deeponet.deeponet - INFO - Epoch 205/300\n",
      "2025-08-04 18:07:20,754 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048801\n",
      "2025-08-04 18:07:20,755 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049299\n",
      "Training progress:  68%|██████▊   | 205/300 [06:50<02:59,  1.88s/it]2025-08-04 18:07:22,674 - sciml.model.deeponet.deeponet - INFO - Epoch 206/300\n",
      "2025-08-04 18:07:22,674 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048730\n",
      "2025-08-04 18:07:22,675 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049282\n",
      "Training progress:  69%|██████▊   | 206/300 [06:52<02:58,  1.90s/it]2025-08-04 18:07:24,639 - sciml.model.deeponet.deeponet - INFO - Epoch 207/300\n",
      "2025-08-04 18:07:24,640 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048714\n",
      "2025-08-04 18:07:24,641 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049261\n",
      "Training progress:  69%|██████▉   | 207/300 [06:54<02:58,  1.92s/it]2025-08-04 18:07:26,712 - sciml.model.deeponet.deeponet - INFO - Epoch 208/300\n",
      "2025-08-04 18:07:26,713 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048734\n",
      "2025-08-04 18:07:26,714 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049287\n",
      "Training progress:  69%|██████▉   | 208/300 [06:56<03:00,  1.96s/it]2025-08-04 18:07:28,649 - sciml.model.deeponet.deeponet - INFO - Epoch 209/300\n",
      "2025-08-04 18:07:28,650 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048729\n",
      "2025-08-04 18:07:28,651 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049264\n",
      "Training progress:  70%|██████▉   | 209/300 [06:58<02:57,  1.96s/it]2025-08-04 18:07:31,247 - sciml.model.deeponet.deeponet - INFO - Epoch 210/300\n",
      "2025-08-04 18:07:31,247 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048714\n",
      "2025-08-04 18:07:31,248 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049255\n",
      "Training progress:  70%|███████   | 210/300 [07:00<03:13,  2.15s/it]2025-08-04 18:07:33,228 - sciml.model.deeponet.deeponet - INFO - Epoch 211/300\n",
      "2025-08-04 18:07:33,228 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048739\n",
      "2025-08-04 18:07:33,229 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049260\n",
      "Training progress:  70%|███████   | 211/300 [07:02<03:06,  2.10s/it]2025-08-04 18:07:35,127 - sciml.model.deeponet.deeponet - INFO - Epoch 212/300\n",
      "2025-08-04 18:07:35,128 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048710\n",
      "2025-08-04 18:07:35,129 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049246\n",
      "Training progress:  71%|███████   | 212/300 [07:04<02:59,  2.04s/it]2025-08-04 18:07:37,616 - sciml.model.deeponet.deeponet - INFO - Epoch 213/300\n",
      "2025-08-04 18:07:37,617 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048705\n",
      "2025-08-04 18:07:37,618 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049247\n",
      "Training progress:  71%|███████   | 213/300 [07:07<03:09,  2.17s/it]2025-08-04 18:07:40,313 - sciml.model.deeponet.deeponet - INFO - Epoch 214/300\n",
      "2025-08-04 18:07:40,314 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048745\n",
      "2025-08-04 18:07:40,314 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049306\n",
      "Training progress:  71%|███████▏  | 214/300 [07:09<03:20,  2.33s/it]2025-08-04 18:07:42,319 - sciml.model.deeponet.deeponet - INFO - Epoch 215/300\n",
      "2025-08-04 18:07:42,320 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049086\n",
      "2025-08-04 18:07:42,321 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049640\n",
      "Training progress:  72%|███████▏  | 215/300 [07:11<03:09,  2.23s/it]2025-08-04 18:07:44,313 - sciml.model.deeponet.deeponet - INFO - Epoch 216/300\n",
      "2025-08-04 18:07:44,314 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048975\n",
      "2025-08-04 18:07:44,315 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049396\n",
      "Training progress:  72%|███████▏  | 216/300 [07:13<03:01,  2.16s/it]2025-08-04 18:07:46,398 - sciml.model.deeponet.deeponet - INFO - Epoch 217/300\n",
      "2025-08-04 18:07:46,399 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048768\n",
      "2025-08-04 18:07:46,400 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049268\n",
      "Training progress:  72%|███████▏  | 217/300 [07:15<02:57,  2.14s/it]2025-08-04 18:07:48,279 - sciml.model.deeponet.deeponet - INFO - Epoch 218/300\n",
      "2025-08-04 18:07:48,280 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048721\n",
      "2025-08-04 18:07:48,280 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049260\n",
      "Training progress:  73%|███████▎  | 218/300 [07:17<02:49,  2.06s/it]2025-08-04 18:07:50,286 - sciml.model.deeponet.deeponet - INFO - Epoch 219/300\n",
      "2025-08-04 18:07:50,287 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048720\n",
      "2025-08-04 18:07:50,288 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049254\n",
      "Training progress:  73%|███████▎  | 219/300 [07:19<02:45,  2.05s/it]2025-08-04 18:07:52,428 - sciml.model.deeponet.deeponet - INFO - Epoch 220/300\n",
      "2025-08-04 18:07:52,429 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048717\n",
      "2025-08-04 18:07:52,430 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049249\n",
      "Training progress:  73%|███████▎  | 220/300 [07:21<02:45,  2.07s/it]2025-08-04 18:07:54,395 - sciml.model.deeponet.deeponet - INFO - Epoch 221/300\n",
      "2025-08-04 18:07:54,396 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048708\n",
      "2025-08-04 18:07:54,397 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  74%|███████▎  | 221/300 [07:23<02:41,  2.04s/it]2025-08-04 18:07:56,435 - sciml.model.deeponet.deeponet - INFO - Epoch 222/300\n",
      "2025-08-04 18:07:56,435 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048703\n",
      "2025-08-04 18:07:56,436 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049249\n",
      "Training progress:  74%|███████▍  | 222/300 [07:25<02:39,  2.04s/it]2025-08-04 18:07:58,322 - sciml.model.deeponet.deeponet - INFO - Epoch 223/300\n",
      "2025-08-04 18:07:58,323 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048703\n",
      "2025-08-04 18:07:58,323 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  74%|███████▍  | 223/300 [07:27<02:33,  2.00s/it]2025-08-04 18:08:00,220 - sciml.model.deeponet.deeponet - INFO - Epoch 224/300\n",
      "2025-08-04 18:08:00,220 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048702\n",
      "2025-08-04 18:08:00,221 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049243\n",
      "Training progress:  75%|███████▍  | 224/300 [07:29<02:29,  1.97s/it]2025-08-04 18:08:02,292 - sciml.model.deeponet.deeponet - INFO - Epoch 225/300\n",
      "2025-08-04 18:08:02,293 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048701\n",
      "2025-08-04 18:08:02,294 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049245\n",
      "Training progress:  75%|███████▌  | 225/300 [07:31<02:29,  2.00s/it]2025-08-04 18:08:04,135 - sciml.model.deeponet.deeponet - INFO - Epoch 226/300\n",
      "2025-08-04 18:08:04,136 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048727\n",
      "2025-08-04 18:08:04,136 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049257\n",
      "Training progress:  75%|███████▌  | 226/300 [07:33<02:24,  1.95s/it]2025-08-04 18:08:06,172 - sciml.model.deeponet.deeponet - INFO - Epoch 227/300\n",
      "2025-08-04 18:08:06,173 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048708\n",
      "2025-08-04 18:08:06,174 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049259\n",
      "Training progress:  76%|███████▌  | 227/300 [07:35<02:24,  1.98s/it]2025-08-04 18:08:08,007 - sciml.model.deeponet.deeponet - INFO - Epoch 228/300\n",
      "2025-08-04 18:08:08,008 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048734\n",
      "2025-08-04 18:08:08,009 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049269\n",
      "Training progress:  76%|███████▌  | 228/300 [07:37<02:19,  1.93s/it]2025-08-04 18:08:10,002 - sciml.model.deeponet.deeponet - INFO - Epoch 229/300\n",
      "2025-08-04 18:08:10,003 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048738\n",
      "2025-08-04 18:08:10,004 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049262\n",
      "Training progress:  76%|███████▋  | 229/300 [07:39<02:18,  1.95s/it]2025-08-04 18:08:12,011 - sciml.model.deeponet.deeponet - INFO - Epoch 230/300\n",
      "2025-08-04 18:08:12,012 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048745\n",
      "2025-08-04 18:08:12,013 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  77%|███████▋  | 230/300 [07:41<02:17,  1.97s/it]2025-08-04 18:08:14,234 - sciml.model.deeponet.deeponet - INFO - Epoch 231/300\n",
      "2025-08-04 18:08:14,235 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048794\n",
      "2025-08-04 18:08:14,235 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049279\n",
      "Training progress:  77%|███████▋  | 231/300 [07:43<02:21,  2.05s/it]2025-08-04 18:08:16,280 - sciml.model.deeponet.deeponet - INFO - Epoch 232/300\n",
      "2025-08-04 18:08:16,281 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048740\n",
      "2025-08-04 18:08:16,282 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049261\n",
      "Training progress:  77%|███████▋  | 232/300 [07:45<02:19,  2.05s/it]2025-08-04 18:08:18,186 - sciml.model.deeponet.deeponet - INFO - Epoch 233/300\n",
      "2025-08-04 18:08:18,187 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048704\n",
      "2025-08-04 18:08:18,188 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049251\n",
      "Training progress:  78%|███████▊  | 233/300 [07:47<02:14,  2.00s/it]2025-08-04 18:08:20,512 - sciml.model.deeponet.deeponet - INFO - Epoch 234/300\n",
      "2025-08-04 18:08:20,513 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048725\n",
      "2025-08-04 18:08:20,514 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049330\n",
      "Training progress:  78%|███████▊  | 234/300 [07:49<02:18,  2.10s/it]2025-08-04 18:08:22,529 - sciml.model.deeponet.deeponet - INFO - Epoch 235/300\n",
      "2025-08-04 18:08:22,530 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048740\n",
      "2025-08-04 18:08:22,530 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049296\n",
      "Training progress:  78%|███████▊  | 235/300 [07:51<02:14,  2.08s/it]2025-08-04 18:08:24,498 - sciml.model.deeponet.deeponet - INFO - Epoch 236/300\n",
      "2025-08-04 18:08:24,499 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048798\n",
      "2025-08-04 18:08:24,499 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049304\n",
      "Training progress:  79%|███████▊  | 236/300 [07:53<02:10,  2.04s/it]2025-08-04 18:08:26,534 - sciml.model.deeponet.deeponet - INFO - Epoch 237/300\n",
      "2025-08-04 18:08:26,534 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048719\n",
      "2025-08-04 18:08:26,535 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049245\n",
      "Training progress:  79%|███████▉  | 237/300 [07:55<02:08,  2.04s/it]2025-08-04 18:08:28,578 - sciml.model.deeponet.deeponet - INFO - Epoch 238/300\n",
      "2025-08-04 18:08:28,579 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048711\n",
      "2025-08-04 18:08:28,580 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049251\n",
      "Training progress:  79%|███████▉  | 238/300 [07:57<02:06,  2.04s/it]2025-08-04 18:08:30,615 - sciml.model.deeponet.deeponet - INFO - Epoch 239/300\n",
      "2025-08-04 18:08:30,615 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048774\n",
      "2025-08-04 18:08:30,616 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049283\n",
      "Training progress:  80%|███████▉  | 239/300 [08:00<02:04,  2.04s/it]2025-08-04 18:08:32,902 - sciml.model.deeponet.deeponet - INFO - Epoch 240/300\n",
      "2025-08-04 18:08:32,903 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048720\n",
      "2025-08-04 18:08:32,904 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049267\n",
      "Training progress:  80%|████████  | 240/300 [08:02<02:06,  2.11s/it]2025-08-04 18:08:34,985 - sciml.model.deeponet.deeponet - INFO - Epoch 241/300\n",
      "2025-08-04 18:08:34,986 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048737\n",
      "2025-08-04 18:08:34,987 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049279\n",
      "Training progress:  80%|████████  | 241/300 [08:04<02:04,  2.11s/it]2025-08-04 18:08:36,966 - sciml.model.deeponet.deeponet - INFO - Epoch 242/300\n",
      "2025-08-04 18:08:36,967 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048719\n",
      "2025-08-04 18:08:36,968 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049266\n",
      "Training progress:  81%|████████  | 242/300 [08:06<01:59,  2.07s/it]2025-08-04 18:08:39,207 - sciml.model.deeponet.deeponet - INFO - Epoch 243/300\n",
      "2025-08-04 18:08:39,208 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048740\n",
      "2025-08-04 18:08:39,208 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049272\n",
      "Training progress:  81%|████████  | 243/300 [08:08<02:00,  2.12s/it]2025-08-04 18:08:41,215 - sciml.model.deeponet.deeponet - INFO - Epoch 244/300\n",
      "2025-08-04 18:08:41,216 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048708\n",
      "2025-08-04 18:08:41,216 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049253\n",
      "Training progress:  81%|████████▏ | 244/300 [08:10<01:56,  2.09s/it]2025-08-04 18:08:44,887 - sciml.model.deeponet.deeponet - INFO - Epoch 245/300\n",
      "2025-08-04 18:08:44,888 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048734\n",
      "2025-08-04 18:08:44,888 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049254\n",
      "Training progress:  82%|████████▏ | 245/300 [08:14<02:20,  2.56s/it]2025-08-04 18:08:47,570 - sciml.model.deeponet.deeponet - INFO - Epoch 246/300\n",
      "2025-08-04 18:08:47,571 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048735\n",
      "2025-08-04 18:08:47,572 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049258\n",
      "Training progress:  82%|████████▏ | 246/300 [08:16<02:20,  2.60s/it]2025-08-04 18:08:49,568 - sciml.model.deeponet.deeponet - INFO - Epoch 247/300\n",
      "2025-08-04 18:08:49,569 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048706\n",
      "2025-08-04 18:08:49,569 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049286\n",
      "Training progress:  82%|████████▏ | 247/300 [08:18<02:08,  2.42s/it]2025-08-04 18:08:51,673 - sciml.model.deeponet.deeponet - INFO - Epoch 248/300\n",
      "2025-08-04 18:08:51,673 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048729\n",
      "2025-08-04 18:08:51,674 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049263\n",
      "Training progress:  83%|████████▎ | 248/300 [08:21<02:00,  2.32s/it]2025-08-04 18:08:53,719 - sciml.model.deeponet.deeponet - INFO - Epoch 249/300\n",
      "2025-08-04 18:08:53,720 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048738\n",
      "2025-08-04 18:08:53,720 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049334\n",
      "Training progress:  83%|████████▎ | 249/300 [08:23<01:54,  2.24s/it]2025-08-04 18:08:55,715 - sciml.model.deeponet.deeponet - INFO - Epoch 250/300\n",
      "2025-08-04 18:08:55,716 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048841\n",
      "2025-08-04 18:08:55,717 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049268\n",
      "Training progress:  83%|████████▎ | 250/300 [08:25<01:48,  2.17s/it]2025-08-04 18:08:57,648 - sciml.model.deeponet.deeponet - INFO - Epoch 251/300\n",
      "2025-08-04 18:08:57,648 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048777\n",
      "2025-08-04 18:08:57,649 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049275\n",
      "Training progress:  84%|████████▎ | 251/300 [08:27<01:42,  2.10s/it]2025-08-04 18:08:59,499 - sciml.model.deeponet.deeponet - INFO - Epoch 252/300\n",
      "2025-08-04 18:08:59,500 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048712\n",
      "2025-08-04 18:08:59,501 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049252\n",
      "Training progress:  84%|████████▍ | 252/300 [08:28<01:37,  2.02s/it]2025-08-04 18:09:01,378 - sciml.model.deeponet.deeponet - INFO - Epoch 253/300\n",
      "2025-08-04 18:09:01,379 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048714\n",
      "2025-08-04 18:09:01,380 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049246\n",
      "Training progress:  84%|████████▍ | 253/300 [08:30<01:33,  1.98s/it]2025-08-04 18:09:03,338 - sciml.model.deeponet.deeponet - INFO - Epoch 254/300\n",
      "2025-08-04 18:09:03,339 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048701\n",
      "2025-08-04 18:09:03,340 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049246\n",
      "Training progress:  85%|████████▍ | 254/300 [08:32<01:30,  1.97s/it]2025-08-04 18:09:05,368 - sciml.model.deeponet.deeponet - INFO - Epoch 255/300\n",
      "2025-08-04 18:09:05,369 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048725\n",
      "2025-08-04 18:09:05,369 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049265\n",
      "Training progress:  85%|████████▌ | 255/300 [08:34<01:29,  1.99s/it]2025-08-04 18:09:07,467 - sciml.model.deeponet.deeponet - INFO - Epoch 256/300\n",
      "2025-08-04 18:09:07,468 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.049057\n",
      "2025-08-04 18:09:07,469 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049526\n",
      "Training progress:  85%|████████▌ | 256/300 [08:36<01:29,  2.02s/it]2025-08-04 18:09:09,447 - sciml.model.deeponet.deeponet - INFO - Epoch 257/300\n",
      "2025-08-04 18:09:09,448 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048839\n",
      "2025-08-04 18:09:09,448 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049287\n",
      "Training progress:  86%|████████▌ | 257/300 [08:38<01:26,  2.01s/it]2025-08-04 18:09:11,469 - sciml.model.deeponet.deeponet - INFO - Epoch 258/300\n",
      "2025-08-04 18:09:11,470 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048719\n",
      "2025-08-04 18:09:11,470 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  86%|████████▌ | 258/300 [08:40<01:24,  2.01s/it]2025-08-04 18:09:13,535 - sciml.model.deeponet.deeponet - INFO - Epoch 259/300\n",
      "2025-08-04 18:09:13,535 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048711\n",
      "2025-08-04 18:09:13,536 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  86%|████████▋ | 259/300 [08:42<01:23,  2.03s/it]2025-08-04 18:09:15,583 - sciml.model.deeponet.deeponet - INFO - Epoch 260/300\n",
      "2025-08-04 18:09:15,583 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048705\n",
      "2025-08-04 18:09:15,584 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049244\n",
      "Training progress:  87%|████████▋ | 260/300 [08:44<01:21,  2.04s/it]2025-08-04 18:09:17,699 - sciml.model.deeponet.deeponet - INFO - Epoch 261/300\n",
      "2025-08-04 18:09:17,700 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048698\n",
      "2025-08-04 18:09:17,701 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049241\n",
      "Training progress:  87%|████████▋ | 261/300 [08:47<01:20,  2.06s/it]2025-08-04 18:09:20,328 - sciml.model.deeponet.deeponet - INFO - Epoch 262/300\n",
      "2025-08-04 18:09:20,329 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048697\n",
      "2025-08-04 18:09:20,330 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049243\n",
      "Training progress:  87%|████████▋ | 262/300 [08:49<01:24,  2.23s/it]2025-08-04 18:09:22,384 - sciml.model.deeponet.deeponet - INFO - Epoch 263/300\n",
      "2025-08-04 18:09:22,385 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048696\n",
      "2025-08-04 18:09:22,386 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049236\n",
      "Training progress:  88%|████████▊ | 263/300 [08:51<01:20,  2.18s/it]2025-08-04 18:09:24,545 - sciml.model.deeponet.deeponet - INFO - Epoch 264/300\n",
      "2025-08-04 18:09:24,545 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048696\n",
      "2025-08-04 18:09:24,546 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049236\n",
      "Training progress:  88%|████████▊ | 264/300 [08:53<01:18,  2.17s/it]2025-08-04 18:09:26,573 - sciml.model.deeponet.deeponet - INFO - Epoch 265/300\n",
      "2025-08-04 18:09:26,574 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048706\n",
      "2025-08-04 18:09:26,575 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049246\n",
      "Training progress:  88%|████████▊ | 265/300 [08:55<01:14,  2.13s/it]2025-08-04 18:09:28,759 - sciml.model.deeponet.deeponet - INFO - Epoch 266/300\n",
      "2025-08-04 18:09:28,760 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048701\n",
      "2025-08-04 18:09:28,761 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049241\n",
      "Training progress:  89%|████████▊ | 266/300 [08:58<01:12,  2.15s/it]2025-08-04 18:09:31,850 - sciml.model.deeponet.deeponet - INFO - Epoch 267/300\n",
      "2025-08-04 18:09:31,851 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048734\n",
      "2025-08-04 18:09:31,852 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049261\n",
      "Training progress:  89%|████████▉ | 267/300 [09:01<01:20,  2.43s/it]2025-08-04 18:09:33,981 - sciml.model.deeponet.deeponet - INFO - Epoch 268/300\n",
      "2025-08-04 18:09:33,982 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048756\n",
      "2025-08-04 18:09:33,983 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049280\n",
      "Training progress:  89%|████████▉ | 268/300 [09:03<01:14,  2.34s/it]2025-08-04 18:09:36,085 - sciml.model.deeponet.deeponet - INFO - Epoch 269/300\n",
      "2025-08-04 18:09:36,086 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048710\n",
      "2025-08-04 18:09:36,087 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049270\n",
      "Training progress:  90%|████████▉ | 269/300 [09:05<01:10,  2.27s/it]2025-08-04 18:09:38,366 - sciml.model.deeponet.deeponet - INFO - Epoch 270/300\n",
      "2025-08-04 18:09:38,367 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048715\n",
      "2025-08-04 18:09:38,367 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049270\n",
      "Training progress:  90%|█████████ | 270/300 [09:07<01:08,  2.27s/it]2025-08-04 18:09:40,380 - sciml.model.deeponet.deeponet - INFO - Epoch 271/300\n",
      "2025-08-04 18:09:40,380 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048775\n",
      "2025-08-04 18:09:40,381 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049268\n",
      "Training progress:  90%|█████████ | 271/300 [09:09<01:03,  2.19s/it]2025-08-04 18:09:42,412 - sciml.model.deeponet.deeponet - INFO - Epoch 272/300\n",
      "2025-08-04 18:09:42,413 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048721\n",
      "2025-08-04 18:09:42,414 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  91%|█████████ | 272/300 [09:11<01:00,  2.15s/it]2025-08-04 18:09:44,751 - sciml.model.deeponet.deeponet - INFO - Epoch 273/300\n",
      "2025-08-04 18:09:44,752 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048760\n",
      "2025-08-04 18:09:44,753 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049247\n",
      "Training progress:  91%|█████████ | 273/300 [09:14<00:59,  2.20s/it]2025-08-04 18:09:46,999 - sciml.model.deeponet.deeponet - INFO - Epoch 274/300\n",
      "2025-08-04 18:09:47,000 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048715\n",
      "2025-08-04 18:09:47,001 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049291\n",
      "Training progress:  91%|█████████▏| 274/300 [09:16<00:57,  2.22s/it]2025-08-04 18:09:49,110 - sciml.model.deeponet.deeponet - INFO - Epoch 275/300\n",
      "2025-08-04 18:09:49,111 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048752\n",
      "2025-08-04 18:09:49,112 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049259\n",
      "Training progress:  92%|█████████▏| 275/300 [09:18<00:54,  2.19s/it]2025-08-04 18:09:51,730 - sciml.model.deeponet.deeponet - INFO - Epoch 276/300\n",
      "2025-08-04 18:09:51,731 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048711\n",
      "2025-08-04 18:09:51,731 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049295\n",
      "Training progress:  92%|█████████▏| 276/300 [09:21<00:55,  2.32s/it]2025-08-04 18:09:53,786 - sciml.model.deeponet.deeponet - INFO - Epoch 277/300\n",
      "2025-08-04 18:09:53,787 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048731\n",
      "2025-08-04 18:09:53,788 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049276\n",
      "Training progress:  92%|█████████▏| 277/300 [09:23<00:51,  2.24s/it]2025-08-04 18:09:55,888 - sciml.model.deeponet.deeponet - INFO - Epoch 278/300\n",
      "2025-08-04 18:09:55,889 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048739\n",
      "2025-08-04 18:09:55,890 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049249\n",
      "Training progress:  93%|█████████▎| 278/300 [09:25<00:48,  2.20s/it]2025-08-04 18:09:58,114 - sciml.model.deeponet.deeponet - INFO - Epoch 279/300\n",
      "2025-08-04 18:09:58,115 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048723\n",
      "2025-08-04 18:09:58,116 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049262\n",
      "Training progress:  93%|█████████▎| 279/300 [09:27<00:46,  2.21s/it]2025-08-04 18:10:00,138 - sciml.model.deeponet.deeponet - INFO - Epoch 280/300\n",
      "2025-08-04 18:10:00,139 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048784\n",
      "2025-08-04 18:10:00,139 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049255\n",
      "Training progress:  93%|█████████▎| 280/300 [09:29<00:43,  2.15s/it]2025-08-04 18:10:02,348 - sciml.model.deeponet.deeponet - INFO - Epoch 281/300\n",
      "2025-08-04 18:10:02,349 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048714\n",
      "2025-08-04 18:10:02,349 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049253\n",
      "Training progress:  94%|█████████▎| 281/300 [09:31<00:41,  2.17s/it]2025-08-04 18:10:04,367 - sciml.model.deeponet.deeponet - INFO - Epoch 282/300\n",
      "2025-08-04 18:10:04,368 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048729\n",
      "2025-08-04 18:10:04,369 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049246\n",
      "Training progress:  94%|█████████▍| 282/300 [09:33<00:38,  2.12s/it]2025-08-04 18:10:06,378 - sciml.model.deeponet.deeponet - INFO - Epoch 283/300\n",
      "2025-08-04 18:10:06,379 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048709\n",
      "2025-08-04 18:10:06,379 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049251\n",
      "Training progress:  94%|█████████▍| 283/300 [09:35<00:35,  2.09s/it]2025-08-04 18:10:08,483 - sciml.model.deeponet.deeponet - INFO - Epoch 284/300\n",
      "2025-08-04 18:10:08,484 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048734\n",
      "2025-08-04 18:10:08,485 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049243\n",
      "Training progress:  95%|█████████▍| 284/300 [09:37<00:33,  2.09s/it]2025-08-04 18:10:10,722 - sciml.model.deeponet.deeponet - INFO - Epoch 285/300\n",
      "2025-08-04 18:10:10,722 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048734\n",
      "2025-08-04 18:10:10,723 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049278\n",
      "Training progress:  95%|█████████▌| 285/300 [09:40<00:32,  2.14s/it]2025-08-04 18:10:13,096 - sciml.model.deeponet.deeponet - INFO - Epoch 286/300\n",
      "2025-08-04 18:10:13,097 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048745\n",
      "2025-08-04 18:10:13,098 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049245\n",
      "Training progress:  95%|█████████▌| 286/300 [09:42<00:30,  2.21s/it]2025-08-04 18:10:15,296 - sciml.model.deeponet.deeponet - INFO - Epoch 287/300\n",
      "2025-08-04 18:10:15,297 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048708\n",
      "2025-08-04 18:10:15,299 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049256\n",
      "Training progress:  96%|█████████▌| 287/300 [09:44<00:28,  2.21s/it]2025-08-04 18:10:17,596 - sciml.model.deeponet.deeponet - INFO - Epoch 288/300\n",
      "2025-08-04 18:10:17,597 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048713\n",
      "2025-08-04 18:10:17,597 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049250\n",
      "Training progress:  96%|█████████▌| 288/300 [09:46<00:26,  2.23s/it]2025-08-04 18:10:19,532 - sciml.model.deeponet.deeponet - INFO - Epoch 289/300\n",
      "2025-08-04 18:10:19,532 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048702\n",
      "2025-08-04 18:10:19,533 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049244\n",
      "Training progress:  96%|█████████▋| 289/300 [09:48<00:23,  2.14s/it]2025-08-04 18:10:21,670 - sciml.model.deeponet.deeponet - INFO - Epoch 290/300\n",
      "2025-08-04 18:10:21,671 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048696\n",
      "2025-08-04 18:10:21,671 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049236\n",
      "Training progress:  97%|█████████▋| 290/300 [09:51<00:21,  2.14s/it]2025-08-04 18:10:23,664 - sciml.model.deeponet.deeponet - INFO - Epoch 291/300\n",
      "2025-08-04 18:10:23,665 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048728\n",
      "2025-08-04 18:10:23,666 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049268\n",
      "Training progress:  97%|█████████▋| 291/300 [09:53<00:18,  2.10s/it]2025-08-04 18:10:26,369 - sciml.model.deeponet.deeponet - INFO - Epoch 292/300\n",
      "2025-08-04 18:10:26,370 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048904\n",
      "2025-08-04 18:10:26,370 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049471\n",
      "Training progress:  97%|█████████▋| 292/300 [09:55<00:18,  2.28s/it]2025-08-04 18:10:28,746 - sciml.model.deeponet.deeponet - INFO - Epoch 293/300\n",
      "2025-08-04 18:10:28,747 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048832\n",
      "2025-08-04 18:10:28,748 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049295\n",
      "Training progress:  98%|█████████▊| 293/300 [09:58<00:16,  2.31s/it]2025-08-04 18:10:31,162 - sciml.model.deeponet.deeponet - INFO - Epoch 294/300\n",
      "2025-08-04 18:10:31,163 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048722\n",
      "2025-08-04 18:10:31,163 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049257\n",
      "Training progress:  98%|█████████▊| 294/300 [10:00<00:14,  2.34s/it]2025-08-04 18:10:33,500 - sciml.model.deeponet.deeponet - INFO - Epoch 295/300\n",
      "2025-08-04 18:10:33,501 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048711\n",
      "2025-08-04 18:10:33,501 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049240\n",
      "Training progress:  98%|█████████▊| 295/300 [10:02<00:11,  2.34s/it]2025-08-04 18:10:35,781 - sciml.model.deeponet.deeponet - INFO - Epoch 296/300\n",
      "2025-08-04 18:10:35,782 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048699\n",
      "2025-08-04 18:10:35,782 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049251\n",
      "Training progress:  99%|█████████▊| 296/300 [10:05<00:09,  2.32s/it]2025-08-04 18:10:38,032 - sciml.model.deeponet.deeponet - INFO - Epoch 297/300\n",
      "2025-08-04 18:10:38,032 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048695\n",
      "2025-08-04 18:10:38,033 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049242\n",
      "Training progress:  99%|█████████▉| 297/300 [10:07<00:06,  2.30s/it]2025-08-04 18:10:40,201 - sciml.model.deeponet.deeponet - INFO - Epoch 298/300\n",
      "2025-08-04 18:10:40,202 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048694\n",
      "2025-08-04 18:10:40,202 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049257\n",
      "Training progress:  99%|█████████▉| 298/300 [10:09<00:04,  2.26s/it]2025-08-04 18:10:42,453 - sciml.model.deeponet.deeponet - INFO - Epoch 299/300\n",
      "2025-08-04 18:10:42,454 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048705\n",
      "2025-08-04 18:10:42,455 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049258\n",
      "Training progress: 100%|█████████▉| 299/300 [10:11<00:02,  2.26s/it]2025-08-04 18:10:44,439 - sciml.model.deeponet.deeponet - INFO - Epoch 300/300\n",
      "2025-08-04 18:10:44,440 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.048701\n",
      "2025-08-04 18:10:44,441 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.049262\n",
      "Training progress: 100%|██████████| 300/300 [10:13<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "707c5d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.07497689127922058, 0.06416235864162445, 0.05886531248688698, 0.05490376055240631, 0.053049392998218536, 0.051903896033763885, 0.05116989463567734, 0.050742845982313156, 0.05043256655335426, 0.05035139620304108, 0.0500737763941288, 0.04989425092935562, 0.04972168803215027, 0.049602117389440536, 0.0499727688729763, 0.04950075224041939, 0.049373701214790344, 0.049353305250406265, 0.04974067211151123, 0.04938188195228577, 0.04925442859530449, 0.04921295493841171, 0.049194253981113434, 0.049512218683958054, 0.04934220388531685, 0.049177005887031555, 0.04913008213043213, 0.049125175923109055, 0.049113679677248, 0.04916517436504364, 0.04920404031872749, 0.04907875135540962, 0.04908384755253792, 0.04917724430561066, 0.04908381402492523, 0.049045175313949585, 0.049023792147636414, 0.049016885459423065, 0.049047600477933884, 0.04919920116662979, 0.049299903213977814, 0.04903094470500946, 0.0489945188164711, 0.048982925713062286, 0.04905484989285469, 0.049013614654541016, 0.04917551204562187, 0.04905508831143379, 0.04897931218147278, 0.04896437004208565, 0.0490003377199173, 0.04914392903447151, 0.049290481954813004, 0.04902198165655136, 0.04897267371416092, 0.04893864318728447, 0.048935119062662125, 0.04894048348069191, 0.048952750861644745, 0.049247827380895615, 0.04897962510585785, 0.04892238974571228, 0.04891416057944298, 0.04893512278795242, 0.04890443757176399, 0.04891170933842659, 0.04899004474282265, 0.04899180307984352, 0.04901054501533508, 0.048921726644039154, 0.048930902034044266, 0.048998236656188965, 0.048878349363803864, 0.0489463172852993, 0.048963312059640884, 0.048878297209739685, 0.04887249320745468, 0.048880625516176224, 0.04905041307210922, 0.048873912543058395, 0.048862554132938385, 0.04893936589360237, 0.04889794439077377, 0.04885265231132507, 0.048832058906555176, 0.048867929726839066, 0.04893844947218895, 0.04900218918919563, 0.04885600507259369, 0.048821914941072464, 0.0488831028342247, 0.049006763845682144, 0.04884398356080055, 0.048813678324222565, 0.048808880150318146, 0.04882069677114487, 0.04884985834360123, 0.04884796962141991, 0.04882150515913963, 0.04887345805764198, 0.04900947958230972, 0.04882415384054184, 0.04879825934767723, 0.0488157719373703, 0.04899515584111214, 0.04881489276885986, 0.04879813641309738, 0.04890381172299385, 0.04882378503680229, 0.04881647229194641, 0.04894086346030235, 0.04881439357995987, 0.048788126558065414, 0.04880043491721153, 0.048910416662693024, 0.04879055917263031, 0.04878054931759834, 0.04877663031220436, 0.048776160925626755, 0.048814546316862106, 0.048883840441703796, 0.04897458851337433, 0.04888664558529854, 0.04878472164273262, 0.04878107085824013, 0.04884396493434906, 0.04884304478764534, 0.048794224858284, 0.04881758615374565, 0.04886873811483383, 0.048800788819789886, 0.04877863824367523, 0.048785530030727386, 0.0488189272582531, 0.04895874112844467, 0.04882967844605446, 0.048775676637887955, 0.0487554632127285, 0.04877516254782677, 0.04875607788562775, 0.04879782348871231, 0.048783477395772934, 0.04877856373786926, 0.04876597970724106, 0.04874148219823837, 0.04877007380127907, 0.04880138859152794, 0.04875937104225159, 0.04877220466732979, 0.04878382757306099, 0.048841580748558044, 0.0487610399723053, 0.04880371689796448, 0.04883265867829323, 0.048793718218803406, 0.04922835901379585, 0.04884405434131622, 0.04875165596604347, 0.04875693842768669, 0.04874224215745926, 0.048731397837400436, 0.048728495836257935, 0.04872782155871391, 0.048730164766311646, 0.04873165488243103, 0.04874100163578987, 0.04875875636935234, 0.048777561634778976, 0.04875839129090309, 0.04881179705262184, 0.04895174875855446, 0.04879401996731758, 0.048750538378953934, 0.048737335950136185, 0.048739954829216, 0.048951517790555954, 0.04886344075202942, 0.048759039491415024, 0.048737071454524994, 0.04873301833868027, 0.04874454066157341, 0.04875132441520691, 0.04874943569302559, 0.04873718321323395, 0.0487452931702137, 0.04873541742563248, 0.048727065324783325, 0.0487547442317009, 0.04922756180167198, 0.04895572364330292, 0.04874492064118385, 0.048724137246608734, 0.0487208217382431, 0.048715390264987946, 0.04871207848191261, 0.04871417582035065, 0.04871401935815811, 0.048720136284828186, 0.0487121157348156, 0.048721056431531906, 0.04876312240958214, 0.048756007105112076, 0.04886181280016899, 0.04879281669855118, 0.04880109801888466, 0.04872996732592583, 0.048714131116867065, 0.04873444512486458, 0.048729442059993744, 0.04871443286538124, 0.04873864725232124, 0.04871002584695816, 0.04870530217885971, 0.04874548316001892, 0.049085818231105804, 0.04897521063685417, 0.048768412321805954, 0.048721060156822205, 0.04872005432844162, 0.048717208206653595, 0.048708196729421616, 0.04870305955410004, 0.048702578991651535, 0.0487016886472702, 0.048701077699661255, 0.04872675985097885, 0.0487079843878746, 0.04873417317867279, 0.04873761534690857, 0.048745378851890564, 0.04879438504576683, 0.048739805817604065, 0.048704080283641815, 0.04872456192970276, 0.048740364611148834, 0.04879815876483917, 0.04871940240263939, 0.048711009323596954, 0.048773813992738724, 0.04872029647231102, 0.048736702650785446, 0.04871872067451477, 0.0487397164106369, 0.04870795086026192, 0.04873372241854668, 0.04873482882976532, 0.0487062931060791, 0.04872864857316017, 0.048737846314907074, 0.048841141164302826, 0.048776715993881226, 0.04871232807636261, 0.04871397465467453, 0.048700910061597824, 0.048724621534347534, 0.04905659332871437, 0.04883906990289688, 0.048719171434640884, 0.04871082678437233, 0.04870491102337837, 0.04869835078716278, 0.04869652912020683, 0.04869605973362923, 0.048695534467697144, 0.048705682158470154, 0.0487007275223732, 0.048734184354543686, 0.048756323754787445, 0.04870985075831413, 0.04871488735079765, 0.048775214701890945, 0.048720747232437134, 0.048760250210762024, 0.04871474578976631, 0.04875168204307556, 0.04871096462011337, 0.0487305223941803, 0.0487385131418705, 0.0487230122089386, 0.04878374934196472, 0.04871417209506035, 0.04872949421405792, 0.04870868846774101, 0.0487341545522213, 0.04873442277312279, 0.04874517023563385, 0.04870816320180893, 0.048713359981775284, 0.048702389001846313, 0.04869567230343819, 0.04872756078839302, 0.04890426620841026, 0.048831507563591, 0.0487222895026207, 0.04871140047907829, 0.04869873449206352, 0.04869462922215462, 0.04869382455945015, 0.048704568296670914, 0.04870123416185379], [0.0644945353269577, 0.061827462166547775, 0.05682748183608055, 0.054541148245334625, 0.052870847284793854, 0.052022483199834824, 0.05168711394071579, 0.051143985241651535, 0.05101937800645828, 0.050850216299295425, 0.05075961351394653, 0.05056193843483925, 0.050323422998189926, 0.05022389441728592, 0.05009765177965164, 0.04997018724679947, 0.05004800111055374, 0.04996160417795181, 0.04995699226856232, 0.049871739000082016, 0.049833085387945175, 0.04981803148984909, 0.049770042300224304, 0.04987110570073128, 0.049728136509656906, 0.049725666642189026, 0.04969606548547745, 0.04970970004796982, 0.0496576651930809, 0.04970455914735794, 0.049647316336631775, 0.04962966963648796, 0.04961172863841057, 0.0496518574655056, 0.04963184893131256, 0.049585796892642975, 0.049582622945308685, 0.04956965148448944, 0.049725547432899475, 0.049926161766052246, 0.049656935036182404, 0.049557048827409744, 0.049537163227796555, 0.04953594505786896, 0.04954373836517334, 0.04953477904200554, 0.04964318126440048, 0.049566105008125305, 0.04952755197882652, 0.04951431602239609, 0.049619436264038086, 0.049623534083366394, 0.04956363886594772, 0.04955751448869705, 0.04949900880455971, 0.04948815330862999, 0.04948369413614273, 0.04947811737656593, 0.04959474503993988, 0.049612607806921005, 0.04952028766274452, 0.04947014898061752, 0.04946490377187729, 0.04948339983820915, 0.04946295544505119, 0.04953915625810623, 0.04947914555668831, 0.04947575181722641, 0.04947469383478165, 0.04944143816828728, 0.04948503151535988, 0.049433641135692596, 0.04944352060556412, 0.04943632334470749, 0.04953379184007645, 0.04942455515265465, 0.04943140968680382, 0.04942169412970543, 0.04942493140697479, 0.049467239528894424, 0.04941588640213013, 0.04942510277032852, 0.049512024968862534, 0.049403708428144455, 0.04939575493335724, 0.04943680763244629, 0.04943913221359253, 0.049465570598840714, 0.04937748610973358, 0.04938175156712532, 0.049405261874198914, 0.04942689836025238, 0.04937232285737991, 0.0493646077811718, 0.04936257749795914, 0.0493808314204216, 0.04939653351902962, 0.04936911165714264, 0.0493924543261528, 0.049401700496673584, 0.049476202577352524, 0.04934828728437424, 0.049339935183525085, 0.04939218983054161, 0.049467429518699646, 0.049333907663822174, 0.04933609440922737, 0.0494035929441452, 0.049353472888469696, 0.049333129078149796, 0.04936760291457176, 0.04935066029429436, 0.04935763403773308, 0.049360428005456924, 0.049374036490917206, 0.04932180792093277, 0.049320466816425323, 0.049316857010126114, 0.04935425519943237, 0.04945387318730354, 0.049342911690473557, 0.04964649677276611, 0.0493263378739357, 0.04931406304240227, 0.04931415989995003, 0.04940027743577957, 0.049338988959789276, 0.04931778460741043, 0.04932176321744919, 0.04939500615000725, 0.049311213195323944, 0.04930104687809944, 0.04930279776453972, 0.04932113364338875, 0.04933638870716095, 0.049339454621076584, 0.04929584637284279, 0.04929079860448837, 0.0492941215634346, 0.04929202049970627, 0.049291353672742844, 0.04929923638701439, 0.04928915202617645, 0.04929061606526375, 0.04928227886557579, 0.04940106347203255, 0.049313031136989594, 0.04929058998823166, 0.049334459006786346, 0.04940127953886986, 0.04932832345366478, 0.04934608191251755, 0.04947405681014061, 0.04930470883846283, 0.04931630566716194, 0.04959046468138695, 0.049293871968984604, 0.049300678074359894, 0.04929351806640625, 0.04927326738834381, 0.0492725595831871, 0.0492686964571476, 0.04926976189017296, 0.0492829754948616, 0.04929908365011215, 0.04930071160197258, 0.04928959161043167, 0.049306273460388184, 0.04933546110987663, 0.049320027232170105, 0.049408432096242905, 0.049326274544000626, 0.049281809478998184, 0.04926082864403725, 0.04927777871489525, 0.04950812831521034, 0.04931505024433136, 0.04927685111761093, 0.04926533252000809, 0.04926476627588272, 0.049266401678323746, 0.04926558583974838, 0.04926322400569916, 0.049266789108514786, 0.04926048219203949, 0.04926156625151634, 0.04925915226340294, 0.049278948456048965, 0.050113484263420105, 0.04930023103952408, 0.049275849014520645, 0.0492619127035141, 0.04925864189863205, 0.049254629760980606, 0.0492505244910717, 0.04924999177455902, 0.04925107955932617, 0.04925338923931122, 0.04925158992409706, 0.04925727844238281, 0.04925380274653435, 0.049263715744018555, 0.04945461452007294, 0.04940754175186157, 0.04929902032017708, 0.04928237199783325, 0.04926127567887306, 0.049286819994449615, 0.0492636002600193, 0.04925481230020523, 0.049259644001722336, 0.04924575239419937, 0.04924701899290085, 0.04930643364787102, 0.049639783799648285, 0.04939647018909454, 0.049267783761024475, 0.04926012083888054, 0.049254391342401505, 0.04924890026450157, 0.049249690026044846, 0.04924880713224411, 0.0492500476539135, 0.049243178218603134, 0.04924476891756058, 0.04925716295838356, 0.04925934970378876, 0.049269191920757294, 0.04926155507564545, 0.049249712377786636, 0.04927942901849747, 0.04926130920648575, 0.049251291900873184, 0.04933015629649162, 0.04929560422897339, 0.04930439218878746, 0.04924531280994415, 0.04925140365958214, 0.049283284693956375, 0.049267224967479706, 0.04927881434559822, 0.049266036599874496, 0.049272119998931885, 0.049253467470407486, 0.049253687262535095, 0.04925757274031639, 0.04928648844361305, 0.04926302656531334, 0.04933397099375725, 0.04926757514476776, 0.04927491396665573, 0.049251820892095566, 0.049246255308389664, 0.04924624785780907, 0.049264851957559586, 0.049526289105415344, 0.04928699508309364, 0.0492498055100441, 0.04925021156668663, 0.049244120717048645, 0.04924101009964943, 0.04924315586686134, 0.0492355078458786, 0.04923634231090546, 0.04924614727497101, 0.04924102500081062, 0.04926116019487381, 0.04928026348352432, 0.04927049204707146, 0.0492703877389431, 0.04926785081624985, 0.049249615520238876, 0.049247026443481445, 0.04929139092564583, 0.04925910383462906, 0.049294523894786835, 0.04927615448832512, 0.049248673021793365, 0.0492619052529335, 0.049254730343818665, 0.04925283417105675, 0.04924582690000534, 0.049251459538936615, 0.049242667853832245, 0.049278054386377335, 0.04924521967768669, 0.049256086349487305, 0.0492500402033329, 0.04924437031149864, 0.04923613369464874, 0.049267854541540146, 0.049470942467451096, 0.04929459095001221, 0.04925680160522461, 0.04924016818404198, 0.04925057664513588, 0.0492415688931942, 0.04925676807761192, 0.04925768822431564, 0.049262430518865585])\n"
     ]
    }
   ],
   "source": [
    "print(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56598b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_history[0], label='Training Loss')  # we plot training loss\n",
    "plt.plot(train_history[1], label='Test Loss')  # we plot test loss\n",
    "plt.yscale('log')  # we use log scale for better visualization\n",
    "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)  # we add grid with transparency\n",
    "plt.xlabel('Epochs')  # we add x label\n",
    "plt.ylabel('Loss')  # we add y label\n",
    "plt.title('Training and Test Loss Over Time')  # we add title\n",
    "plt.legend()  # we add legend\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd8958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
